{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:16:00+01:00"
    },
    {
      "path": "chill.html",
      "title": "Chill models",
      "author": [],
      "contents": "\r\nIn this chapter, various chill models will be explored using the chillR package in R, which simplifies the calculation of chilling hours and other dormancy-related metrics based on temperature data.\r\nChilling_Hours() Function\r\nThe Chilling_Hours() function calculates the time during which temperatures fall within a key range for chill accumulation. It takes hourly temperature data as input and, by default, provides the cumulative amount of chilling accumulated over time.\r\n\r\n\r\nChilling_Hours(Winters_hours_gaps$Temp)[1:100]\r\n\r\n  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  2  2  2  3  4  5\r\n [22]  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\r\n [43]  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  8\r\n [64]  9 10 11 12 13 14 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16\r\n [85] 16 17 18 19 20 21 22 23 24 25 25 25 25 25 25 25\r\n\r\nThe result will show the first 100 values, where the cumulative chilling hours increase as the temperature falls within the specified range.\r\nUtah Model\r\nThe Utah Model assigns different weights to various temperature ranges, reflecting their impact on chill accumulation. The Utah_Model() function in chillR calculates these weighted chilling contributions for each hour of temperature data. The output will show the Utah model values for the first 100 hours, where positive, zero, and negative weights are applied based on the temperature:\r\n\r\n\r\nUtah_Model(Winters_hours_gaps$Temp)[1:100]\r\n\r\n  [1]  0.0 -0.5 -1.5 -2.5 -3.5 -4.5 -5.5 -6.0 -6.0 -6.0 -5.5 -5.0 -4.0\r\n [14] -3.0 -2.0 -1.0  0.0  0.5  1.5  2.5  3.5  4.5  5.0  5.0  5.0  4.0\r\n [27]  3.0  2.0  1.0  0.0 -1.0 -2.0 -2.5 -2.5 -2.0 -1.5 -1.0 -0.5  0.5\r\n [40]  1.0  1.5  2.0  2.0  2.5  3.0  3.5  4.0  4.0  4.0  3.5  2.5  1.5\r\n [53]  0.5 -0.5 -1.5 -2.5 -3.0 -3.0 -2.5 -1.5 -0.5  0.5  1.5  2.5  3.5\r\n [66]  4.5  5.5  6.5  7.5  8.5  9.5 10.0 10.0  9.5  9.0  8.5  8.0  7.5\r\n [79]  7.0  6.5  6.5  7.0  7.5  8.5  9.5 10.5 11.5 12.5 13.5 14.5 15.5\r\n [92] 16.5 17.5 18.5 19.0 19.0 19.0 18.5 17.5 16.5\r\n\r\nCreating Custom Chill Models with step_model()\r\nThe step_model() function, part of the chillR package, enables the creation of custom chill models based on temperature thresholds and weights. This process involves defining a data frame that specifies temperature ranges and their corresponding weights. Here’s an example of a data frame that defines temperature ranges and their corresponding weights:\r\n\r\n\r\ndf <- data.frame(\r\n  lower = c(-1000, 1, 2, 3, 4, 5,    6),\r\n  upper = c(    1, 2, 3, 4, 5, 6, 1000),\r\n  weight = c(   0, 1, 2, 3, 2, 1,    0))\r\n\r\n\r\n\r\n\r\nlower\r\n\r\n\r\nupper\r\n\r\n\r\nweight\r\n\r\n\r\n-1000\r\n\r\n\r\n1\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n3\r\n\r\n\r\n2\r\n\r\n\r\n3\r\n\r\n\r\n4\r\n\r\n\r\n3\r\n\r\n\r\n4\r\n\r\n\r\n5\r\n\r\n\r\n2\r\n\r\n\r\n5\r\n\r\n\r\n6\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n1000\r\n\r\n\r\n0\r\n\r\n\r\nA function called custom() implements a chill model based on this data frame. This function is then applied to the Winters_hours_gaps dataset to calculate the chilling contributions:\r\n\r\n\r\ncustom <- function(x) step_model(x, df)\r\ncustom(Winters_hours_gaps$Temp)[1:100]\r\n\r\n  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  4\r\n [22]  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\r\n [43]  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\r\n [64]  7  8 10 13 16 19 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\r\n [85] 22 22 22 23 25 27 29 31 34 37 37 37 37 37 37 37\r\n\r\nDynamic model\r\nThe Dynamic Model provides a more complex and reliable approach to calculating chill, with the Dynamic_Model() function handling the intricate equations involved. This function can be easily applied to the Winters_hours_gaps dataset, producing output that displays dynamic chill values for the first 100 hours, reflecting the underlying physiological processes:\r\n\r\n\r\nDynamic_Model(Winters_hours_gaps$Temp)[1:100]\r\n\r\n  [1] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\r\n  [7] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\r\n [13] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\r\n [19] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\r\n [25] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\r\n [31] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\r\n [37] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\r\n [43] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\r\n [49] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\r\n [55] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\r\n [61] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\r\n [67] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.9698435\r\n [73] 0.9698435 0.9698435 0.9698435 0.9698435 0.9698435 0.9698435\r\n [79] 0.9698435 0.9698435 0.9698435 0.9698435 0.9698435 0.9698435\r\n [85] 0.9698435 0.9698435 0.9698435 0.9698435 0.9698435 0.9698435\r\n [91] 0.9698435 0.9698435 0.9698435 0.9698435 0.9698435 0.9698435\r\n [97] 0.9698435 0.9698435 0.9698435 0.9698435\r\n\r\nChilling and tempResponse functions\r\nThe chillR package offers several functions for analyzing hourly temperature data, including wrapper functions that enable the computation of chill between specific start and end dates. The chilling() function automatically calculates various basic metrics, including Chilling Hours, Utah Model, Dynamic Model, and Growing Degree Hours. It is important to use the make_JDay() function to add Julian dates (which count the days of the year) to the dataset, ensuring proper functionality.\r\n\r\n\r\nchill_output <- chilling(make_JDay(Winters_hours_gaps), Start_JDay = 90, End_JDay = 100)\r\n\r\n\r\n\r\n\r\n\r\nSeason\r\n\r\n\r\nEnd_year\r\n\r\n\r\nSeason_days\r\n\r\n\r\nData_days\r\n\r\n\r\nPerc_complete\r\n\r\n\r\nChilling_Hours\r\n\r\n\r\nUtah_Model\r\n\r\n\r\nChill_portions\r\n\r\n\r\nGDH\r\n\r\n\r\n2007/2008\r\n\r\n\r\n2008\r\n\r\n\r\n11\r\n\r\n\r\n11\r\n\r\n\r\n100\r\n\r\n\r\n40\r\n\r\n\r\n15.5\r\n\r\n\r\n2.009147\r\n\r\n\r\n2406.52\r\n\r\n\r\n\r\nHowever, there may be instances where not all metrics are desired, or there is a need for different metrics altogether. In such cases, the tempResponse function can be employed. This function is similar to chilling() but offers the flexibility to take a list of specific temperature models to be computed as input.\r\n\r\n\r\nchill_output <- tempResponse(make_JDay(Winters_hours_gaps), \r\n                       Start_JDay = 90, \r\n                       End_JDay = 100, \r\n                       models = list(Chill_Portions = Dynamic_Model, GDH = GDH))\r\n\r\n\r\n\r\n\r\nSeason\r\n\r\n\r\nEnd_year\r\n\r\n\r\nSeason_days\r\n\r\n\r\nData_days\r\n\r\n\r\nPerc_complete\r\n\r\n\r\nChill_Portions\r\n\r\n\r\nGDH\r\n\r\n\r\n2007/2008\r\n\r\n\r\n2008\r\n\r\n\r\n11\r\n\r\n\r\n11\r\n\r\n\r\n100\r\n\r\n\r\n2.009147\r\n\r\n\r\n2406.52\r\n\r\n\r\nThis will return only the Dynamic Model and Growing Degree Hours (GDH) values for the specified period.\r\nExercises on chill models\r\nRun the chilling() function on the Winters_hours_gap dataset.\r\n\r\n\r\naugust <- chilling(make_JDay(Winters_hours_gaps), Start_JDay = 214, End_JDay = 244)\r\n\r\n\r\n\r\n\r\n\r\nSeason\r\n\r\n\r\nEnd_year\r\n\r\n\r\nSeason_days\r\n\r\n\r\nData_days\r\n\r\n\r\nPerc_complete\r\n\r\n\r\nChilling_Hours\r\n\r\n\r\nUtah_Model\r\n\r\n\r\nChill_portions\r\n\r\n\r\nGDH\r\n\r\n\r\n2007/2008\r\n\r\n\r\n2008\r\n\r\n\r\n31\r\n\r\n\r\n31\r\n\r\n\r\n100\r\n\r\n\r\n0\r\n\r\n\r\n-569.5\r\n\r\n\r\n0\r\n\r\n\r\n9933.327\r\n\r\n\r\n\r\nCreate your own temperature-weighting chill model using the step_model() function.\r\n\r\n\r\ndf <- data.frame(\r\n  lower = c(-1000, 0,  5, 10, 15, 20,   25),  \r\n  upper = c(    0, 5, 10, 15, 20, 25, 1000), \r\n  weight = c(   0, 1,  2,  3,  2,  1,    0))\r\n\r\ncustom <- function(x) step_model(x, df)\r\n\r\n\r\n\r\n\r\nlower\r\n\r\n\r\nupper\r\n\r\n\r\nweight\r\n\r\n\r\n-1000\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n5\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n10\r\n\r\n\r\n2\r\n\r\n\r\n10\r\n\r\n\r\n15\r\n\r\n\r\n3\r\n\r\n\r\n15\r\n\r\n\r\n20\r\n\r\n\r\n2\r\n\r\n\r\n20\r\n\r\n\r\n25\r\n\r\n\r\n1\r\n\r\n\r\n25\r\n\r\n\r\n1000\r\n\r\n\r\n0\r\n\r\n\r\nRun this model on the Winters_hours_gaps dataset using the tempResponse() function.\r\n\r\n\r\nmodels <- list(\r\n  Chilling_Hours = Chilling_Hours,\r\n  Utah_Chill_Units = Utah_Model,\r\n  Chill_Portions = Dynamic_Model,\r\n  GDH = GDH,\r\n  custom = custom)\r\n\r\nresult <- tempResponse(make_JDay(Winters_hours_gaps), \r\n                       Start_JDay = 214, \r\n                       End_JDay = 244, \r\n                       models)\r\n\r\n\r\n\r\n\r\n\r\nSeason\r\n\r\n\r\nEnd_year\r\n\r\n\r\nSeason_days\r\n\r\n\r\nData_days\r\n\r\n\r\nPerc_complete\r\n\r\n\r\nChilling_Hours\r\n\r\n\r\nUtah_Chill_Units\r\n\r\n\r\nChill_Portions\r\n\r\n\r\nGDH\r\n\r\n\r\ncustom\r\n\r\n\r\n2007/2008\r\n\r\n\r\n2008\r\n\r\n\r\n31\r\n\r\n\r\n31\r\n\r\n\r\n100\r\n\r\n\r\n0\r\n\r\n\r\n-569.5\r\n\r\n\r\n0\r\n\r\n\r\n9933.327\r\n\r\n\r\n838\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:16:16+01:00"
    },
    {
      "path": "climate_change.html",
      "title": "Climate Change and impact projection",
      "author": [],
      "contents": "\r\nClimate change refers to long-term changes in temperatures and weather patterns. While these changes can occur naturally — such as fluctuations in solar activity — since the 19th century, climate change has primarily been driven by human activities, particularly the burning of fossil fuels like coal, oil, and natural gas.\r\nBefore using chillR, there’s a brief overview of climate change, because the upcoming work will mainly focus on predicting how global warming might affect phenology-related metrics.\r\nThe drivers of climate change\r\nTo understand what’s happening to our planet, it’s important to know the main causes of climate change. This helps us spot false claims that things like the sun, cities, or natural changes in the climate are the main reasons for global warming. The truth is simple: human-made greenhouse gas emissions are heating up our planet, and the only way to stop this is to greatly reduce these emissions.\r\nThe video below, titled Climate Change 1 - Drivers of Climate Change, is the first in a series of four videos on the topic of climate change presented by Eike Lüdeling. It provides a comprehensive overview of the primary drivers of global climate change, such as greenhouse gases, aerosols, solar radiation, ozone, and others.\r\n\r\n\r\n\r\n\r\nWhat’s already known\r\nThe next video, Climate Change 2 - Recent Warming, explores climatic changes that have already occurred or for which there is substantial evidence. It demonstrates that the planet has experienced significant warming for several decades, almost globally.\r\n\r\n\r\n\r\n\r\nFuture scenarios\r\nWhen it comes to climate change, the most severe impacts are still ahead. This is largely due to the significantly higher rate of greenhouse gas emissions observed over the past few decades, with no signs of a slowdown in the near future. As a result, the human-induced ‘forcing’ effect on our climate has reached unprecedented levels, making it likely that future changes will occur even more rapidly than those we have already witnessed. The next video Climate Change 3 - Future scenarios introduces the methods that climate scientists employ to forecast future conditions and presents climate scenarios developed by these scientists, which researchers in other fields can use to project the impacts of climate change on ecological and agricultural systems.\r\n\r\n\r\n\r\n\r\nImpact projections approaches\r\nHaving robust climate scenarios is essential, but they only take us partway toward reliable assessments of climate change impacts. A potentially greater challenge lies in translating these climate scenarios into biological consequences. To achieve this, we need impact models or other methods to derive the impacts of climate change. The last video Climate change 4 - impact projection approaches introduces various methods for projecting climate impacts.\r\n\r\n\r\n\r\n\r\nExercises on climate change\r\nList the main drivers of climate change at the decade to century scale, and briefly explain the mechanism through which the currently most important driver affects our climate.\r\nThe main drivers of climate change on a decade-to-century scale include:\r\nGreenhouse Gases (GHGs): GHGs like carbon dioxide (CO₂), methane (CH₄), and nitrous oxide (N₂O) trap heat in the atmosphere, leading to the greenhouse effect, which raises Earth’s temperature. The increase in these gases is primarily due to human activities, such as burning fossil fuels, industrial processes, and deforestation\r\nAerosols: Particles in the atmosphere that can cool the climate by reflecting sunlight. They come from both natural sources (e.g. sea salt, dust, volcanic eruptions, fires) and human activities (e.g.power plants, cars, fires and cook stove). They are major climate driver in industrial centers (e.g. China)\r\nSun: Solar radiation heats the Earth, with minor fluctuations occurring over time due to cycles in solar activity, such as sunspots. Although these variations contribute only a small portion to the current climate changes, they play a significant role in driving climate change over geological timescales\r\nOzone: Ozone in the stratosphere protects Earth from UV-B radiation, while tropospheric ozone acts as a greenhouse gas and contributes to warming\r\nSurface albedo: The reflectivity of the Earth’s surface affects how much solar energy is absorbed. Light surfaces (like ice) reflect more energy, while dark surfaces (like forests or oceans) absorb more, influencing the planet’s heat balance. Changes in surface reflectivity, such as melting ice and snow, decrease the albedo effect, leading to more heat absorption and further warming\r\nThe currently most important driver of climate change is greenhouse gases, particularly CO₂. The mechanism through which CO₂ affects the climate involves the greenhouse effect: CO₂ molecules in the atmosphere absorb long-wave radiation emitted from the Earth’s surface and re-radiate it in all directions, including back toward the surface. This process traps heat and increases global temperatures, driving many of the changes we observe in climate patterns.\r\nExplain briefly what is special about temperature dynamics of recent decades, and why we have good reasons to be concerned.\r\nIn recent decades, global temperatures have been rising at a faster rate than at any other time in human history. This trend is evident from the fact that the hottest years on record have all occurred within the last few decades. One striking example is the extreme heat in Siberia in the spring of 2020, where temperatures were up to 8°C above the recent average. This trend is particularly concerning because it is mainly driven by human activities, especially the emission of greenhouse gases. Unlike previous climate changes, which took place slowly over long periods, today’s fast rise in temperatures increases the risk of triggering dangerous effects, like melting permafrost and losing ice cover, which could make global warming even worse. Even a small increase of 1.5°C could seriously upset the balance of our climate, showing how important it is to take action against these human-caused changes.\r\nWhat does the abbreviation ‘RCP’ stand for, how are RCPs defined, and what is their role in projecting future climates?\r\nRCP stands for Representative Concentration Pathways, which are essential scenarios used in climate modeling to project potential future greenhouse gas emissions and their impacts on the climate. RCPs are defined by the level of radiative forcing — measured in watts per square meter (W/m²) — that is expected by the end of the 21st century. Each pathway corresponds to a specific amount of greenhouse gas concentrations, which can significantly influence global temperatures. The role of RCPs is to serve as inputs for climate models, helping to produce future climate scenarios, which are essential for understanding the potential impacts of climate change and planning appropriate mitigation and adaptation strategies.\r\nBriefly describe the 4 climate impact projection methods described in the fourth video.\r\nThe four climate impact projection methods described in the fourth video are:\r\nStatistical models: These models establish relationships between climate parameters and impact measures, such as crop yield. They use historical data to explain past trends and project future climate impacts. Their primary limitation is that the statistical relationships may not remain valid under future climate conditions, and they may overlook important factors\r\nSpecies Distribution Modeling: Also known as ecological niche modeling, this method predicts the future distribution of species by relating current presence or absence data to climatic parameters. However, these models may assume species are in equilibrium with the climate, which is often not the case\r\nProcess based models: These models aim to represent all major system processes using equations, capturing the scientific knowledge of processes like crop growth, phenology or hydrology. However, they are limited by the lack of complete understanding of complex systems, and often require extensive parameterization or assumptions\r\nClimate Analogue models: This method identifies current locations with climates similar to those expected in the future at another site, offering real-world examples that can guide adaptation strategies. However, they may be limited by differences in non-climatic factors and lack of suitable data, making it difficult to draw clear conditions\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:16:24+01:00"
    },
    {
      "path": "cmip5.html",
      "title": "Making CMIP5 scenarios with the ClimateWizard",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\nUsing ClimateWizard\r\nThe ClimateWizard provides access to future climate data from CMIP5 models for the RCP 4.5 and RCP 8.5 scenarios. Since the service is occasionally unavailable, malfunctions may occur. The following example shows how to retrieve data for a specific area:\r\n\r\n\r\ngetClimateWizardData(coordinates = c(longitude = 10.61, \r\n                                     latitude = 34.93),\r\n                     scenario = \"rcp45\",\r\n                     start_year = 2020,\r\n                     end_year = 2050,\r\n                     metric = c(\"CD18\", \"R02\"),\r\n                     GCMs = c(\"bcc-csm1-1\", \"BNU-ESM\"))\r\n\r\n\r\nThis code retrieves data for two climate models, an RCP scenario, and two climate metrics: cooling degree days above 18°C (“CD18”) and annual precipitation days over 0.2 mm/day (“R02”).\r\nAdaptation for Bonn\r\nInstead of the sample coordinates in Tunisia, data for Bonn should be used. All available climate models and both RCP scenarios (4.5 and 8.5) are considered. The focus is on minimum and maximum temperatures (monthly_min_max_temps). Since ClimateWizard cannot automatically download multiple scenarios, a loop is used:\r\n\r\n\r\nRCPs <- c(\"rcp45\", \r\n          \"rcp85\")\r\n\r\nTimes <- c(2050, \r\n           2085)\r\n\r\nfor(RCP in RCPs)\r\n  for(Time in Times) {\r\n    clim_scen <- getClimateWizardData(\r\n      coordinates = c(longitude = 7.143, \r\n                      latitude = 50.866),\r\n      scenario = RCP,\r\n      start_year = Time - 15,\r\n      end_year = Time + 15,\r\n      metric = \"monthly_min_max_temps\",\r\n      GCMs = \"all\")\r\n    save_temperature_scenarios(clim_scen, \"data/ClimateWizard\", paste0(\"Bonn_futures_\", Time, \"_\", RCP))\r\n  }\r\n\r\n\r\nBaseline Adjustment\r\nThe ClimateWizard database requires a 20-year baseline period between 1950 and 2005. Since weather data for Bonn is available from 1973 to 2019, the period 1975–2005 is chosen to allow a median year adjustment to 1990. This reflects current climate trends and meets database requirements.\r\nSince the observed weather data require a median year adjustment to 1996, a correction is applied:\r\n\r\n\r\nscenario_1990 <- Bonn_temps %>% temperature_scenario_from_records(1990)\r\nscenario_1996 <- Bonn_temps %>% temperature_scenario_from_records(1996)\r\n\r\nadjustment_scenario <- temperature_scenario_baseline_adjustment(\r\n  scenario_1996, \r\n  scenario_1990)\r\n\r\n\r\nTemperature Generation and Storage\r\nTo avoid repeated time-consuming data queries, the adjusted scenarios are saved.\r\n\r\n\r\nfor(RCP in RCPs)\r\n  for(Time in Times)\r\n  {\r\n    clim_scen <- load_ClimateWizard_scenarios(\r\n      \"data/climateWizard\",\r\n      paste0(\"Bonn_futures_\",\r\n             Time,\r\n             \"_\",\r\n             RCP))\r\n    \r\n    clim_scen_adjusted <-\r\n      temperature_scenario_baseline_adjustment(\r\n        baseline_temperature_scenario = adjustment_scenario,\r\n        temperature_scenario = clim_scen)\r\n    \r\n    Temps <- temperature_generation(\r\n      weather = Bonn_temps, \r\n      years = c(1973,\r\n                2019),\r\n      sim_years = c(2001,\r\n                    2101),\r\n      temperature_scenario = clim_scen_adjusted)\r\n    \r\n    save_temperature_scenarios(\r\n      Temps,\r\n      \"data/Weather_ClimateWizard\",\r\n      paste0(\"Bonn_\",\r\n             Time,\r\n             \"_\",\r\n             RCP))\r\n  }\r\n\r\n\r\nCreation of Historical Scenarios\r\nFor better analysis, historical temperature data for the years 1980, 1990, 2000, and 2010 are generated and stored:\r\n\r\n\r\nall_past_scenarios <- temperature_scenario_from_records(weather = Bonn_temps, \r\n                                                        year = c(1980, \r\n                                                                 1990, \r\n                                                                 2000, \r\n                                                                 2010))\r\n\r\nadjusted_scenarios <- temperature_scenario_baseline_adjustment(\r\n  baseline = scenario_1996, \r\n  temperature_scenario = all_past_scenarios)\r\n\r\nall_past_scenario_temps <- temperature_generation(\r\n  weather = Bonn_temps, \r\n  years = c(1973, \r\n            2019), \r\n  sim_years = c(2001, \r\n                2101), \r\n  temperature_scenario = adjusted_scenarios)\r\n\r\nsave_temperature_scenarios(all_past_scenario_temps, \"data/Weather_ClimateWizard\", \"Bonn_historic\")\r\n\r\n\r\nModeling and Calculation of Chill, Heat, and Frost Scenarios\r\nThree models are defined to calculate chill, heat, and frost hours:\r\n\r\n\r\nmodels <- list(Chill_Portions = Dynamic_Model, \r\n               GDH = GDH, \r\n               Frost_H = function(x) step_model(x, data.frame(lower=c(-1000,0),\r\n                                                              upper=c(0,1000),\r\n                                                              weight=c(1,0))))\r\n\r\n\r\nThe calculation is performed for future scenarios:\r\n\r\n\r\nchill_past_scenarios <- load_temperature_scenarios(\r\n  \"data/chill_ClimateWizard\",\r\n  \"Bonn_historic\")\r\n\r\nchill_observed <- load_temperature_scenarios(\r\n  \"data/chill_ClimateWizard\",\r\n  \"Bonn_observed\")\r\n\r\nchills <- make_climate_scenario(\r\n  chill_past_scenarios,\r\n  caption = \"Historic\",\r\n  historic_data = chill_observed,\r\n  time_series = TRUE)\r\n\r\nfor(RCP in RCPs)\r\n  for(Time in Times)\r\n    {\r\n    chill <- load_temperature_scenarios(\r\n      \"data/chill_ClimateWizard\",\r\n      paste0(\"Bonn_\",\r\n             Time,\r\n             \"_\",\r\n             RCP))\r\n    if(RCP == \"rcp45\") RCPcaption <- \"RCP4.5\"\r\n    if(RCP == \"rcp85\") RCPcaption <- \"RCP8.5\"\r\n    if(Time == \"2050\") Time_caption <- \"2050\"\r\n    if(Time == \"2085\") Time_caption <- \"2085\"\r\n    chills <- chill %>% \r\n      make_climate_scenario(\r\n        caption = c(RCPcaption,\r\n                    Time_caption),\r\n        add_to = chills)\r\n}\r\n\r\n\r\nVisualization of Results\r\nThe determined scenarios are displayed in graphs:\r\n\r\n\r\ninfo_chill <- \r\n  plot_climate_scenarios(climate_scenario_list = chills, \r\n                         metric = \"Chill_Portions\", \r\n                         metric_label = \"Chill (Chill Portions)\")\r\n\r\n\r\n\r\n\r\n\r\ninfo_heat <- \r\n  plot_climate_scenarios(climate_scenario_list = chills, \r\n                         metric = \"GDH\", \r\n                         metric_label = \"Heat (Growing Degree Hours)\")\r\n\r\n\r\n\r\n\r\n\r\ninfo_frost <- \r\n  plot_climate_scenarios(climate_scenario_list = chills, \r\n                         metric = \"Frost_H\", \r\n                         metric_label = \"Frost hours\")\r\n\r\n\r\n\r\nExercises on generating CMIP5 temperature scenarios\r\nAnalyze the historic and future impact of climate change on three agroclimatic metrics of your choice, for the location you’ve chosen for your earlier analyses.\r\n\r\n\r\n# Set baseline period and save temperature scenarios \r\nRCPs <- c(\"rcp45\",\r\n          \"rcp85\")\r\nTimes <- c(2050,\r\n           2085)\r\n\r\nfor(RCP in RCPs)\r\n  for(Time in Times)\r\n  {start_year <- Time - 15\r\n  end_year <- Time + 15\r\n  clim_scen <-\r\n    getClimateWizardData(\r\n      c(longitude = -120.539,\r\n        latitude = 46.569),\r\n      RCP,\r\n      start_year,\r\n      end_year,\r\n      temperature_generation_scenarios = TRUE,\r\n      baseline =c(1975, 2005),\r\n      metric = \"monthly_min_max_temps\",\r\n      GCMs = \"all\")\r\n  save_temperature_scenarios(clim_scen,\r\n                             \"Yakima/ClimateWizard\",\r\n                             paste0(\"Yakima_futures_\",Time,\"_\",RCP))}\r\n\r\n\r\n\r\n\r\n# Baseline adjustment\r\nscenario_1990 <- Yakima_temps %>%\r\n  temperature_scenario_from_records(1990)\r\nscenario_1998 <- Yakima_temps %>%\r\n  temperature_scenario_from_records(1998)\r\nadjustment_scenario <-\r\n  temperature_scenario_baseline_adjustment(scenario_1998,\r\n                                           scenario_1990)\r\n\r\n\r\n\r\n\r\n# Selecting RCPs and scenario years \r\nRCPs <- c(\"rcp45\",\r\n          \"rcp85\")\r\nTimes <- c(2050,\r\n           2085)\r\n\r\n\r\n\r\n\r\n# Temperature generation for future scenarios \r\nfor(RCP in RCPs)\r\n  for(Time in Times)\r\n  {\r\n    clim_scen <- load_ClimateWizard_scenarios(\r\n      \"Yakima/climateWizard\",\r\n      paste0(\"Yakima_futures_\",\r\n             Time,\r\n             \"_\",\r\n             RCP))\r\n    \r\n    clim_scen_adjusted <-\r\n      temperature_scenario_baseline_adjustment(\r\n        baseline_temperature_scenario = adjustment_scenario,\r\n        temperature_scenario = clim_scen)\r\n    \r\n    Temps <- temperature_generation(\r\n      weather = Yakima_temps, \r\n      years = c(1973,\r\n                2023),\r\n      sim_years = c(2001,\r\n                    2101),\r\n      temperature_scenario = clim_scen_adjusted)\r\n    \r\n    save_temperature_scenarios(\r\n      Temps,\r\n      \"Yakima/Weather_ClimateWizard\",\r\n      paste0(\"Yakima_\",\r\n             Time,\r\n             \"_\",\r\n             RCP))\r\n  }\r\n\r\n\r\n\r\n\r\n# Adding historic scenarios \r\nall_past_scenarios <- temperature_scenario_from_records(\r\n  weather = Yakima_temps,\r\n  year = c(1980,\r\n           1990,\r\n           2000,\r\n           2010))\r\n\r\nadjusted_scenarios <- temperature_scenario_baseline_adjustment(\r\n  baseline = scenario_1998,\r\n  temperature_scenario = all_past_scenarios)\r\n\r\nall_past_scenario_temps <- temperature_generation(\r\n  weather = Yakima_temps,\r\n  years = c(1973,\r\n            2023),\r\n  sim_years = c(2001,\r\n                2101),\r\n  temperature_scenario = adjusted_scenarios)\r\n\r\nsave_temperature_scenarios(\r\n  all_past_scenario_temps,\r\n  \"Yakima/Weather_ClimateWizard\",\r\n  \"Yakima_historic\")\r\n\r\n\r\n\r\n\r\n# Selection of models \r\nmodels <- list(Chill_Portions = Dynamic_Model, \r\n               GDH = GDH, \r\n               Frost_H = function(x) step_model(x, data.frame(lower=c(-1000,0),\r\n                                                              upper=c(0,1000),\r\n                                                              weight=c(1,0))))\r\n\r\n\r\n\r\n\r\n# Apply the models to historic data \r\nTemps <- load_temperature_scenarios(\"Yakima/Weather_ClimateWizard\",\r\n                                    \"Yakima_historic\")\r\n\r\nchill_past_scenarios <-\r\n  Temps %>%\r\n  tempResponse_daily_list(\r\n    latitude = 46.569,\r\n    Start_JDay = 305,\r\n    End_JDay = 59,\r\n    models = models,\r\n    misstolerance = 10)\r\n\r\nchill_observed <- \r\n  Yakima_temps %>%\r\n  tempResponse_daily_list(\r\n    latitude = 46.569,\r\n    Start_JDay = 305,\r\n    End_JDay = 59,\r\n    models = models,\r\n    misstolerance = 10)\r\n\r\nsave_temperature_scenarios(chill_past_scenarios,\r\n                           \"Yakima/chill_ClimateWizard\",\r\n                           \"Yakima_historic\")\r\nsave_temperature_scenarios(chill_observed,\r\n                           \"Yakima/chill_ClimateWizard\",\r\n                           \"Yakima_observed\")\r\n\r\n\r\n\r\n\r\nchill_past_scenarios <- load_temperature_scenarios(\r\n  \"Yakima/chill_ClimateWizard\",\r\n  \"Yakima_historic\")\r\nchill_observed <- load_temperature_scenarios(\r\n  \"Yakima/chill_ClimateWizard\",\r\n  \"Yakima_observed\")\r\n\r\nchills <- make_climate_scenario(\r\n  chill_past_scenarios,\r\n  caption = \"Historic\",\r\n  historic_data = chill_observed,\r\n  time_series = TRUE)\r\n\r\n# Plot climate scenarios \r\nplot_climate_scenarios(\r\n  climate_scenario_list = chills,\r\n  metric = \"Chill_Portions\",\r\n  metric_label = \"Chill (Chill Portions)\")\r\n\r\n\r\n[[1]]\r\n[1] \"time series labels\"\r\n\r\n\r\n\r\n# Add climate scenario to the chills object\r\nfor(RCP in RCPs)\r\n  for(Time in Times)\r\n    {\r\n    Temps <- load_temperature_scenarios(\r\n      \"Yakima/Weather_ClimateWizard\",\r\n      paste0(\"Yakima_\",\r\n             Time,\r\n             \"_\",\r\n             RCP))\r\n    chill <- Temps %>% \r\n      tempResponse_daily_list(\r\n        latitude = 46.569,\r\n        Start_JDay = 305,\r\n        End_JDay = 59,\r\n        models = models,\r\n        misstolerance = 10)\r\n    save_temperature_scenarios(\r\n      chill,\r\n      \"Yakima/chill_ClimateWizard\",\r\n      paste0(\"Yakima_\",\r\n             Time,\r\n             \"_\",\r\n             RCP))\r\n}\r\n\r\n\r\n\r\n\r\nfor(RCP in RCPs)\r\n  for(Time in Times)\r\n    {\r\n    chill <- load_temperature_scenarios(\r\n      \"Yakima/chill_ClimateWizard\",\r\n      paste0(\"Yakima_\",\r\n             Time,\r\n             \"_\",\r\n             RCP))\r\n    if(RCP == \"rcp45\") RCPcaption <- \"RCP4.5\"\r\n    if(RCP == \"rcp85\") RCPcaption <- \"RCP8.5\"\r\n    if(Time == \"2050\") Time_caption <- \"2050\"\r\n    if(Time == \"2085\") Time_caption <- \"2085\"\r\n    chills <- chill %>% \r\n      make_climate_scenario(\r\n        caption = c(RCPcaption,\r\n                    Time_caption),\r\n        add_to = chills)\r\n}\r\n\r\n\r\n\r\n\r\n# Plot chill hours\r\ninfo_chill <-\r\n  plot_climate_scenarios(\r\n    climate_scenario_list = chills,\r\n    metric = \"Chill_Portions\",\r\n    metric_label = \"Chill (Chill Portions)\",\r\n    texcex = 1.5)\r\n\r\n\r\n\r\n\r\n\r\n# Plot Heat (Growing degree hours)\r\ninfo_heat <-\r\n  plot_climate_scenarios(\r\n    climate_scenario_list = chills,\r\n    metric = \"GDH\",\r\n    metric_label = \"Heat (Growing Degree Hours)\",\r\n    texcex = 1.5)\r\n\r\n\r\n\r\n\r\n\r\n# Plot frost hours\r\ninfo_frost <- \r\n  plot_climate_scenarios(  \r\n    climate_scenario_list=chills,\r\n    metric=\"Frost_H\",\r\n    metric_label=\"Frost hours\",\r\n    texcex=1.5)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:16:49+01:00"
    },
    {
      "path": "cmip6.html",
      "title": "Making CMIP6 scenarios",
      "author": [],
      "contents": "\r\nAccessing Gridded Climate Data from the Copernicus Climate Data Store\r\nFuture climate data is often provided in a gridded format, making it necessary to download large datasets to extract information for a single station. While CMIP5 data was accessible through ClimateWizard, a comparable solution for CMIP6 is not available.\r\nAccessing CMIP6 Data\r\nThe Copernicus Climate Data Store (CDS) provides access to CMIP6 climate projections. A free registration is required to obtain an API key for downloading data.\r\nThe function download_cmip6_ecmwfr() allows downloading climate model data for a specified region. For example, retrieving data for Bonn (7.1°E, 50.8°N):\r\n\r\n\r\nlocation = c(7.1, 50.8)\r\narea <- c(52, 6, 50, 8) # (max. Lat, min. Lon, min. Lat, max. Lon)\r\n\r\ndownload_cmip6_ecmwfr(\r\n  scenarios = 'ssp126', \r\n  area = area,\r\n  user = 'USER_ID',\r\n  key = 'API_KEY',\r\n  model = 'default',\r\n  frequency = 'monthly',\r\n  variable = c('Tmin', 'Tmax'),\r\n  year_start = 2015,\r\n  year_end = 2100)\r\n\r\n\r\nThe data is stored in a subfolder (cmip6_downloaded). Models that lack data for the selected parameters are automatically excluded.\r\nIt is possible to download multiple climate scenarios simultaneously:\r\n\r\ndownload_cmip6_ecmwfr(\r\n  scenarios = c(\"ssp126\", \"ssp245\", \"ssp370\", \"ssp585\"), \r\n  area = area,\r\n  user = 'write user id here'\r\n  key = 'write key here',\r\n  model = 'default',\r\n  frequency = 'monthly',\r\n  variable = c('Tmin', 'Tmax'),\r\n  year_start = 2015,\r\n  year_end = 2100)\r\n\r\nGenerating Change Scenarios\r\nSince climate models use a coarse grid, it is useful to calculate temperature changes relative to a baseline period (1986-2014).\r\n\r\n\r\ndownload_baseline_cmip6_ecmwfr(\r\n  area = area,\r\n  user = 'USER_ID',\r\n  key = 'API_KEY',\r\n  model = 'match_downloaded',\r\n  frequency = 'monthly',\r\n  variable = c('Tmin', 'Tmax'),\r\n  year_start = 1986, \r\n  year_end = 2014)\r\n\r\n\r\nExtracting Data for a Specific Station\r\nThe extract_cmip6_data() function allows extracting climate data for a specific location.\r\n\r\n\r\nstation <- data.frame(\r\n  station_name = c(\"Bonn\"),\r\n  longitude = c(7.1),\r\n  latitude = c(50.8))\r\n\r\nextracted <- extract_cmip6_data(stations = station)\r\n\r\nwrite.csv(extracted$`ssp126_AWI-CM-1-1-MR`, \"data/extract_example_ssp126_AWI-CM-1-1-MR.csv\", row.names = FALSE)\r\n\r\n\r\nCalculating Relative Changes\r\nUsing the extracted data, relative climate change scenarios can be generated:\r\n\r\n\r\nchange_scenarios <- gen_rel_change_scenario(extracted)\r\nwrite.csv(change_scenarios, \"data/all_change_scenarios.csv\", row.names = FALSE)\r\n\r\n\r\nTo make the data usable for further analysis, it can be converted into a structured format:\r\n\r\n\r\nscen_list <- convert_scen_information(change_scenarios)\r\n\r\n\r\nAdjusting the Baseline for Weather Simulations\r\nIf the baseline period of the scenarios does not match observational records, an adjustment is needed.\r\nExample: Calculating the temperature trend in Bonn between 1996 and 2000:\r\n\r\n\r\ntemps_1996 <- temperature_scenario_from_records(Bonn_temps, 1996)\r\ntemps_2000 <- temperature_scenario_from_records(Bonn_temps, 2000)\r\n\r\nbase <- temperature_scenario_baseline_adjustment(temps_1996, temps_2000)\r\n\r\n\r\nNow, the baseline of the scenarios is adjusted:\r\n\r\n\r\nscen_list <- convert_scen_information(change_scenarios, give_structure = FALSE)\r\n\r\nadjusted_list <- temperature_scenario_baseline_adjustment(\r\n  base,\r\n  scen_list,\r\n  temperature_check_args = list(scenario_check_thresholds = c(-5, 15)))\r\n\r\n\r\nGenerating and Saving Climate Scenarios\r\nThe corrected climate scenarios can now be used in a weather generator:\r\n\r\n\r\ntemps <- temperature_generation(Bonn_temps, \r\n                                years = c(1973, 2019), \r\n                                sim_years = c(2001, 2100), \r\n                                adjusted_list)\r\n\r\nsave_temperature_scenarios(temps,\r\n                           \"data/future_climate\",\r\n                           \"Bonn_futuretemps\")\r\n\r\n\r\nIt’s important to save the data now to avoid waiting for the process to run again in the future. Temperature responses are calculated efficiently using the tempResponse_daily_list function, with three models: the Dynamic Model for chill accumulation, the GDH model for heat accumulation, and a simple model for frost hours.\r\n\r\n\r\nfrost_model <- function(x)\r\n  step_model(x,\r\n             data.frame(\r\n               lower = c(-1000, 0),\r\n               upper = c(0, 1000),\r\n               weight = c(1, 0)))\r\n\r\nmodels <- list(Chill_Portions = Dynamic_Model,\r\n               GDH = GDH,\r\n               Frost_H = frost_model)\r\n\r\n\r\nClimate scenarios are generated using the make_climate_scenario function and plotted. Historical and future climate scenarios are combined, and for each SSP and year (2050, 2085), the scenario is added.\r\n\r\n\r\nchill_future_scenario_list <- tempResponse_daily_list(temps,\r\n                                                    latitude = 50.8,\r\n                                                    Start_JDay = 305,\r\n                                                    End_JDay = 59,\r\n                                                    models = models)\r\n\r\nchill_future_scenario_list <- lapply(chill_future_scenario_list,\r\n                                     function(x) x %>%\r\n                                       filter(Perc_complete == 100))\r\n\r\nsave_temperature_scenarios(chill_future_scenario_list,\r\n                           \"data/future_climate\",\r\n                           \"Bonn_futurechill_305_59\")\r\n\r\n\r\nLoading Historical Data and Making Climate Scenarios\r\nHistorical climate data is loaded and used to create climate scenarios for both past and future conditions.\r\n\r\n\r\nchill_hist_scenario_list <- load_temperature_scenarios(\"data\",\r\n                                                     \"Bonn_hist_chill_305_59\")\r\n\r\nobserved_chill <- read_tab(\"data/Bonn_observed_chill_305_59.csv\")\r\n\r\nchills <- make_climate_scenario(\r\n  chill_hist_scenario_list,\r\n  caption = \"Historical\",\r\n  historic_data = observed_chill,\r\n  time_series = TRUE)\r\n\r\nplot_climate_scenarios(\r\n  climate_scenario_list = chills,\r\n  metric = \"Chill_Portions\",\r\n  metric_label = \"Chill (Chill Portions)\")\r\n\r\n\r\n\r\nProcessing Future Climate Scenarios by SSP and Time\r\nFor each SSP and time combination (2050, 2085), future climate scenarios are added to the climate scenarios object.\r\n\r\n\r\nSSPs <- c(\"ssp126\", \"ssp245\", \"ssp370\", \"ssp585\")\r\nTimes <- c(2050, 2085)\r\n\r\nlist_ssp <- \r\n  strsplit(names(chill_future_scenario_list), '\\\\.') %>%\r\n  map(2) %>%\r\n  unlist()\r\n\r\nlist_gcm <-\r\n  strsplit(names(chill_future_scenario_list), '\\\\.') %>%\r\n  map(3) %>%\r\n  unlist()\r\n\r\nlist_time <-\r\n  strsplit(names(chill_future_scenario_list), '\\\\.') %>%\r\n  map(4) %>%\r\n  unlist()\r\n\r\n\r\nfor(SSP in SSPs)\r\n  for(Time in Times)\r\n    {\r\n    \r\n    # find all scenarios for the ssp and time\r\n    chill <- chill_future_scenario_list[list_ssp == SSP & list_time == Time]\r\n    names(chill) <- list_gcm[list_ssp == SSP & list_time == Time]\r\n    if(SSP == \"ssp126\") SSPcaption <- \"SSP1\"\r\n    if(SSP == \"ssp245\") SSPcaption <- \"SSP2\"\r\n    if(SSP == \"ssp370\") SSPcaption <- \"SSP3\"\r\n    if(SSP == \"ssp585\") SSPcaption <- \"SSP5\"    \r\n    if(Time == \"2050\") Time_caption <- \"2050\"\r\n    if(Time == \"2085\") Time_caption <- \"2085\"\r\n    chills <- chill %>% \r\n      make_climate_scenario(\r\n        caption = c(SSPcaption,\r\n                    Time_caption),\r\n        add_to = chills)\r\n}\r\n\r\n\r\nPlotting and Analyzing Climate Trends\r\nFinally, the trends for chill, heat, and frost hours are visualized, and additional information is stored for later analysis.\r\n\r\n\r\ninfo_chill <- plot_climate_scenarios(\r\n  climate_scenario_list = chills,\r\n  metric = \"Chill_Portions\",\r\n  metric_label = \"Chill (Chill Portions)\",\r\n  texcex = 1.5)\r\n\r\n\r\n\r\n\r\n\r\ninfo_heat <- plot_climate_scenarios(\r\n  climate_scenario_list = chills,\r\n  metric = \"GDH\",\r\n  metric_label = \"Heat (Growing Degree Hours)\",\r\n  texcex = 1.5)\r\n\r\n\r\n\r\n\r\n\r\ninfo_frost <- plot_climate_scenarios(\r\n  climate_scenario_list = chills,\r\n  metric = \"Frost_H\",\r\n  metric_label = \"Frost hours\",\r\n  texcex = 1.5)\r\n\r\n\r\n\r\nExercises on generating CMIP6 temperature scenarios\r\nAnalyze the historic and future impact of climate change on two agroclimatic metrics of your choice, for the location you’ve chosen for your earlier analyses.\r\n\r\n\r\n# Set location\r\nlocation = c(-120.5, 46.6)\r\narea <- c(48, -122 , 45, -119)\r\n\r\n# Download scenarios \r\ndownload_cmip6_ecmwfr(\r\n  scenarios = c(\"ssp126\", \"ssp245\", \"ssp370\", \"ssp585\"), \r\n  area = c(49, -122 , 44, -118),\r\n  user = 'd78103f2-834f-468c-94f0-8b7064c75df7',\r\n  key = 'ac66d05a-e82b-42d1-9a8d-a94c1afb9fb9',\r\n  model = 'default',\r\n  frequency = 'monthly',\r\n  variable = c('Tmin', 'Tmax'),\r\n  year_start = 2015,\r\n  year_end = 2100)\r\n\r\n# Download baseline\r\ndownload_baseline_cmip6_ecmwfr(\r\n  area = c(49, -122 , 44, -118),\r\n  user = 'd78103f2-834f-468c-94f0-8b7064c75df7',\r\n  key = 'ac66d05a-e82b-42d1-9a8d-a94c1afb9fb9',\r\n  model = 'match_downloaded',\r\n  frequency = 'monthly',\r\n  variable = c('Tmin', 'Tmax'),\r\n  year_start = 1986, \r\n  year_end = 2014, \r\n  month = 1:12)\r\n\r\n# Extract data for specified location\r\nstation <- data.frame(\r\n  station_name = c(\"Yakima\"),\r\n  longitude = c(-120.5),\r\n  latitude = c(46.6))\r\n\r\nextracted <- extract_cmip6_data(stations = station,\r\n                                download_path = \"cmip6_downloaded/49_-122_44_-118\")\r\n\r\n\r\n\r\nUnzipping files\r\nExtracting downloaded CMIP6 files\r\n\r\n\r\n\r\n# Generate change scenarios\r\nchange_scenarios <- gen_rel_change_scenario(extracted)\r\n\r\n# Convert information into a list\r\nscen_list <- convert_scen_information(change_scenarios)\r\n\r\n# Calculate temperature between 1996 and 2000\r\ntemps_1996 <- temperature_scenario_from_records(Yakima_temps,\r\n                                                1996)\r\n\r\ntemps_2000 <- temperature_scenario_from_records(Yakima_temps,\r\n                                                2000)\r\n\r\n# Adjusts baseline based on observed temperature trends\r\nbase <- temperature_scenario_baseline_adjustment(temps_1996,\r\n                                                 temps_2000)\r\n\r\n# Convert scenarios \r\nscen_list <- convert_scen_information(change_scenarios, \r\n                                      give_structure = FALSE)\r\n\r\nadjusted_list <- temperature_scenario_baseline_adjustment(base,\r\n                                                          scen_list,\r\n                                                          temperature_check_args = list(scenario_check_thresholds = c(-5, 15)))\r\n\r\n\r\n\r\n\r\n# Generate temperatures \r\nfor(scen in 1:length(adjusted_list))\r\n{\r\n  if(!file.exists(paste0(\"Yakima/future_climate/Yakima_future_\",\r\n                         scen,\"_\",\r\n                         names(adjusted_list)[scen],\".csv\")) )\r\n  {temp_temp <- temperature_generation(Yakima_temps,\r\n                                       years = c(1973, 2019),\r\n                                       sim_years = c(2001, 2100),\r\n                                       adjusted_list[scen],  \r\n                                       temperature_check_args = \r\n                                         list( scenario_check_thresholds = c(-5, 15)))\r\n  write.csv(temp_temp[[1]],paste0(\"Yakima/future_climate/Yakima_future_\",scen,\"_\",names(adjusted_list)[scen],\".csv\"),\r\n            row.names=FALSE)\r\n  print(paste(\"Processed object\",scen,\"of\", length(adjusted_list)))\r\n  \r\n  \r\n  }\r\n  \r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Selection of models \r\nmodels <- list(Chill_Portions = Dynamic_Model, \r\n               GDH = GDH, \r\n               Frost_H = function(x) step_model(x, data.frame(lower=c(-1000,0),\r\n                                                              upper=c(0,1000),\r\n                                                              weight=c(1,0))))\r\n\r\n# Calculate temperature responses \r\ntemps <- load_temperature_scenarios(\"Yakima/future_climate\",\"Yakima_future_\")\r\n\r\nchill_future_scenario_list <- tempResponse_daily_list(temps,\r\n                                                      latitude = 46.6,\r\n                                                      Start_JDay = 305,\r\n                                                      End_JDay = 59,\r\n                                                      models = models)\r\n\r\nchill_future_scenario_list <- lapply(chill_future_scenario_list,\r\n                                     function(x) x %>%\r\n                                       filter(Perc_complete == 100))\r\n\r\nsave_temperature_scenarios(chill_future_scenario_list,\r\n                           \"Yakima/future_climate\",\r\n                           \"Yakima_futurechill_305_59\")\r\n\r\n\r\n\r\n\r\n# Generate climate scenarios \r\nobserved_chill <- read_tab(\"Yakima/Yakima_observed_chill_305_59.csv\")\r\nchill_hist_scenario_list <- load_temperature_scenarios(\"Yakima\",\r\n                                                       \"Yakima_hist_chill_305_59\")\r\n\r\nchills <- make_climate_scenario(\r\n  chill_hist_scenario_list,\r\n  caption = \"Historic\",\r\n  historic_data = observed_chill,\r\n  time_series = TRUE)\r\n\r\n# Plot historic climate scenarios \r\nplot_climate_scenarios(\r\n  climate_scenario_list = chills,\r\n  metric = \"Chill_Portions\",\r\n  metric_label = \"Chill (Chill Portions)\")\r\n\r\n\r\n[[1]]\r\n[1] \"time series labels\"\r\n\r\n\r\n\r\n# Identify data that belong to specific combinations of SSP and time \r\nSSPs <- c(\"ssp126\", \"ssp245\", \"ssp370\", \"ssp585\")\r\nTimes <- c(2050, 2085)\r\n\r\nlist_ssp <- \r\n  strsplit(names(chill_future_scenario_list), '\\\\.') %>%\r\n  map(2) %>%\r\n  unlist()\r\n\r\nlist_gcm <-\r\n  strsplit(names(chill_future_scenario_list), '\\\\.') %>%\r\n  map(3) %>%\r\n  unlist()\r\n\r\nlist_time <-\r\n  strsplit(names(chill_future_scenario_list), '\\\\.') %>%\r\n  map(4) %>%\r\n  unlist()\r\n\r\n\r\nfor(SSP in SSPs)\r\n  for(Time in Times)\r\n  {\r\n    \r\n    chill <- chill_future_scenario_list[list_ssp == SSP & list_time == Time]\r\n    names(chill) <- list_gcm[list_ssp == SSP & list_time == Time]\r\n    if(SSP == \"ssp126\") SSPcaption <- \"SSP1\"\r\n    if(SSP == \"ssp245\") SSPcaption <- \"SSP2\"\r\n    if(SSP == \"ssp370\") SSPcaption <- \"SSP3\"  \r\n    if(SSP == \"ssp585\") SSPcaption <- \"SSP5\"    \r\n    if(Time == \"2050\") Time_caption <- \"2050\"\r\n    if(Time == \"2085\") Time_caption <- \"2085\"\r\n    chills <- chill %>% \r\n      make_climate_scenario(\r\n        caption = c(SSPcaption,\r\n                    Time_caption),\r\n        add_to = chills)\r\n  }\r\n\r\n\r\n\r\n\r\n# Plot chill hours\r\ninfo_chill <-\r\n  plot_climate_scenarios(\r\n    climate_scenario_list = chills,\r\n    metric = \"Chill_Portions\",\r\n    metric_label = \"Chill (Chill Portions)\",\r\n    texcex = 1.5)\r\n\r\n\r\n\r\n\r\n\r\n# Plot Heat (Growing degree hours)\r\ninfo_heat <-\r\n  plot_climate_scenarios(\r\n    climate_scenario_list = chills,\r\n    metric = \"GDH\",\r\n    metric_label = \"Heat (Growing Degree Hours)\",\r\n    texcex = 1.5)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:21:28+01:00"
    },
    {
      "path": "enhanced_PLS.html",
      "title": "Experimentally enhanced PLS",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:21:34+01:00"
    },
    {
      "path": "estimate.html",
      "title": "A robust method to estimate future frost risks",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:21:39+01:00"
    },
    {
      "path": "examples.html",
      "title": "Examples of PLS regression with agroclimatic metrics",
      "author": [],
      "contents": "\r\nPLS regression across species and agroclimatic contexts\r\nSince 2012, PLS regression with agroclimatic metrics (chill and heat) has been applied in various contexts. While some researchers have adopted this approach, this chapter focuses on studies involving the author.\r\nChestnut, jujube and apricot in Beijing\r\nOne of the coldest locations where this approach was applied is Beijing, where research led by Guo Liang used bloom data for Chinese chestnut (Castanea mollissima) and jujube (Ziziphus jujuba) to define chilling and forcing periods (Guo Liang et al., 2014). Another study analyzed datasets for apricot (Prunus armeniaca) and mountain peach (Prunus davidiana), yielding the following results:\r\nResults of a PLS analysis based on the relationship between daily chill (quantified with the Dynamic Model) and heat (quantified with the GDH model) accumulation and bloom of Chinese chestnut (Castanea mollissima) in Beijing, China (Guo et al., 2014a)Results of a PLS analysis based on the relationship between daily chill (quantified with the Dynamic Model) and heat (quantified with the GDH model) accumulation and bloom of jujube (Ziziphus jujuba) in Beijing, China (Guo et al., 2014a)Results of a PLS analysis based on the relationship between daily chill (quantified with the Dynamic Model) and heat (quantified with the GDH model) accumulation and bloom of mountain peach (Prunus davidiana) in Beijing, China (Guo et al., 2014b)Results of a PLS analysis based on the relationship between daily chill (quantified with the Dynamic Model) and heat (quantified with the GDH model) accumulation and bloom of mountain peach (Prunus davidiana) in Beijing, China (Guo et al., 2014b)Results of a PLS analysis based on the relationship between daily chill (quantified with the Dynamic Model) and heat (quantified with the GDH model) accumulation and bloom of apricot (Prunus armeniaca) in Beijing, China (Guo et al., 2014b)For apricots, PLS regressions were conducted using multiple chill metrics, including Chilling Hours, the Utah Model (Chill Units), and the Dynamic Model (Chill Portions):\r\nResults of a PLS analysis based on the relationship between daily chill and heat accumulation and bloom of apricot (Prunus armeniaca) in Beijing, China. Coefficients for heat are not shown here (they are similar to what’s shown in the previous figure). Chill accumulation was quantified with the Chilling Hours Model (left), the Utah Model (middle) and the Dynamic Model (right) (Guo et al., 2015b)In all analyses of phenology records from Beijing, the forcing period was easy to delineate, but the chilling period was difficult to see.\r\nApples in Shaanxi Province, China\r\nGuo Liang also led a study on apple phenology in Shaanxi, one of China’s main apple growing provinces:\r\nResults of a PLS analysis of the relationship between chill (in Chill Portions) and heat (in GDH) and bloom dates of apple in Shaanxi, China (Guo et al., 2019)Also here the chilling phase was visible but difficult to delineate.\r\nCherries in Klein-Altendorf\r\nWinters in Beijing and Shaanxi are quite cold. A slightly warmer location was analyzed by studying cherries in Klein-Altendorf.\r\nResults of a PLS analysis of bloom dates of cherries ‘Schneiders späte Knorpelkirsche’ in Klein-Altendorf, Germany, based on chill (in Chill Portions) and heat (in GDH) accumulation (Luedeling et al., 2013a)Again, it’s pretty difficult to see the chilling period.\r\nApricots in the UK\r\nFor apricots in the UK National Fruit Collection at Brogdale Farm, Faversham, a clear chill response phase was observed in January and February. However, this period begins later than the typical expected start of chill accumulation.\r\nResults of a PLS analysis of apricot bloom in the southern UK, based on chill accumulation (in Chill Portions) and heat accumulation (in GDH) (Martı́nez-Lüscher et al., 2017)Grapevine in Croatia\r\nGrapes also have chilling requirements. Johann Johann Martínez-Lüscher, who led the UK apricot study, analyzed the temperature response of grapes grown in Croatia.\r\nResults of a PLS analysis of flowering dates of grapevine (cv. ‘Riesling Italico’) in Mandicevac, Croatia. Chill was quantified with the Dynamic Model, heat with the Growing Degree Hours Model (Martı́nez-Lüscher et al., 2016)In Croatia, where winters are warmer and chill accumulation rates are more variable, the chilling period is more distinct. Bloom response to chill is particularly strong in December and January. With a broader interpretation, the chilling period could extend from late September to February.\r\nWalnuts in California\r\nIn California, where winters are even warmer, the chilling period for walnuts was evident both from raw temperature data and when using agroclimatic metrics.\r\nResults of a PLS analysis of leaf emergence dates of walnuts (cv. ‘Payne’) in Davis, California. Chill was quantified with the Dynamic Model, heat with the Growing Degree Hours Model (Luedeling et al., 2013a)The analysis again reveals a distinct chilling period, seemingly divided into two phases. The reason for this split remains unclear and may be worth further investigation. However, a clear bloom response to high chill accumulation rates is observed between mid-October and late December.\r\nAlmonds in Tunisia\r\nSfax, in central Tunisia, represents an even warmer climate near the cultivation limit for temperate nut trees. A study led by Haïfa Benmoussa analyzed bloom data from 37 almond cultivars, successfully identifying both the chilling and forcing periods in nearly all cases. The following figures illustrate these findings.\r\nPLS results for almond cultivars near Sfax, Tunisia - part 1 (Benmoussa et al., 2017a)PLS results for almond cultivars near Sfax, Tunisia - part 2 (Benmoussa et al., 2017a)PLS results for almond cultivars near Sfax, Tunisia - part 3 (Benmoussa et al., 2017a)Pistachios in Tunisia\r\nPistachio data from the same experimental station in Sfax, Tunisia, was also analyzed. The results revealed a long chilling period with strong responses to chill accumulation rates. However, the forcing period was less distinct.\r\nPLS results for pistachios near Sfax, Tunisia (Benmoussa et al., 2017b)Exercises on examples of PLS regression with agroclimatic metrics\r\nLook across all the PLS results presented above. Can you detect a pattern in where chilling and forcing periods could be delineated clearly, and where this attempt failed?\r\nLooking at the PLS results across different locations and crops, a clear pattern emerges regarding the delineation of chilling and forcing periods:\r\nChilling Period Identification:\r\nIn colder regions like Beijing, Shaanxi, and Croatia, chilling periods were generally well-defined, often spanning from late autumn to mid-winter.\r\nIn moderately cold locations like Klein-Altendorf and Brogdale Farm (UK), chilling phases were also visible, but in some cases, they appeared later than expected.\r\nIn warm locations like Sfax (Tunisia) and California, chilling periods could still be detected, but they sometimes appeared fragmented or extended over a longer time frame.\r\n\r\nForcing Period Identification:\r\nIn most locations, forcing periods were clearly visible and followed the expected seasonal pattern.\r\nHowever, in pistachios from Sfax, the forcing phase was difficult to identify, suggesting that temperature alone may not be the primary driver of bud development in this case.\r\n\r\nThink about possible reasons for the success or failure of PLS analysis based on agroclimatic metrics. Write down your thoughts.\r\nReasons for Success or Failure of PLS Analysis:\r\nTemperature Variability:\r\nIn regions with distinct seasonal temperature changes (e.g., Beijing, Croatia), PLS was effective in identifying chilling and forcing phases\r\nIn warmer areas with mild winters (e.g., Sfax, California), chill accumulation was more gradual, leading to less distinct responses\r\n\r\nChilling Model Accuracy:\r\nDifferent crops may respond to chilling in unique ways, and the effectiveness of PLS depends on how well the selected agroclimatic metric captures the true physiological response of the plants\r\nThe Dynamic Model often provided better results than simpler models like Chilling Hours or the Utah Model\r\n\r\nThreshold Effects and Physiological Responses:\r\nIn some cases, the chilling phase appeared to consist of two parts, suggesting that additional factors (e.g., photoperiod, water availability) may influence dormancy release\r\nThe inability to detect a forcing period in pistachios suggests that heat accumulation alone might not fully explain bud development in this crop\r\n\r\nClimatic Extremes:\r\nExtremely cold winters (e.g., Beijing, Shaanxi) might lead to periods where chill accumulation is excessive, making further responses difficult to detect\r\nIn very warm climates (e.g., Sfax), chill accumulation might be insufficient in some years, causing irregular dormancy release patterns\r\n\r\n",
      "last_modified": "2025-03-11T17:21:46+01:00"
    },
    {
      "path": "future.html",
      "title": "Future temperature scenarios",
      "author": [],
      "contents": "\r\nHuman-induced climate change is already causing significant impacts on the climate, ecosystems, and agriculture. The situation is expected to worsen, driven by high levels of greenhouse gases and ongoing emissions (about 40 Gt CO2-equivalents annually). Ecosystem degradation further weakens the planet’s resilience. Future outcomes are uncertain, but climate change adaptation research aims to reduce uncertainties by focusing on exposure, sensitivity, and adaptive capacity.\r\nFramework for Climate Vulnerability and Adaptation\r\nThe conceptual framework for evaluating climate vulnerability and adaptation involves:\r\nExposure: The anticipated future climate conditions.\r\nSensitivity: How ecosystems or systems respond to those conditions.\r\nAdaptive Capacity: The ability of systems to adapt to climate change.\r\nCombining exposure and sensitivity helps estimate potential impacts, while adaptation efforts work to reduce sensitivity (e.g., using resilient cultivars) or enhance adaptive capacity (e.g., flexible management strategies). Current research mainly focuses on exposure, particularly in areas like orchards. While some models account for tree sensitivity, these analyses are largely centered around exposure factors.\r\nFuture Climate Scenarios and Modeling\r\nDeveloping future climate scenarios requires precise climate model setups, including Global Climate Models (GCMs), Regional Climate Models (RCMs), and downscaling, with no single “correct” approach. The chillR package can use both high-quality and less accurate climate scenarios, facilitating access to reliable databases even for users without expert knowledge.\r\nBackground on Climate Models and Warming Pathways\r\nUp until November 2023, ClimateWizard was the best source for climate data in chillR, providing point-specific climate data from various models. ClimateWizard simplifies data retrieval for specific locations, bypassing large-scale datasets that could otherwise create bottlenecks. However, its data is based on older climate models (CMIP5) and outdated Representative Concentration Pathways (RCPs), which are becoming less reliable. The newer CMIP6 models and Shared Socioeconomic Pathways (SSPs), released in 2021, provide a more modern approach for accurate climate projections and are now the recommended scenarios for climate change modeling. While ClimateWizard still supports CMIP5 and RCP scenarios, transitioning to CMIP6 and SSP scenarios is crucial for the most up-to-date and accurate climate change projections.\r\nExercises on future temperature scenarios\r\nBriefly describe the differences between the RCPs and the SSPs (you may have to follow some of the links provided above).\r\nThe Representative Concentration Pathways (RCPs) and the Shared Socioeconomic Pathways (SSPs) are both scenario frameworks used for modeling future climate developments, but they differ in their methodology and focus.\r\nRCPs (Representative Concentration Pathways):\r\nDeveloped for the IPCC’s 5th Assessment Report (AR5, published in 2014).\r\nDescribe different possible levels of radiative forcing (W/m²) by 2100, meaning the direct effect of greenhouse gas emissions on the climate.\r\nFour main pathways: RCP2.6 (strong emissions reduction), RCP4.5 and RCP6.0 (moderate emissions), RCP8.5 (very high emissions, often referred to as “business as usual”).\r\nA purely climate-science-based approach without considering socioeconomic developments.\r\n\r\nSSPs (Shared Socioeconomic Pathways):\r\nDeveloped for the IPCC’s 6th Assessment Report (AR6, published in 2021).\r\nCombine socioeconomic developments with emission pathways to create different future scenarios.\r\nFive main scenarios (SSP1 to SSP5), representing various societal, economic, and political trajectories, such as sustainable development (SSP1) or continued reliance on fossil fuels (SSP5).\r\nCan be combined with different radiative forcing levels (e.g., SSP1-2.6 for sustainable development with low emissions or SSP5-8.5 for high emissions and fossil fuel dependence).\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:21:51+01:00"
    },
    {
      "path": "gaps.html",
      "title": "Filling gaps in temperature records",
      "author": [],
      "contents": "\r\nWeather data often contains gaps due to equipment malfunctions, power outages, or storage problems. These gaps create challenges for modeling agroclimatic conditions, requiring effective gap-filling methods.\r\nFilling Short Gaps in Daily Records\r\nFor short gaps (2-3 days), linear interpolation estimates missing values by averaging the last known and first known values around the gap. The chillR package provides the interpolate_gaps() function for this:\r\n\r\n\r\nweather <- KA_weather %>% make_all_day_table()\r\n\r\nTmin_int <- interpolate_gaps(weather[,\"Tmin\"])\r\nweather <- weather %>% mutate(Tmin = Tmin_int$interp, Tmin_interpolated = Tmin_int$missing)\r\n\r\nTmax_int <- interpolate_gaps(weather[,\"Tmax\"])\r\nweather <- weather %>% mutate(Tmax = Tmax_int$interp, Tmax_interpolated = Tmax_int$missing)\r\n\r\nKA_weather_gap <- rbind(KA_weather, c(Year = 2011,\r\n                                      Month = 3,\r\n                                      Day = 3,\r\n                                      Tmax = 26,\r\n                                      Tmin = 14)) \r\n\r\n\r\nThe fix_weather() function can also be used to fill gaps:\r\n\r\n\r\nfixed_winter_days <- KA_weather_gap %>% fix_weather(start_year = 2000, \r\n                                                    end_year = 2011, \r\n                                                    start_date = 300, \r\n                                                    end_date = 100)\r\nfixed_all_days <- KA_weather_gap %>% fix_weather()\r\n\r\n\r\nThe function returns a weather dataframe with interpolated data and a QC object summarizing interpolation quality:\r\n\r\n\r\nfixed_winter_days$QC\r\n\r\n\r\n\r\n\r\n\r\nSeason\r\n\r\n\r\nEnd_year\r\n\r\n\r\nSeason_days\r\n\r\n\r\nData_days\r\n\r\n\r\nMissing_Tmin\r\n\r\n\r\nMissing_Tmax\r\n\r\n\r\nIncomplete_days\r\n\r\n\r\nPerc_complete\r\n\r\n\r\n1999/2000\r\n\r\n\r\n2000\r\n\r\n\r\n166\r\n\r\n\r\n100\r\n\r\n\r\n66\r\n\r\n\r\n66\r\n\r\n\r\n66\r\n\r\n\r\n60.2\r\n\r\n\r\n2000/2001\r\n\r\n\r\n2001\r\n\r\n\r\n167\r\n\r\n\r\n167\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2001/2002\r\n\r\n\r\n2002\r\n\r\n\r\n166\r\n\r\n\r\n166\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2002/2003\r\n\r\n\r\n2003\r\n\r\n\r\n166\r\n\r\n\r\n166\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2003/2004\r\n\r\n\r\n2004\r\n\r\n\r\n166\r\n\r\n\r\n166\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2004/2005\r\n\r\n\r\n2005\r\n\r\n\r\n167\r\n\r\n\r\n167\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2005/2006\r\n\r\n\r\n2006\r\n\r\n\r\n166\r\n\r\n\r\n166\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2006/2007\r\n\r\n\r\n2007\r\n\r\n\r\n166\r\n\r\n\r\n166\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2007/2008\r\n\r\n\r\n2008\r\n\r\n\r\n166\r\n\r\n\r\n166\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2008/2009\r\n\r\n\r\n2009\r\n\r\n\r\n167\r\n\r\n\r\n167\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2009/2010\r\n\r\n\r\n2010\r\n\r\n\r\n166\r\n\r\n\r\n166\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2010/2011\r\n\r\n\r\n2011\r\n\r\n\r\n166\r\n\r\n\r\n128\r\n\r\n\r\n165\r\n\r\n\r\n165\r\n\r\n\r\n165\r\n\r\n\r\n0.6\r\n\r\n\r\n\r\n\r\n\r\nfixed_all_days$QC\r\n\r\n\r\n\r\n\r\n\r\nSeason\r\n\r\n\r\nEnd_year\r\n\r\n\r\nSeason_days\r\n\r\n\r\nData_days\r\n\r\n\r\nMissing_Tmin\r\n\r\n\r\nMissing_Tmax\r\n\r\n\r\nIncomplete_days\r\n\r\n\r\nPerc_complete\r\n\r\n\r\n1997/1998\r\n\r\n\r\n1998\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n1998/1999\r\n\r\n\r\n1999\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n1999/2000\r\n\r\n\r\n2000\r\n\r\n\r\n366\r\n\r\n\r\n366\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2000/2001\r\n\r\n\r\n2001\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2001/2002\r\n\r\n\r\n2002\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2002/2003\r\n\r\n\r\n2003\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2003/2004\r\n\r\n\r\n2004\r\n\r\n\r\n366\r\n\r\n\r\n366\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2004/2005\r\n\r\n\r\n2005\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2005/2006\r\n\r\n\r\n2006\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2006/2007\r\n\r\n\r\n2007\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2007/2008\r\n\r\n\r\n2008\r\n\r\n\r\n366\r\n\r\n\r\n366\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2008/2009\r\n\r\n\r\n2009\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100.0\r\n\r\n\r\n2009/2010\r\n\r\n\r\n2010\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n214\r\n\r\n\r\n214\r\n\r\n\r\n214\r\n\r\n\r\n41.4\r\n\r\n\r\n2010/2011\r\n\r\n\r\n2011\r\n\r\n\r\n365\r\n\r\n\r\n62\r\n\r\n\r\n364\r\n\r\n\r\n364\r\n\r\n\r\n364\r\n\r\n\r\n0.3\r\n\r\n\r\n\r\nA plot illustrates the effect of gap length on interpolation accuracy:\r\n\r\n\r\ngap_weather <- KA_weather[200:305, ]\r\ngap_weather[ ,\"Tmin_observed\"] <- gap_weather$Tmin\r\ngap_weather$Tmin[c(2, 4:5, 7:9, 11:14, 16:20, 22:27, 29:35, \r\n                   37:44, 46:54, 56:65, 67:77, 79:90, 92:104)] <- NA\r\nfixed_gaps <- fix_weather(gap_weather)$weather\r\n\r\nggplot(data = fixed_gaps, aes(DATE, Tmin_observed)) +\r\n  geom_line(lwd = 1.3) +\r\n  xlab(\"Date\") +\r\n  ylab(\"Daily minimum temperature (°C)\") +\r\n  geom_line(data = fixed_gaps, aes(DATE, Tmin), col = \"red\", lwd = 1.3)\r\n\r\n\r\n\r\nInterpolation errors increase with gap size:\r\n\r\n\r\nfixed_gaps[,\"error\"] <- abs(fixed_gaps$Tmin - fixed_gaps$Tmin_observed)\r\n\r\nggplot(data = fixed_gaps, aes(DATE, error)) +\r\n  geom_line(lwd = 1.3) +\r\n  xlab(\"Date\") +\r\n  ylab(\"Error introduced by interpolation (°C)\") +\r\n  geom_point(data = fixed_gaps[which(!fixed_gaps$no_Tmin),], aes(DATE, error), col = \"red\", cex = 3)\r\n\r\n\r\n\r\nFilling Long Gaps in Daily Records\r\nFor long gaps, data from nearby weather stations is used. The patch_weather() function in chillR helps with this:\r\n\r\n\r\n\r\n\r\n\r\nstation_list <- handle_gsod(action = \"list_stations\",\r\n                            location = c(7.10, 50.73),\r\n                            time_interval = c(1990, 2020))\r\n\r\n\r\nRelevant stations are downloaded:\r\n\r\n\r\n\r\n\r\n\r\npatch_weather <- \r\n  handle_gsod(action = \"download_weather\", \r\n              location = as.character(station_list$chillR_code[c(2, 3, 6)]), \r\n              time_interval = c(1990, 2020)) %>% \r\n  handle_gsod()\r\n\r\n\r\nGaps are filled using patch_daily_temperatures():\r\n\r\n\r\npatched <- patch_daily_temperatures(weather = Bonn, patch_weather = patch_weather)\r\n\r\n\r\nPatch statistics are examined:\r\n\r\n\r\npatched$statistics[[1]]\r\n\r\n\r\n\r\n\r\n\r\n\r\nmean_bias\r\n\r\n\r\nstdev_bias\r\n\r\n\r\nfilled\r\n\r\n\r\ngaps_remain\r\n\r\n\r\nTmin\r\n\r\n\r\n-0.307\r\n\r\n\r\n1.304\r\n\r\n\r\n2146\r\n\r\n\r\n1\r\n\r\n\r\nTmax\r\n\r\n\r\n0.202\r\n\r\n\r\n1.154\r\n\r\n\r\n2146\r\n\r\n\r\n1\r\n\r\n\r\n\r\n\r\npatched$statistics[[2]]\r\n\r\n     mean_bias stdev_bias filled gaps_remain\r\nTmin    -1.871      2.080      0           1\r\nTmax     1.466      1.427      0           1\r\n\r\n\r\n\r\n\r\n\r\nmean_bias\r\n\r\n\r\nstdev_bias\r\n\r\n\r\nfilled\r\n\r\n\r\ngaps_remain\r\n\r\n\r\nTmin\r\n\r\n\r\n-1.871\r\n\r\n\r\n2.080\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\nTmax\r\n\r\n\r\n1.466\r\n\r\n\r\n1.427\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\n\r\n\r\npatched$statistics[[3]]\r\n\r\n     mean_bias stdev_bias filled gaps_remain\r\nTmin    -0.546      1.186      0           1\r\nTmax     1.314      1.089      0           1\r\n\r\n\r\n\r\n\r\n\r\nmean_bias\r\n\r\n\r\nstdev_bias\r\n\r\n\r\nfilled\r\n\r\n\r\ngaps_remain\r\n\r\n\r\nTmin\r\n\r\n\r\n-0.546\r\n\r\n\r\n1.186\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\nTmax\r\n\r\n\r\n1.314\r\n\r\n\r\n1.089\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\nTo improve accuracy, mean bias and standard deviation bias limits are set:\r\n\r\n\r\npatched <- patch_daily_temperatures(weather = Bonn, \r\n                                    patch_weather = patch_weather, \r\n                                    max_mean_bias = 1, \r\n                                    max_stdev_bias = 2)\r\n\r\n\r\nFinal gaps are identified:\r\n\r\n\r\npost_patch_stats <- fix_weather(patched)$QC\r\n\r\n\r\nRemaining short gaps are filled with interpolation:\r\n\r\n\r\nBonn_weather <- fix_weather(patched)\r\n\r\n\r\nFor seasonally adjusted bias correction, patch_daily_temps() is used:\r\n\r\n\r\npatched_monthly <- patch_daily_temps(weather = Bonn, \r\n                                     patch_weather = patch_weather, \r\n                                     max_mean_bias = 1, \r\n                                     max_stdev_bias = 2, \r\n                                     time_interval = \"month\")\r\n\r\n\r\nThis function allows for interval-based bias corrections:\r\n\r\n\r\npatched_2weeks <- patch_daily_temps(weather = Bonn, \r\n                                    patch_weather = patch_weather, \r\n                                    max_mean_bias = 1, \r\n                                    max_stdev_bias = 2, \r\n                                    time_interval = \"2 weeks\")\r\n\r\n\r\nUsing finer time intervals improves bias correction accuracy, but requires sufficient data for reliability.\r\nExercises on filling gaps\r\nUse chillR functions to find out how many gaps you have in your dataset (even if you have none, please still follow all further steps)\r\n\r\n\r\nYakima <- read.csv(\"Yakima/Yakima_chillR_weather.csv\")\r\nYakima_QC <- fix_weather(Yakima)$QC\r\n\r\n\r\n\r\n\r\n\r\nSeason\r\n\r\n\r\nEnd_year\r\n\r\n\r\nSeason_days\r\n\r\n\r\nData_days\r\n\r\n\r\nMissing_Tmin\r\n\r\n\r\nMissing_Tmax\r\n\r\n\r\nIncomplete_days\r\n\r\n\r\nPerc_complete\r\n\r\n\r\n1989/1990\r\n\r\n\r\n1990\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n1990/1991\r\n\r\n\r\n1991\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n1991/1992\r\n\r\n\r\n1992\r\n\r\n\r\n366\r\n\r\n\r\n366\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n1992/1993\r\n\r\n\r\n1993\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n1993/1994\r\n\r\n\r\n1994\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n1994/1995\r\n\r\n\r\n1995\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n1995/1996\r\n\r\n\r\n1996\r\n\r\n\r\n366\r\n\r\n\r\n366\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n1996/1997\r\n\r\n\r\n1997\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n1997/1998\r\n\r\n\r\n1998\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n1998/1999\r\n\r\n\r\n1999\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n1999/2000\r\n\r\n\r\n2000\r\n\r\n\r\n366\r\n\r\n\r\n366\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2000/2001\r\n\r\n\r\n2001\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2001/2002\r\n\r\n\r\n2002\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2002/2003\r\n\r\n\r\n2003\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2003/2004\r\n\r\n\r\n2004\r\n\r\n\r\n366\r\n\r\n\r\n366\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2004/2005\r\n\r\n\r\n2005\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2005/2006\r\n\r\n\r\n2006\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2006/2007\r\n\r\n\r\n2007\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2007/2008\r\n\r\n\r\n2008\r\n\r\n\r\n366\r\n\r\n\r\n366\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2008/2009\r\n\r\n\r\n2009\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2009/2010\r\n\r\n\r\n2010\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2010/2011\r\n\r\n\r\n2011\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2011/2012\r\n\r\n\r\n2012\r\n\r\n\r\n366\r\n\r\n\r\n366\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2012/2013\r\n\r\n\r\n2013\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2013/2014\r\n\r\n\r\n2014\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2014/2015\r\n\r\n\r\n2015\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2015/2016\r\n\r\n\r\n2016\r\n\r\n\r\n366\r\n\r\n\r\n366\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2016/2017\r\n\r\n\r\n2017\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2017/2018\r\n\r\n\r\n2018\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2018/2019\r\n\r\n\r\n2019\r\n\r\n\r\n365\r\n\r\n\r\n365\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n2019/2020\r\n\r\n\r\n2020\r\n\r\n\r\n366\r\n\r\n\r\n366\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n100\r\n\r\n\r\n\r\nCreate a list of the 25 closest weather stations using the handle_gsod function\r\n\r\n\r\nstation_list_Yakima <- handle_gsod(action = \"list_stations\",\r\n                                   location = c(long = -120.50, lat = 46.60),\r\n                                   time_interval = c(1990, 2020))\r\n\r\n\r\n\r\n\r\n\r\nchillR_code\r\n\r\n\r\nSTATION.NAME\r\n\r\n\r\nCTRY\r\n\r\n\r\nLat\r\n\r\n\r\nLong\r\n\r\n\r\nBEGIN\r\n\r\n\r\nEND\r\n\r\n\r\nDistance\r\n\r\n\r\nOverlap_years\r\n\r\n\r\nPerc_interval_covered\r\n\r\n\r\n72781024243\r\n\r\n\r\nYAKIMA AIR TERMINAL/MCALSR FIELD AP\r\n\r\n\r\nUS\r\n\r\n\r\n46.564\r\n\r\n\r\n-120.535\r\n\r\n\r\n19730101\r\n\r\n\r\n20250304\r\n\r\n\r\n4.82\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n99999924243\r\n\r\n\r\nYAKIMA AIR TERMINAL\r\n\r\n\r\nUS\r\n\r\n\r\n46.568\r\n\r\n\r\n-120.543\r\n\r\n\r\n19480101\r\n\r\n\r\n19721231\r\n\r\n\r\n4.85\r\n\r\n\r\n0.00\r\n\r\n\r\n0\r\n\r\n\r\n72781399999\r\n\r\n\r\nVAGABOND AAF / YAKIMA TRAINING CENTER WASHINGTON USA\r\n\r\n\r\nUS\r\n\r\n\r\n46.667\r\n\r\n\r\n-120.454\r\n\r\n\r\n20030617\r\n\r\n\r\n20081110\r\n\r\n\r\n8.25\r\n\r\n\r\n5.40\r\n\r\n\r\n17\r\n\r\n\r\n72056299999\r\n\r\n\r\nRANGE OP 13 / YAKIMA TRAINING CENTER\r\n\r\n\r\nUS\r\n\r\n\r\n46.800\r\n\r\n\r\n-120.167\r\n\r\n\r\n20080530\r\n\r\n\r\n20170920\r\n\r\n\r\n33.79\r\n\r\n\r\n9.31\r\n\r\n\r\n30\r\n\r\n\r\n72788399999\r\n\r\n\r\nBOWERS FLD\r\n\r\n\r\nUS\r\n\r\n\r\n47.033\r\n\r\n\r\n-120.531\r\n\r\n\r\n20000101\r\n\r\n\r\n20031231\r\n\r\n\r\n48.26\r\n\r\n\r\n4.00\r\n\r\n\r\n13\r\n\r\n\r\n72788324220\r\n\r\n\r\nBOWERS FIELD AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n47.034\r\n\r\n\r\n-120.531\r\n\r\n\r\n19880106\r\n\r\n\r\n20250304\r\n\r\n\r\n48.37\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n99999924220\r\n\r\n\r\nELLENSBURG BOWERS FI\r\n\r\n\r\nUS\r\n\r\n\r\n47.034\r\n\r\n\r\n-120.530\r\n\r\n\r\n19480601\r\n\r\n\r\n19550101\r\n\r\n\r\n48.37\r\n\r\n\r\n0.00\r\n\r\n\r\n0\r\n\r\n\r\n72784094187\r\n\r\n\r\nHANFORD AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n46.567\r\n\r\n\r\n-119.600\r\n\r\n\r\n20060101\r\n\r\n\r\n20130326\r\n\r\n\r\n68.96\r\n\r\n\r\n7.23\r\n\r\n\r\n23\r\n\r\n\r\n72784099999\r\n\r\n\r\nHANFORD\r\n\r\n\r\nUS\r\n\r\n\r\n46.567\r\n\r\n\r\n-119.600\r\n\r\n\r\n19730101\r\n\r\n\r\n19971231\r\n\r\n\r\n68.96\r\n\r\n\r\n8.00\r\n\r\n\r\n26\r\n\r\n\r\n72782594239\r\n\r\n\r\nPANGBORN MEMORIAL AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n47.397\r\n\r\n\r\n-120.201\r\n\r\n\r\n20000101\r\n\r\n\r\n20250304\r\n\r\n\r\n91.58\r\n\r\n\r\n21.00\r\n\r\n\r\n68\r\n\r\n\r\n72782599999\r\n\r\n\r\nPANGBORN MEM\r\n\r\n\r\nUS\r\n\r\n\r\n47.399\r\n\r\n\r\n-120.207\r\n\r\n\r\n19730101\r\n\r\n\r\n19971231\r\n\r\n\r\n91.69\r\n\r\n\r\n8.00\r\n\r\n\r\n26\r\n\r\n\r\n72788499999\r\n\r\n\r\nRICHLAND AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n46.306\r\n\r\n\r\n-119.304\r\n\r\n\r\n19810203\r\n\r\n\r\n20250303\r\n\r\n\r\n97.39\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n72781524237\r\n\r\n\r\nSTAMPASS PASS FLTWO\r\n\r\n\r\nUS\r\n\r\n\r\n47.277\r\n\r\n\r\n-121.337\r\n\r\n\r\n19730101\r\n\r\n\r\n20250304\r\n\r\n\r\n98.63\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n99999924237\r\n\r\n\r\nSTAMPEDE PASS\r\n\r\n\r\nUS\r\n\r\n\r\n47.277\r\n\r\n\r\n-121.337\r\n\r\n\r\n19480101\r\n\r\n\r\n19721231\r\n\r\n\r\n98.63\r\n\r\n\r\n0.00\r\n\r\n\r\n0\r\n\r\n\r\n72790024141\r\n\r\n\r\nEPHRATA MUNICIPAL AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n47.308\r\n\r\n\r\n-119.516\r\n\r\n\r\n20050101\r\n\r\n\r\n20250304\r\n\r\n\r\n108.64\r\n\r\n\r\n16.00\r\n\r\n\r\n52\r\n\r\n\r\n72782624141\r\n\r\n\r\nEPHRATA MUNICIPAL\r\n\r\n\r\nUS\r\n\r\n\r\n47.308\r\n\r\n\r\n-119.515\r\n\r\n\r\n19420101\r\n\r\n\r\n19971231\r\n\r\n\r\n108.69\r\n\r\n\r\n8.00\r\n\r\n\r\n26\r\n\r\n\r\n99999924141\r\n\r\n\r\nEPHRATA AP FCWOS\r\n\r\n\r\nUS\r\n\r\n\r\n47.308\r\n\r\n\r\n-119.515\r\n\r\n\r\n19480101\r\n\r\n\r\n19550101\r\n\r\n\r\n108.69\r\n\r\n\r\n0.00\r\n\r\n\r\n0\r\n\r\n\r\n72782724110\r\n\r\n\r\nGRANT COUNTY INTL AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n47.193\r\n\r\n\r\n-119.315\r\n\r\n\r\n19430610\r\n\r\n\r\n20250304\r\n\r\n\r\n111.73\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n72782799999\r\n\r\n\r\nMOSES LAKE/GRANT CO\r\n\r\n\r\nUS\r\n\r\n\r\n47.200\r\n\r\n\r\n-119.317\r\n\r\n\r\n20000101\r\n\r\n\r\n20031231\r\n\r\n\r\n112.06\r\n\r\n\r\n4.00\r\n\r\n\r\n13\r\n\r\n\r\n72784524163\r\n\r\n\r\nTRI-CITIES AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n46.270\r\n\r\n\r\n-119.118\r\n\r\n\r\n19730101\r\n\r\n\r\n20250304\r\n\r\n\r\n112.21\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n72784599999\r\n\r\n\r\nTRI CITIES\r\n\r\n\r\nUS\r\n\r\n\r\n46.267\r\n\r\n\r\n-119.117\r\n\r\n\r\n20000101\r\n\r\n\r\n20031231\r\n\r\n\r\n112.40\r\n\r\n\r\n4.00\r\n\r\n\r\n13\r\n\r\n\r\n99999924163\r\n\r\n\r\nPASCO NAS\r\n\r\n\r\nUS\r\n\r\n\r\n46.267\r\n\r\n\r\n-119.117\r\n\r\n\r\n19450401\r\n\r\n\r\n19460601\r\n\r\n\r\n112.40\r\n\r\n\r\n0.00\r\n\r\n\r\n0\r\n\r\n\r\n72698824219\r\n\r\n\r\nMUNICIPAL AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n45.619\r\n\r\n\r\n-121.166\r\n\r\n\r\n19730101\r\n\r\n\r\n20250304\r\n\r\n\r\n120.70\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n99999924219\r\n\r\n\r\nTHE DALLES MUNICIPAL ARPT\r\n\r\n\r\nUS\r\n\r\n\r\n45.619\r\n\r\n\r\n-121.166\r\n\r\n\r\n19480101\r\n\r\n\r\n19650101\r\n\r\n\r\n120.70\r\n\r\n\r\n0.00\r\n\r\n\r\n0\r\n\r\n\r\n72688399999\r\n\r\n\r\nHERMISTON MUNI\r\n\r\n\r\nUS\r\n\r\n\r\n45.828\r\n\r\n\r\n-119.259\r\n\r\n\r\n19980514\r\n\r\n\r\n20051231\r\n\r\n\r\n128.55\r\n\r\n\r\n7.64\r\n\r\n\r\n25\r\n\r\n\r\n\r\nIdentify suitable weather stations for patching gaps\r\nDownload weather data for promising stations, convert them to chillR format and compile them in a list\r\n\r\n\r\n\r\n\r\n\r\npatch_weather <-\r\n  handle_gsod(action = \"download_weather\",\r\n              location = as.character(station_list_Yakima$chillR_code[c(4, 6, 8)]),\r\n              time_interval = c(1990, 2020)) %>%\r\n  handle_gsod()\r\n\r\n\r\nUse the patch_daily_temperatures function to fill gaps\r\n\r\n\r\npatched <- patch_daily_temperatures(weather = Yakima,\r\n                                    patch_weather = patch_weather)\r\n\r\n\r\n\r\n\r\n# Patch statistics for YRANGE OP 13 /AKIMA TRAINING CENTER\r\npatched$statistics[[1]]\r\n\r\n\r\n\r\n\r\n\r\n\r\nmean_bias\r\n\r\n\r\nstdev_bias\r\n\r\n\r\nfilled\r\n\r\n\r\ngaps_remain\r\n\r\n\r\nTmin\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nTmax\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\n\r\n\r\n# Patch statistics for HANFORD AIRPORT\r\npatched$statistics[[2]]\r\n\r\n     mean_bias stdev_bias filled gaps_remain\r\nTmin        NA         NA     NA          NA\r\nTmax        NA         NA     NA          NA\r\n\r\n\r\n\r\n\r\n\r\nmean_bias\r\n\r\n\r\nstdev_bias\r\n\r\n\r\nfilled\r\n\r\n\r\ngaps_remain\r\n\r\n\r\nTmin\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nTmax\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\n\r\n\r\n# Patch statistics for BOWERS FIELD AIRPORT\r\npatched$statistics[[3]]\r\n\r\n     mean_bias stdev_bias filled gaps_remain\r\nTmin        NA         NA     NA          NA\r\nTmax        NA         NA     NA          NA\r\n\r\n\r\n\r\n\r\n\r\nmean_bias\r\n\r\n\r\nstdev_bias\r\n\r\n\r\nfilled\r\n\r\n\r\ngaps_remain\r\n\r\n\r\nTmin\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nTmax\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nNA\r\n\r\n\r\nInvestigate the results - have all gaps been filled?\r\n\r\n\r\nwrite.csv(patched$weather,\r\n          \"Yakima/Yakima_weather.csv\", row.names = FALSE)\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:23:04+01:00"
    },
    {
      "path": "generate_temp.html",
      "title": "Generating temperature scenarios",
      "author": [],
      "contents": "\r\nEffective orchard management requires understanding local climate conditions, especially chill availability, to make informed decisions on tree species and cultivars. While historical weather data has been useful, orchard managers now need more tailored, site-specific forecasts, especially regarding chill and heat levels, to optimize planting decisions.\r\nChill Scenarios\r\nThe key objective is to provide growers with reliable forecasts for chill availability, helping them select the right trees. Climate conditions like chill and heat accumulation must be predicted over the long term, beyond simple historical data. This enables better decision-making when considering tree species that will meet their specific climatic needs and cope with potential frost risks.\r\nRisk Assessment in Orchard Planning\r\nBecause trees have long lifespans, they experience different weather patterns throughout their productive years. For optimal yields, trees must consistently meet their climatic requirements each year. Orchard managers need to understand the full range of possible weather scenarios, ensuring that chosen trees will meet their chill requirements and avoid frost damage. This requires assessing the distribution of local climate data, as opposed to relying on a single year’s data.\r\nWeather Generators\r\nThe best way to assess the local climate is through long-term weather data. Weather generators model these patterns and simulate realistic weather conditions to help in orchard planning. chillR uses the R-compatible weather generator RMAWGEN for simulating temperature data, which is crucial for modeling chill availability.\r\nWeather Generation in chillR\r\nTo generate temperature data, chillR uses the RMAWGEN weather generator. The function temperature_generation is used to calibrate long-term temperature data, and it produces simulated temperature records that can be used to evaluate climate patterns over extended periods.\r\n\r\n\r\nTemp <- KA_weather %>%\r\n  temperature_generation(years = c(1998, 2009),\r\n                         sim_years = c(2001, 2100))\r\n\r\nTemperatures <- KA_weather %>% filter(Year %in% 1998:2009) %>%\r\n  cbind(Data_source = \"observed\") %>%\r\n  rbind(\r\n    Temp[[1]] %>% select(c(Year,\r\n                           Month,\r\n                           Day,\r\n                           Tmin,\r\n                           Tmax)) %>%\r\n      cbind(Data_source = \"simulated\")\r\n  ) %>%\r\n  mutate(Date = as.Date(ISOdate(2000,\r\n                                Month,\r\n                                Day)))\r\n\r\n\r\nTemperature Visualization\r\nTo compare observed and simulated temperature data, ggplot2 is used to visualize smoothed temperature trends, allowing for clearer analysis of temperature patterns.\r\n\r\n\r\nggplot(data = Temperatures,\r\n       aes(Date, Tmin)) +\r\n  geom_smooth(aes(colour = factor(Year))) +\r\n  facet_wrap(vars(Data_source)) +\r\n  theme_bw(base_size = 20) +\r\n  theme(legend.position = \"none\") +\r\n  scale_x_date(date_labels = \"%b\")\r\n\r\n\r\n\r\n\r\n\r\nggplot(data=Temperatures,\r\n       aes(Date, Tmax)) +\r\n  geom_smooth(aes(colour = factor(Year))) +\r\n  facet_wrap(vars(Data_source)) +\r\n  theme_bw(base_size = 20) +\r\n  theme(legend.position = \"none\") +\r\n  scale_x_date(date_labels = \"%b\")\r\n\r\n\r\n\r\nChill Comparison\r\nNext, chill accumulation is analyzed by comparing observed and simulated chill data using the stack_hourly_temps and chilling functions. This helps in assessing the chill accumulation over multiple years.\r\n\r\n\r\nchill_observed <- Temperatures %>%\r\n  filter(Data_source == \"observed\") %>%\r\n  stack_hourly_temps(latitude = 50.4) %>%\r\n  chilling(Start_JDay = 305,\r\n           End_JDay = 59)\r\n\r\nchill_simulated <- Temperatures %>%\r\n  filter(Data_source == \"simulated\") %>%\r\n  stack_hourly_temps(latitude = 50.4) %>%\r\n  chilling(Start_JDay = 305,\r\n           End_JDay = 59)\r\n\r\nchill_comparison <-\r\n  cbind(chill_observed,\r\n        Data_source = \"observed\") %>%\r\n  rbind(cbind(chill_simulated,\r\n              Data_source = \"simulated\"))\r\n\r\n\r\nChill Distribution Visualization\r\nThe distribution of chill accumulation is visualized using a histogram to compare observed and simulated chill portions.\r\n\r\n\r\nggplot(chill_comparison_full_seasons,\r\n       aes(x = Chill_portions)) + \r\n  geom_histogram(binwidth = 1,\r\n                 aes(fill = factor(Data_source))) +\r\n  theme_bw(base_size = 20) +\r\n  labs(fill = \"Data source\") +\r\n  xlab(\"Chill accumulation (Chill Portions)\") +\r\n  ylab(\"Frequency\")\r\n\r\n\r\n\r\nCumulative Distribution Function\r\nA cumulative distribution function (CDF) is plotted to visualize the likelihood of meeting the required chill accumulation thresholds.\r\n\r\n\r\nchill_simulations <-\r\n  chill_comparison_full_seasons %>%\r\n  filter(Data_source == \"simulated\")\r\n\r\nggplot(chill_simulations,\r\n       aes(x = Chill_portions)) +\r\n  stat_ecdf(geom = \"step\",\r\n            lwd = 1.5,\r\n            col = \"blue\") +\r\n  ylab(\"Cumulative probability\") +\r\n  xlab(\"Chill accumulation (in Chill Portions)\") +\r\n  theme_bw(base_size = 20)\r\n\r\n\r\n\r\nQuantiles for Safe Winter Chill\r\nSpecific quantiles of chill accumulation are calculated to assess “Safe Winter Chill” levels and the risk associated with not meeting chilling requirements.\r\n\r\n\r\n# 10% quantile (Safe Winter Chill)\r\nquantile(chill_simulations$Chill_portions, 0.1)\r\n\r\n     10% \r\n77.28649 \r\n\r\n# 50% confidence interval (25th to 75th percentile)\r\nquantile(chill_simulations$Chill_portions, c(0.25, 0.75))\r\n\r\n     25%      75% \r\n79.76791 84.23847 \r\n\r\nExercises on temperature generation\r\nFor the location you chose for your earlier analyses, use chillR’s weather generator to produce 100 years of synthetic temperature data.\r\n\r\n\r\n\r\n\r\n\r\n# Generate temperature data with temperature_generation function\r\nTemp <- Yakima %>% \r\n  temperature_generation(years = c(1998, 2009),\r\n                         sim_years = c(2001, 2100))\r\n\r\nTemperatures <- Yakima %>% \r\n  select(Year, Month, Day, Tmin, Tmax) %>%  \r\n  filter(Year %in% 1998:2009) %>%\r\n  cbind(Data_source = \"observed\") %>%\r\n  rbind(\r\n    Temp[[1]] %>% select(c(Year, Month, Day, Tmin, Tmax)) %>% \r\n      cbind(Data_source = \"simulated\")\r\n  ) %>%\r\n  mutate(Date = as.Date(ISOdate(2000, Month, Day)))\r\n\r\n\r\n\r\n\r\n# Plot observed vs. simulated minimum temperature data\r\nggplot(data = Temperatures,\r\n       aes(Date,\r\n           Tmin)) +\r\n  geom_smooth(aes(colour = factor(Year))) +\r\n  facet_wrap(vars(Data_source)) +\r\n  theme_bw(base_size = 20) +\r\n  theme(legend.position = \"none\") +\r\n  scale_x_date(date_labels = \"%b\")\r\n\r\n\r\n\r\n\r\n\r\n# Plot observed vs. simulated maximum temperature data\r\nggplot(data = Temperatures,\r\n       aes(Date,\r\n           Tmax)) +\r\n  geom_smooth(aes(colour = factor(Year))) +\r\n  facet_wrap(vars(Data_source)) +\r\n  theme_bw(base_size = 20) +\r\n  theme(legend.position = \"none\") +\r\n  scale_x_date(date_labels = \"%b\")\r\n\r\n\r\n\r\nCalculate winter chill (in Chill Portions) for your synthetic weather, and illustrate your results as histograms and cumulative distributions.\r\n\r\n\r\n# Analyzing chill accumulation by comparing observed and simulated chill data using the stack_hourly_temps function\r\nchill_observed <- Temperatures %>%\r\n  filter(Data_source == \"observed\") %>%\r\n  stack_hourly_temps(latitude = 46.6) %>%\r\n  chilling(Start_JDay = 305,\r\n           End_JDay = 59)\r\n  \r\nchill_simulated <- Temperatures %>%\r\n  filter(Data_source == \"simulated\") %>%\r\n  stack_hourly_temps(latitude = 46.6) %>%\r\n  chilling(Start_JDay = 305,\r\n           End_JDay = 59)\r\n  \r\nchill_comparison <-\r\n  cbind(chill_observed,\r\n        Data_source = \"observed\") %>%\r\n  rbind(cbind(chill_simulated,\r\n              Data_source = \"simulated\"))\r\n\r\nchill_comparison_full_seasons <- \r\n  chill_comparison %>%\r\n  filter(Perc_complete == 100)\r\n\r\n\r\n\r\n\r\n# Plot chill distribution as histogram\r\nggplot(chill_comparison_full_seasons,\r\n       aes(x = Chill_portions)) + \r\n  geom_histogram(binwidth = 1,\r\n                 aes(fill = factor(Data_source))) +\r\n  theme_bw(base_size = 20) +\r\n  labs(fill = \"Data source\") +\r\n  xlab(\"Chill accumulation (Chill Portions)\") +\r\n  ylab(\"Frequency\")\r\n\r\n\r\n\r\n\r\n\r\nchill_simulations <-\r\n  chill_comparison_full_seasons %>%\r\n  filter(Data_source == \"simulated\")\r\n  \r\n# Plot chill distribution as cumulative distribution\r\nggplot(chill_simulations,\r\n       aes(x = Chill_portions)) +\r\n  stat_ecdf(geom = \"step\",\r\n            lwd = 1.5,\r\n            col = \"blue\") +\r\n  ylab(\"Cumulative probability\") +\r\n  xlab(\"Chill accumulation (in Chill Portions)\") +\r\n  theme_bw(base_size = 20)\r\n\r\n\r\n\r\nProduce similar plots for the number of freezing hours (<0°C) in April (or October, if your site is in the Southern Hemisphere) for your location of interest\r\n\r\n\r\ndf <- data.frame(\r\n  lower =  c(-1000,    0),\r\n  upper =  c(    0, 1000),\r\n  weight = c(    1,    0))\r\n\r\nfreezing_hours <- function(x) step_model(x, df)\r\n\r\nchill_observed <- Temperatures %>%\r\n  filter(Data_source == \"observed\") %>%\r\n  stack_hourly_temps(latitude = 46.6) %>%\r\n  tempResponse(Start_JDay = 91,\r\n               End_JDay = 120,\r\n               models = list(Frost = freezing_hours,\r\n                             Chill_portions = Dynamic_Model,\r\n                             GDH = GDH))\r\n\r\nchill_simulated <- Temperatures %>%\r\n  filter(Data_source == \"simulated\") %>%\r\n  stack_hourly_temps(latitude = 46.6) %>%\r\n  tempResponse(Start_JDay = 91,\r\n               End_JDay = 120,\r\n               models=list(Frost = freezing_hours,\r\n                           Chill_portions = Dynamic_Model,\r\n                           GDH = GDH))\r\n\r\nchill_comparison <-\r\n  cbind(chill_observed,\r\n        Data_source = \"observed\") %>%\r\n  rbind(cbind(chill_simulated,\r\n              Data_source = \"simulated\"))\r\n\r\nchill_comparison_full_seasons <-\r\n  chill_comparison %>%\r\n  filter(Perc_complete == 100)\r\n\r\n\r\n\r\n\r\n# Plot chill distribution in April as histogram \r\nggplot(chill_comparison_full_seasons,\r\n       aes(x = Frost)) + \r\n  geom_histogram(binwidth = 25,\r\n                 aes(fill = factor(Data_source))) +\r\n  theme_bw(base_size = 10) +\r\n  labs(fill = \"Data source\") +\r\n  xlab(\"Frost incidence during April (hours)\") +\r\n  ylab(\"Frequency\")\r\n\r\n\r\n\r\n\r\n\r\nchill_simulations <-\r\n  chill_comparison_full_seasons %>%\r\n  filter(Data_source == \"simulated\")\r\n\r\n# Plot chill distribution in April as cumulative distribution \r\nggplot(chill_simulations,\r\n       aes(x = Frost)) +\r\n  stat_ecdf(geom = \"step\",\r\n            lwd = 1.5,\r\n            col = \"blue\") +\r\n  ylab(\"Cumulative probability\") +\r\n  xlab(\"Frost incidence during April (hours)\") +\r\n  theme_bw(base_size = 20)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:25:38+01:00"
    },
    {
      "path": "getting_started.html",
      "title": "Learning goals and tools used in the Module",
      "author": [],
      "contents": "\r\nLearning goals\r\nThe content begins with an introduction to phenology (with a special emphasis on dormancy) as well as an overview of climate change. It then focuses heavily on the practical application of the chillR package for R. This tool has been continuously developed since 2013 by Prof. Dr. Eike Lüdeling, head of the HortiBonn research group at the Institute of Crop Science and Resource Conservation (INRES) at the University of Bonn, to support this type of analysis.\r\nThis course will offer the following skills and experiences:\r\nKnowledge about phenology\r\nKnowledge about tree dormancy\r\nUnderstanding of climate change impact projection methods\r\nAppreciation for the importance of risks and uncertainty in climate change projection\r\nUnderstanding of how to use some staple tools of R code development\r\nAbility to use chillR functions for climate change impact projection\r\nAbility to use chillR functions for tree phenology analysis\r\nUnderstanding and ability to use the PhenoFlex dormancy analysis framework\r\nTools\r\nThis course is designed to provide knowledge about tree phenology, climate change, and related topics, along with hands-on exercises to demonstrate the functionalities of the chillR package. It is recommended to document everything learned in a learning logbook. To engage in these practical components effectively, various tools are required. Since chillR is an R package, using R, preferably through the RStudio interface, will be necessary.\r\nAlthough it is possible to run RStudio on a local computer and save files directly on the hard drive, this approach differs from the methods commonly used by professional programmers. To align with standard programming practices, familiarity with certain code development tools is essential. This course will therefore cover the basics of using Git and GitHub, which are valuable tools for organizing, securing, and sharing code. Additionally, proper documentation techniques in R will be introduced, focusing on creating well-structured, professional reports using RMarkdown. While these tools may seem complex at first, their usefulness is likely to become clearer as they are used throughout the module.\r\nDr. Cory Whitney, a researcher at HortiBonn, has volunteered to create tutorial videos to provide an introduction to these tools.\r\nR and RStudio\r\nThe first video Using R and RStudio demonstrates how to install and run R and RStudio:\r\n\r\n\r\n\r\n\r\nGit and Github\r\nThe next video Using Git and Github explores the programming version control environment Git and the interface GitHub, which is used to access these features:\r\n\r\n\r\n\r\n\r\nRmarkdown\r\nIn the last video Using R Mardown, R Markdown will be examined, a powerful tool that enables the creation of sophisticated reports, websites, and more from R code:\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:25:48+01:00"
    },
    {
      "path": "historic.html",
      "title": "Historic temperature scenearios",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\nGenerating Climate Scenarios with chillR\r\nA weather generator in the chillR package can create agroclimatic profiles for specific locations. By calibrating it with historical temperature data, the generated profile represents the climate of the calibration period. This generator also simulates future climate scenarios using the temperature_scenario parameter in the temperature_generation function.\r\nDefining a Temperature Scenario\r\nThe temperature_scenario parameter requires a data.frame with two columns (Tmin and Tmax), each containing 12 values representing monthly temperature adjustments. Without this parameter, no temperature changes are applied.\r\nA simple scenario increasing temperatures by 2°C in all months is created as follows:\r\n\r\n\r\nchange_scenario <- data.frame(Tmin = rep(2, 12), Tmax = rep(2, 12))\r\n\r\nTemp_2 <- temperature_generation(KA_weather,\r\n                                 years = c(1998, 2005),\r\n                                 sim_years = c(2001, 2100),\r\n                                 temperature_scenario = change_scenario)\r\n\r\n\r\nComparing Observed and Simulated Temperatures\r\nA dataset is created to compare observed and simulated temperatures:\r\n\r\n\r\nTemperature_scenarios <- KA_weather %>%\r\n  filter(Year %in% 1998:2005) %>%\r\n  cbind(Data_source = \"observed\") %>%\r\n  rbind(Temp[[1]] %>% \r\n          select(c(Year, Month, Day, Tmin, Tmax)) %>% \r\n          cbind(Data_source = \"simulated\")\r\n        ) %>%\r\n  rbind(Temp_2[[1]] %>%\r\n          select(c(Year, Month, Day, Tmin, Tmax)) %>% \r\n          cbind(Data_source = \"Warming_2C\")\r\n        ) %>%\r\n  mutate(Date = as.Date(ISOdate(2000,\r\n                                Month,\r\n                                Day)))\r\n\r\n\r\nThese scenarios can be visualized using ggplot2:\r\n\r\n\r\nggplot(data = Temperature_scenarios, \r\n       aes(Date, Tmin)) +\r\n  geom_smooth(aes(colour = factor(Year))) +\r\n  facet_wrap(vars(Data_source)) +\r\n  theme_bw(base_size = 20) +\r\n  theme(legend.position = \"none\") +\r\n  scale_x_date(date_labels = \"%b\")\r\n\r\n\r\n\r\n\r\n\r\nggplot(data = Temperature_scenarios,\r\n       aes(Date,Tmax)) +\r\n  geom_smooth(aes(colour = factor(Year))) +\r\n  facet_wrap(vars(Data_source)) +\r\n  theme_bw(base_size = 20) +\r\n  theme(legend.position = \"none\") +\r\n  scale_x_date(date_labels = \"%b\")\r\n\r\n\r\n\r\nThis simplified approach applies uniform changes across all months, which does not reflect historical patterns but aligns with early climate modeling methods.\r\nCreating Historical Temperature Scenarios\r\nA long-term dataset is necessary to generate historical climate scenarios. Weather data for Cologne/Bonn Airport is downloaded and formatted for chillR:\r\n\r\n\r\nstation_list <- handle_gsod(action = \"list_stations\", location = c(7.1, 50.8))\r\nBonn_weather <- handle_gsod(action = \"download_weather\",\r\n                            location = station_list$chillR_code[1],\r\n                            time_interval = c(1973, 2019)) %>%\r\n  handle_gsod()\r\n\r\n\r\nMissing data is identified and interpolated:\r\n\r\n\r\nBonn_patched <- patch_daily_temperatures(weather = Bonn_weather$`KOLN BONN`,\r\n                                         patch_weather = list(KA_weather))\r\n\r\nBonn <- fix_weather(Bonn_patched)\r\n\r\nBonn_temps <- Bonn$weather\r\n\r\n\r\nGenerating Scenarios for Specific Years\r\nHistorical temperature scenarios for years like 1980, 1990, 2000, and 2010 are created:\r\n\r\n\r\nscenario_1980 <- temperature_scenario_from_records(weather = Bonn_temps, \r\n                                                   year = 1980)\r\n\r\n\r\nThe scenario is refined by setting a reference year (1996) and adjusting accordingly:\r\n\r\n\r\nscenario_1996 <- temperature_scenario_from_records(weather = Bonn_temps, \r\n                                                   year = 1996)\r\n\r\nrelative_scenario <- temperature_scenario_baseline_adjustment(\r\n  baseline = scenario_1996, \r\n  temperature_scenario = scenario_1980)\r\n\r\n\r\nThis adjusted scenario is used to generate temperature projections:\r\n\r\n\r\ntemps_1980 <- temperature_generation(weather = Bonn_temps,\r\n                                     years = c(1973, 2019),\r\n                                     sim_years = c(2001, 2100),\r\n                                     temperature_scenario = relative_scenario)\r\n\r\n\r\nThe process is repeated for multiple years:\r\n\r\n\r\nall_past_scenarios <- temperature_scenario_from_records(\r\n  weather = Bonn_temps, \r\n  year = c(1980, \r\n           1990, \r\n           2000, \r\n           2010))\r\n\r\nadjusted_scenarios <- temperature_scenario_baseline_adjustment(\r\n  baseline = scenario_1996, \r\n  temperature_scenario = all_past_scenarios)\r\n\r\nall_past_scenario_temps <- temperature_generation(\r\n  weather = Bonn_temps,\r\n  years = c(1973, 2019),\r\n  sim_years = c(2001, 2100),\r\n  temperature_scenario = adjusted_scenarios)\r\n\r\n\r\nThe generated data is saved for future use:\r\n\r\n\r\nsave_temperature_scenarios(all_past_scenario_temps, \"data\", \"Bonn_hist_scenarios\")\r\n\r\n\r\nEstimating Chill Accumulation\r\nUsing the tempResponse_daily_list function, chill accumulation can be estimated:\r\n\r\n\r\nchill_hist_scenario_list <- tempResponse_daily_list(all_past_scenario_temps,\r\n                                                    latitude = 50.9,\r\n                                                    Start_JDay = 305,\r\n                                                    End_JDay = 59,\r\n                                                    models = models)\r\n\r\n\r\nObserved chill data is computed and saved:\r\n\r\n\r\nscenarios <- names(chill_hist_scenario_list)[1:4]\r\n\r\nall_scenarios <- chill_hist_scenario_list[[scenarios[1]]] %>%\r\n  mutate(scenario = as.numeric(scenarios[1]))\r\n\r\nfor (sc in scenarios[2:4])\r\n all_scenarios <- all_scenarios %>%\r\n  rbind(chill_hist_scenario_list[[sc]] %>%\r\n          cbind(\r\n            scenario=as.numeric(sc))\r\n        ) %>%\r\n  filter(Perc_complete == 100)\r\n\r\nactual_chill <- tempResponse_daily_list(Bonn_temps,\r\n                                        latitude=50.9,\r\n                                        Start_JDay = 305,\r\n                                        End_JDay = 59,\r\n                                        models)[[1]] %>%\r\n  filter(Perc_complete == 100)\r\n\r\nwrite.csv(actual_chill, \"data/Bonn_observed_chill_305_59.csv\", row.names = FALSE)\r\n\r\n\r\nVisualizing Chill Accumulation Scenarios\r\n\r\n\r\nggplot(data = all_scenarios, aes(scenario, Chill_Portions, fill = factor(scenario))) +\r\n  geom_violin() +\r\n  ylab(\"Chill accumulation (Chill Portions)\") +\r\n  xlab(\"Scenario year\") +\r\n  theme_bw(base_size = 15) +\r\n  ylim(c(0,90)) +\r\n  geom_point(data = actual_chill, aes(End_year, Chill_Portions, fill = \"blue\"), col = \"blue\", show.legend = FALSE) +\r\n  scale_fill_discrete(name = \"Scenario\", breaks = unique(all_scenarios$scenario))\r\n\r\n\r\n\r\nComparing Running Mean and Linear Regression Approaches\r\nThe running mean and linear regression methods are compared to estimate long-term trends:\r\n\r\n\r\ntemperature_means <- \r\n  data.frame(Year = min(Bonn_temps$Year):max(Bonn_temps$Year),\r\n             Tmin = aggregate(Bonn_temps$Tmin,\r\n                              FUN = \"mean\",\r\n                              by = list(Bonn_temps$Year))[,2],\r\n             Tmax=aggregate(Bonn_temps$Tmax,\r\n                            FUN = \"mean\",\r\n                            by = list(Bonn_temps$Year))[,2]) %>%\r\n  mutate(runn_mean_Tmin = runn_mean(Tmin,15),\r\n         runn_mean_Tmax = runn_mean(Tmax,15))\r\n\r\nTmin_regression <- lm(Tmin~Year, temperature_means)\r\nTmax_regression <- lm(Tmax~Year, temperature_means)\r\n\r\ntemperature_means <- temperature_means %>%\r\n  mutate(regression_Tmin = Tmin_regression$coefficients[1]+\r\n           Tmin_regression$coefficients[2]*temperature_means$Year,\r\n           regression_Tmax = Tmax_regression$coefficients[1]+\r\n           Tmax_regression$coefficients[2]*temperature_means$Year\r\n         )\r\n\r\n# Plot mean monthly minimum temperature \r\nggplot(temperature_means,\r\n       aes(Year,\r\n           Tmin)) + \r\n  geom_point() + \r\n  geom_line(data = temperature_means,\r\n            aes(Year,\r\n                runn_mean_Tmin),\r\n            lwd = 2,\r\n            col = \"blue\") + \r\n  geom_line(data = temperature_means,\r\n            aes(Year,\r\n                regression_Tmin),\r\n            lwd = 2,\r\n            col = \"red\") +\r\n  theme_bw(base_size = 15) +\r\n  ylab(\"Mean monthly minimum temperature (°C)\")\r\n\r\n\r\n\r\n\r\n\r\n# Plot mean monthly maximum temperature\r\nggplot(temperature_means,\r\n       aes(Year,\r\n           Tmax)) + \r\n  geom_point() + \r\n  geom_line(data = temperature_means,\r\n            aes(Year,\r\n                runn_mean_Tmax),\r\n            lwd = 2,\r\n            col = \"blue\") + \r\n  geom_line(data = temperature_means,\r\n            aes(Year, \r\n                regression_Tmax),\r\n            lwd = 2,\r\n            col = \"red\") +\r\n  theme_bw(base_size = 15) +\r\n  ylab(\"Mean monthly maximum temperature (°C)\")\r\n\r\n\r\n\r\nThese methods yield different results, highlighting variations in trend estimation as climate change progresses. This comparison underscores the importance of selecting appropriate methods for temperature trend analysis.\r\nExercises on generating historic temperature scenarios\r\nFor the location you chose for previous exercises, produce historic temperature scenarios representing several years of the historic record (your choice).\r\n\r\n\r\n\r\n\r\n\r\n# Get a list of close-by weather stations\r\nstation_list <- handle_gsod(action = \"list_stations\",\r\n                            location = c(long = -120.5, lat = 46.6),\r\n                            time_interval = c(1973, 2023))\r\n\r\n\r\n# Download data\r\nYakima_weather <- handle_gsod(action = \"download_weather\",\r\n                            location = station_list$chillR_code[1],\r\n                            time_interval = c(1973, 2023)) %>%\r\n  handle_gsod()\r\n\r\n\r\n# Check record for missing data\r\nfix_weather(Yakima_weather$`YAKIMA AIR TERMINAL/MCALSR FIELD AP`)$QC\r\n\r\n\r\n# Filling gaps in temperature records\r\npatch_weather <-\r\n  handle_gsod(action = \"download_weather\",\r\n              location = as.character(station_list$chillR_code[c(4, 6)]),\r\n              time_interval = c(1973, 2023)) %>%\r\n  handle_gsod()\r\n\r\n\r\nYakima_patched <- patch_daily_temperatures(\r\n  weather = Yakima_weather$`YAKIMA AIR TERMINAL/MCALSR FIELD AP`,\r\n  patch_weather = patch_weather)\r\n\r\nfix_weather(Yakima_patched)$QC\r\n\r\nYakima_temps <- Yakima_patched$weather\r\n\r\n\r\n\r\n\r\n# Generating running mean and linear regression \r\ntemperature_means <- \r\n  data.frame(Year = min(Yakima_temps$Year):max(Yakima_temps$Year),\r\n             Tmin = aggregate(Yakima_temps$Tmin,\r\n                              FUN = \"mean\",\r\n                              by = list(Yakima_temps$Year))[,2],\r\n             Tmax=aggregate(Yakima_temps$Tmax,\r\n                            FUN = \"mean\",\r\n                            by = list(Yakima_temps$Year))[,2]) %>%\r\n  mutate(runn_mean_Tmin = runn_mean(Tmin,15),\r\n         runn_mean_Tmax = runn_mean(Tmax,15))\r\n\r\n\r\nTmin_regression <- lm(Tmin~Year,\r\n                      temperature_means)\r\n\r\nTmax_regression <- lm(Tmax~Year,\r\n                      temperature_means)\r\n\r\ntemperature_means <- temperature_means %>%\r\n  mutate(regression_Tmin = Tmin_regression$coefficients[1]+\r\n           Tmin_regression$coefficients[2]*temperature_means$Year,\r\n         regression_Tmax = Tmax_regression$coefficients[1]+\r\n           Tmax_regression$coefficients[2]*temperature_means$Year\r\n  )\r\n\r\n\r\n\r\n\r\n# Plot mean monthly minimum temperature of 1973 to 2023\r\nggplot(temperature_means,\r\n       aes(Year,\r\n           Tmin)) + \r\n  geom_point() + \r\n  geom_line(data = temperature_means,\r\n            aes(Year,\r\n                runn_mean_Tmin),\r\n            lwd = 2,\r\n            col = \"blue\") + \r\n  geom_line(data = temperature_means,\r\n            aes(Year,\r\n                regression_Tmin),\r\n            lwd = 2,\r\n            col = \"red\") +\r\n  theme_bw(base_size = 15) +\r\n  ylab(\"Mean monthly minimum temperature (°C)\")\r\n\r\n\r\n\r\n\r\n\r\n# Plot mean monthly maximum temperature of 1973 to 2023\r\nggplot(temperature_means,\r\n       aes(Year,\r\n           Tmax)) + \r\n  geom_point() + \r\n  geom_line(data = temperature_means,\r\n            aes(Year,\r\n                runn_mean_Tmax),\r\n            lwd = 2,\r\n            col = \"blue\") + \r\n  geom_line(data = temperature_means,\r\n            aes(Year, \r\n                regression_Tmax),\r\n            lwd = 2,\r\n            col = \"red\") +\r\n  theme_bw(base_size = 15) +\r\n  ylab(\"Mean monthly maximum temperature (°C)\")\r\n\r\n\r\n\r\nProduce chill distributions for these scenarios and plot them.\r\n\r\n\r\n# Generating scenarios for specific years \r\nscenario_1980 <- temperature_scenario_from_records(weather = Yakima_temps,\r\n                                                   year = 1980)\r\n\r\ntemps_1980 <- temperature_generation(weather = Yakima_temps,\r\n                                     years = c(1973, 2023),\r\n                                     sim_years = c(2001, 2100),\r\n                                     temperature_scenario = scenario_1980)\r\n\r\n# Setting a reference year (1998)\r\nscenario_1998 <- temperature_scenario_from_records(weather = Yakima_temps,\r\n                                                   year = 1998)\r\n\r\nrelative_scenario <- temperature_scenario_baseline_adjustment(\r\n  baseline = scenario_1998,\r\n  temperature_scenario = scenario_1980)\r\n\r\n# Adjusted scenario is used to generate temperature projections\r\ntemps_1980 <- temperature_generation(weather = Yakima_temps,\r\n                                   years = c(1973, 2023),\r\n                                   sim_years = c(2001,2100),\r\n                                   temperature_scenario = relative_scenario)\r\n\r\n# Process is repeated for multiple years \r\nall_past_scenarios <- temperature_scenario_from_records(\r\n  weather = Yakima_temps,\r\n  year = c(1980,\r\n           1990,\r\n           2000,\r\n           2010, \r\n           2020))\r\n\r\nadjusted_scenarios <- temperature_scenario_baseline_adjustment(\r\n  baseline = scenario_1998,\r\n  temperature_scenario = all_past_scenarios)\r\n\r\nall_past_scenario_temps <- temperature_generation(\r\n  weather = Yakima_temps,\r\n  years = c(1973, 2023),\r\n  sim_years = c(2001, 2100),\r\n  temperature_scenario = adjusted_scenarios)\r\n\r\n# Generated data is saved for future use \r\nsave_temperature_scenarios(all_past_scenario_temps, \"Yakima\", \"Yakima_hist_scenarios\")\r\n\r\n\r\n\r\n\r\n# Selecting models for evaluation \r\nfrost_model <- function(x)\r\n  step_model(x,\r\n             data.frame(\r\n               lower = c(-1000, 0),\r\n               upper = c(0, 1000),\r\n               weight = c(1, 0)))\r\n\r\nmodels <- list(Chill_Portions = Dynamic_Model, \r\n               GDH = GDH,\r\n               Frost_H = frost_model)\r\n\r\n# Using tempResponse_daily_list function to estimate chill accumulation\r\nchill_hist_scenario_list <- tempResponse_daily_list(all_past_scenario_temps,\r\n                                                    latitude = 46.6,\r\n                                                    Start_JDay = 305,\r\n                                                    End_JDay = 59,\r\n                                                    models = models)\r\n\r\nchill_hist_scenario_list <- lapply(chill_hist_scenario_list,\r\n                                   function(x) x %>%\r\n                                     filter(Perc_complete == 100))\r\n\r\n# Save generated chill data \r\nsave_temperature_scenarios(chill_hist_scenario_list, \"Yakima\",\"Yakima_hist_chill_305_59\")\r\n\r\n\r\n\r\n\r\n# Load generated chill data for Yakima\r\nchill_hist_scenario_list <- load_temperature_scenarios(\"Yakima\",\"Yakima_hist_chill_305_59\")\r\n\r\n# Compute the actual 'observed' chill for comparison\r\nscenarios <- names(chill_hist_scenario_list)[1:5]\r\n\r\nall_scenarios <- chill_hist_scenario_list[[scenarios[1]]] %>%\r\n  mutate(scenario = as.numeric(scenarios[1]))\r\n\r\nfor (sc in scenarios[2:5])\r\n  all_scenarios <- all_scenarios %>%\r\n  rbind(chill_hist_scenario_list[[sc]] %>%\r\n          cbind(\r\n            scenario=as.numeric(sc))\r\n  ) %>%\r\n  filter(Perc_complete == 100)\r\n\r\nactual_chill <- tempResponse_daily_list(Yakima_temps,\r\n                                        latitude=46.6,\r\n                                        Start_JDay = 305,\r\n                                        End_JDay = 59,\r\n                                        models)[[1]] %>%\r\n  filter(Perc_complete == 100)\r\n\r\n\r\n\r\n\r\n# Visualize chill accumulation \r\nggplot(data = all_scenarios,\r\n       aes(scenario,\r\n           Chill_Portions,\r\n           fill = factor(scenario))) +\r\n  geom_violin() +\r\n  ylab(\"Chill accumulation (Chill Portions)\") +\r\n  xlab(\"Scenario year\") +\r\n  theme_bw(base_size = 15) +\r\n  ylim(c(0,90)) +\r\n  geom_point(data = actual_chill,\r\n             aes(End_year,\r\n                 Chill_Portions,\r\n                 fill = \"blue\"),\r\n             col = \"blue\",\r\n             show.legend = FALSE) +\r\n  scale_fill_discrete(name = \"Scenario\",\r\n                      breaks = unique(all_scenarios$scenario)) \r\n\r\n\r\n\r\n\r\n\r\n# Save observed chill data for Yakima\r\nwrite.csv(actual_chill,\"Yakima/Yakima_observed_chill_305_59.csv\", row.names = FALSE)\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:26:56+01:00"
    },
    {
      "path": "index.html",
      "title": "Tree phenology analysis with R",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          Jacqueline Wingen\r\n          \r\n          \r\n          Home\r\n          Getting Started\r\n          \r\n          \r\n          Lessons\r\n           \r\n          ▾\r\n          \r\n          \r\n          Tree dormancy\r\n          Climate change and impact projection\r\n          Winter chill projections\r\n          Manual chill\r\n          Chill models\r\n          Making hourly temperatures\r\n          Useful tools in R\r\n          Getting temperature data\r\n          Filling gaps in temperature records\r\n          Generating temperature scenarios\r\n          Saving and loading data\r\n          Historic temperature scenarios\r\n          Future temperature scenarios\r\n          Making CMIP6 scenarios\r\n          Making CMIP5 scenarios with the ClimateWizard\r\n          Plotting future scenarios\r\n          Chill model comparison\r\n          Simple phenology analysis\r\n          Delineating temperature response phases with PLS regression\r\n          Successes and limitations of PLS regression analysis\r\n          PLS regression with agroclimatic metrics\r\n          Examples of PLS regression with agroclimatic metrics\r\n          Why PLS doesn’t always work\r\n          Evaluating PLS outputs\r\n          The relative importance of chill and heat\r\n          Experimentally enhanced PLS\r\n          Making valid tree phenology models\r\n          The PhenoFlex model\r\n          The PhenoFlex model - a second look\r\n          Can we improve the performance of PhenoFlex?\r\n          Frost risk analysis\r\n          A robust method to estimate future frost risk\r\n          Major concepts\r\n          \r\n          \r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              Tree phenology analysis with R\r\n            \r\n            \r\n              \r\n                \r\n                    \r\n                      \r\n                         GitHub\r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                         Email\r\n                      \r\n                    \r\n                  \r\n                                  \r\n            \r\n          \r\n        \r\n        \r\n        \r\n          \r\n            \r\n            Welcome!\r\n            Hi, my name is Jacqueline. I’m a master’s student in Crop\r\n            Sciences at the University of Bonn.\r\n            This is my learning logbook for the module “Tree phenology\r\n            analysis with R”. This module provides an overview of\r\n            methods to study the impact of climate and climate change on\r\n            tree phenology.\r\n            It is designed for those who may not yet be familiar with\r\n            phenology or how to analyze climate change effects, but it\r\n            also aims to offer new insights for those with existing\r\n            knowledge in these areas. Initially developed for M.Sc.\r\n            students in Crop Science and Agricultural Science and\r\n            Resource Management in the Tropics and Subtropics (ARTS) at\r\n            the University of Bonn, the material is accessible to anyone\r\n            interested.\r\n            \r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              Tree phenology analysis with R\r\n            \r\n            \r\n              \r\n                \r\n                                    \r\n                    \r\n                       GitHub\r\n                    \r\n                  \r\n                                    \r\n                    \r\n                       Email\r\n                    \r\n                  \r\n                                  \r\n              \r\n            \r\n            \r\n              \r\n              Welcome!\r\n              Hi, my name is Jacqueline. I’m a master’s student in\r\n              Crop Sciences at the University of Bonn.\r\n              This is my learning logbook for the module “Tree phenology\r\n              analysis with R”. This module provides an overview of\r\n              methods to study the impact of climate and climate change\r\n              on tree phenology.\r\n              It is designed for those who may not yet be familiar\r\n              with phenology or how to analyze climate change effects,\r\n              but it also aims to offer new insights for those with\r\n              existing knowledge in these areas. Initially developed for\r\n              M.Sc. students in Crop Science and Agricultural Science\r\n              and Resource Management in the Tropics and Subtropics\r\n              (ARTS) at the University of Bonn, the material is\r\n              accessible to anyone interested.\r\n              \r\n            \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2025-03-11T17:27:12+01:00"
    },
    {
      "path": "major_concepts.html",
      "title": "Major concepts",
      "author": [],
      "contents": "\r\nTree Dormancy\r\nWoody plants in cold climates enter a dormant phase during winter. To\r\nresume growth in spring, they must first go through a period of cold\r\nexposure (endodormancy) and then a period of warmth (ecodormancy). The\r\nrelease from dormancy is influenced by factors such as intercellular\r\ncommunication, carbohydrate storage and transport, plant hormones, and\r\nthe regulation of specific genes. The exact mechanisms are not yet fully\r\nunderstood, and there are no complete process-based models.\r\nClimate Change\r\nGlobal warming leads to changes in temperature and precipitation\r\npatterns worldwide. While the exact developments remain uncertain,\r\nclimate scientists have a strong understanding to create models of\r\nfuture conditions. The extent of future warming depends on atmospheric\r\ngreenhouse gas concentrations, which are uncertain. Therefore, different\r\nscenarios are used to represent these uncertainties. Effective climate\r\nchange mitigation requires significant reductions in greenhouse gas\r\nemissions, particularly in the energy sector.\r\nPhenology Modeling\r\nModeling phenology, which is the timing of plant growth phases, is\r\nchallenging due to gaps in understanding. Various models exist for chill\r\nand heat accumulation, but estimates of their effects on phenology\r\ndiffer greatly. The Dynamic Model is the leading model for chill\r\naccumulation, while the Growing Degree Hour Model is favored for heat\r\naccumulation. Some comprehensive modeling frameworks attempt to predict\r\nfuture phenology based on temperature data, but they have limitations\r\nand fail to account for uncertainties.\r\nPhenology Responses to Global Warming\r\nMost plant species have advanced their phenology in response to rising\r\ntemperatures. However, this trend may not continue indefinitely as\r\nwarming progresses. In areas where temperatures are high enough to\r\ninterfere with chill accumulation during endodormancy, phenology shifts\r\nmay slow, stop, or even reverse. This hypothesis is supported by\r\nfundamental principles but requires further validation.\r\nThe PhenoFlex Modeling Framework\r\nPhenoFlex integrates effective chill and heat accumulation models into a\r\ncomprehensive framework to predict the timing of spring phenological\r\nphases. The model can be parameterized using long-term phenology data\r\nthrough an empirical fitting algorithm called Simulated Annealing. It\r\nallows the characterization of cultivar-specific temperature response\r\nfunctions. Initial results are promising, but the model has limitations,\r\nincluding challenges in generalizing across species and the risk of\r\nsuboptimal parameters from the fitting procedure.\r\nKey Concepts\r\nReproducibility & Transparency: Science should prioritize\r\nreproducibility and transparency. While experiments are often\r\nchallenging to fully replicate, modeling studies typically allow for\r\nhigher reproducibility. Methods should be clearly documented, and\r\nthe code and raw data should be shared for verification.\r\nTools: GitHub, R, RStudio, and various R add-ons were used in\r\nthis study to enhance workflows. Whether these tools will remain\r\nrelevant in the future is uncertain, but using effective tools\r\nremains important.\r\nAutomation: Repetitive tasks should be automated to free up time\r\nfor more creative and meaningful work. This also helps in generating\r\ncomparable results across different contexts efficiently.\r\nThe Power of R: R is not just a statistical program but also a\r\npowerful tool for advanced statistical analyses, spatial analyses,\r\nanimated visualizations, and interactive applications. R is free and\r\na valuable investment for any scientific career.\r\nCuriosity and Interdisciplinarity: Focusing too narrowly on one\r\nfield can lead to deep expertise but may stifle innovation. Exposure\r\nto other fields fosters new perspectives and can lead to\r\ngroundbreaking discoveries.\r\nUncertainty: Uncertainty is an inherent part of real-world\r\nproblems. Models are approximations of complex natural processes,\r\nand acknowledging and quantifying this uncertainty is essential.\r\nEnsemble Analysis: In cases like climate change, where\r\nuncertainty arises from not knowing which scenario will unfold,\r\nensemble analysis combines multiple models and scenarios to provide\r\na more comprehensive view of possible future developments.\r\nP-Hacking: P-hacking refers to manipulating data to find random\r\ncorrelations that lack true significance. This leads to findings\r\nthat do not provide meaningful insights into the system.\r\nDangers of Machine Learning: Machine learning can be problematic\r\nwhen applied without domain-specific knowledge, as many models\r\noperate as “black boxes,” making it difficult to understand how\r\nconclusions are reached. This increases the risk of\r\nmisinterpretation and flawed conclusions.\r\nRationalizing: A problematic practice in science involves\r\ndrawing conclusions from data and then crafting stories to justify\r\nthe results. These explanations can mislead and should be avoided.\r\nOverfitting: When models are too complex and capture random\r\nnoise in the data rather than the true underlying process,\r\noverfitting occurs. This leads to incorrect conclusions.\r\nProcess and Model Validation: Models should not only fit the\r\ndata but also accurately represent the underlying biological or\r\necological processes. Models need validation to ensure they provide\r\nreliable predictions in real-world scenarios.\r\nModel Validation and Purpose: Validation should reflect the\r\ncontext of the intended prediction. For example, climate change\r\nmodels should use data from warmer conditions, and prediction models\r\nshould be tested on years without prior data.\r\nOur Role in Research: Scientific research should be grounded in\r\ntheory, hypotheses, and predictions. There is a debate over whether\r\nprior knowledge and beliefs should influence research, but\r\nintegrating expertise can enhance scientific inquiry if assumptions\r\nare made explicit and continuously questioned.\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:27:23+01:00"
    },
    {
      "path": "making_temp.html",
      "title": "Making hourly temperatures",
      "author": [],
      "contents": "\r\nThe calculation of Chilling Hours requires hourly temperature data. However, since only daily minimum and maximum temperatures are often available, methods for hourly interpolation must be developed. Previous approaches used linear interpolation and triangular temperature profiles (Baldocchi & Wong, 2008):\r\n\r\n\r\n\r\nHowever, triangular temperature profiles are not always realistic, as temperature increases and decreases are asymmetric.\r\nIdealized Daily Temperature Model\r\nDale E. Linvill (1990) developed a model that describes daytime warming with a sine curve and nighttime cooling with a logarithmic function. The chillR function daylength() uses astronomical calculations to determine the length of daylight:\r\n\r\n\r\nDays <- daylength(latitude = 50.4, JDay = 1:365)\r\nDays_df <-\r\n  data.frame(\r\n    JDay = 1:365,\r\n    Sunrise = Days$Sunrise,\r\n    Sunset = Days$Sunset,\r\n    Daylength = Days$Daylength\r\n  )\r\nDays_df <- pivot_longer(Days_df, cols = c(Sunrise:Daylength))\r\n\r\nggplot(Days_df, aes(JDay, value)) +\r\n  geom_line(lwd = 1.5) +\r\n  facet_grid(cols = vars(name)) +\r\n  ylab(\"Time of Day / Daylength (Hours)\") +\r\n  theme_bw(base_size = 15)\r\n\r\n\r\n\r\nThe stack_hourly_temps() function calculates hourly temperatures based on daily Tmin/Tmax values and latitude:\r\n\r\n\r\nYear\r\n\r\n\r\nMonth\r\n\r\n\r\nDay\r\n\r\n\r\nTmax\r\n\r\n\r\nTmin\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n1\r\n\r\n\r\n8.2\r\n\r\n\r\n5.1\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n9.1\r\n\r\n\r\n5.0\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n3\r\n\r\n\r\n10.4\r\n\r\n\r\n3.3\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n4\r\n\r\n\r\n8.4\r\n\r\n\r\n4.5\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n7\r\n\r\n\r\n12.0\r\n\r\n\r\n6.9\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n8\r\n\r\n\r\n11.2\r\n\r\n\r\n8.6\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n9\r\n\r\n\r\n13.9\r\n\r\n\r\n8.5\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n10\r\n\r\n\r\n14.5\r\n\r\n\r\n3.6\r\n\r\n\r\nAnd the following process describes how hourly temperatures can be calculated based on the idealized daily temperature curve:\r\n\r\n\r\nstack_hourly_temps(KA_weather, latitude = 50.4)\r\n\r\n\r\n\r\n\r\n\r\nYear\r\n\r\n\r\nMonth\r\n\r\n\r\nDay\r\n\r\n\r\nTmax\r\n\r\n\r\nTmin\r\n\r\n\r\nJDay\r\n\r\n\r\nHour\r\n\r\n\r\nTemp\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n3\r\n\r\n\r\n4.844164\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n4\r\n\r\n\r\n4.746566\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n5\r\n\r\n\r\n4.656244\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n6\r\n\r\n\r\n4.572187\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n7\r\n\r\n\r\n4.493583\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n8\r\n\r\n\r\n4.569464\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n9\r\n\r\n\r\n5.384001\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n10\r\n\r\n\r\n6.139939\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n11\r\n\r\n\r\n6.787169\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n12\r\n\r\n\r\n7.282787\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n13\r\n\r\n\r\n7.593939\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n14\r\n\r\n\r\n7.700000\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n15\r\n\r\n\r\n7.593939\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n16\r\n\r\n\r\n7.282787\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n17\r\n\r\n\r\n6.591821\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n18\r\n\r\n\r\n6.168074\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n19\r\n\r\n\r\n5.870570\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n20\r\n\r\n\r\n5.641106\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n21\r\n\r\n\r\n5.454280\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n22\r\n\r\n\r\n5.296704\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n7.7\r\n\r\n\r\n4.5\r\n\r\n\r\n5\r\n\r\n\r\n23\r\n\r\n\r\n5.160445\r\n\r\n\r\n\r\nBased on this the following plot shows the calculated data:\r\n\r\n\r\n\r\nEmpirical Daily Temperature Profiles\r\nIn complex topographies (e.g., Oman), idealized models can be inaccurate. Here, the Empirical_daily_temperature_curve() function helps to empirically determine typical hourly temperature patterns:\r\n\r\n\r\nempi_curve <- Empirical_daily_temperature_curve(Winters_hours_gaps)\r\n\r\n\r\n\r\n\r\n\r\nMonth\r\n\r\n\r\nHour\r\n\r\n\r\nPrediction_coefficient\r\n\r\n\r\n3\r\n\r\n\r\n0\r\n\r\n\r\n0.1774859\r\n\r\n\r\n3\r\n\r\n\r\n1\r\n\r\n\r\n0.1550693\r\n\r\n\r\n3\r\n\r\n\r\n2\r\n\r\n\r\n0.1285651\r\n\r\n\r\n3\r\n\r\n\r\n3\r\n\r\n\r\n0.1145597\r\n\r\n\r\n3\r\n\r\n\r\n4\r\n\r\n\r\n0.0696064\r\n\r\n\r\n3\r\n\r\n\r\n5\r\n\r\n\r\n0.0339583\r\n\r\n\r\n3\r\n\r\n\r\n6\r\n\r\n\r\n0.0000000\r\n\r\n\r\n3\r\n\r\n\r\n7\r\n\r\n\r\n0.0313115\r\n\r\n\r\n3\r\n\r\n\r\n8\r\n\r\n\r\n0.3121959\r\n\r\n\r\n3\r\n\r\n\r\n9\r\n\r\n\r\n0.4953232\r\n\r\n\r\n3\r\n\r\n\r\n10\r\n\r\n\r\n0.6819674\r\n\r\n\r\n3\r\n\r\n\r\n11\r\n\r\n\r\n0.8227423\r\n\r\n\r\n3\r\n\r\n\r\n12\r\n\r\n\r\n0.9506491\r\n\r\n\r\n3\r\n\r\n\r\n13\r\n\r\n\r\n0.9662604\r\n\r\n\r\n3\r\n\r\n\r\n14\r\n\r\n\r\n0.9915996\r\n\r\n\r\n3\r\n\r\n\r\n15\r\n\r\n\r\n1.0000000\r\n\r\n\r\n3\r\n\r\n\r\n16\r\n\r\n\r\n0.9490319\r\n\r\n\r\n3\r\n\r\n\r\n17\r\n\r\n\r\n0.8483098\r\n\r\n\r\n3\r\n\r\n\r\n18\r\n\r\n\r\n0.6864529\r\n\r\n\r\n3\r\n\r\n\r\n19\r\n\r\n\r\n0.4945415\r\n\r\n\r\n3\r\n\r\n\r\n20\r\n\r\n\r\n0.3636642\r\n\r\n\r\n3\r\n\r\n\r\n21\r\n\r\n\r\n0.2972377\r\n\r\n\r\n3\r\n\r\n\r\n22\r\n\r\n\r\n0.2360349\r\n\r\n\r\n3\r\n\r\n\r\n23\r\n\r\n\r\n0.1794802\r\n\r\n\r\n4\r\n\r\n\r\n0\r\n\r\n\r\n0.1960789\r\n\r\n\r\n4\r\n\r\n\r\n1\r\n\r\n\r\n0.1407018\r\n\r\n\r\n4\r\n\r\n\r\n2\r\n\r\n\r\n0.1283250\r\n\r\n\r\n4\r\n\r\n\r\n3\r\n\r\n\r\n0.0819307\r\n\r\n\r\n4\r\n\r\n\r\n4\r\n\r\n\r\n0.0541415\r\n\r\n\r\n4\r\n\r\n\r\n5\r\n\r\n\r\n0.0188241\r\n\r\n\r\n4\r\n\r\n\r\n6\r\n\r\n\r\n0.0000000\r\n\r\n\r\n4\r\n\r\n\r\n7\r\n\r\n\r\n0.1697052\r\n\r\n\r\n4\r\n\r\n\r\n8\r\n\r\n\r\n0.4442722\r\n\r\n\r\n4\r\n\r\n\r\n9\r\n\r\n\r\n0.5939797\r\n\r\n\r\n4\r\n\r\n\r\n10\r\n\r\n\r\n0.7363923\r\n\r\n\r\n4\r\n\r\n\r\n11\r\n\r\n\r\n0.8399804\r\n\r\n\r\n4\r\n\r\n\r\n12\r\n\r\n\r\n0.9245702\r\n\r\n\r\n4\r\n\r\n\r\n13\r\n\r\n\r\n0.9770693\r\n\r\n\r\n4\r\n\r\n\r\n14\r\n\r\n\r\n0.9963131\r\n\r\n\r\n4\r\n\r\n\r\n15\r\n\r\n\r\n1.0000000\r\n\r\n\r\n4\r\n\r\n\r\n16\r\n\r\n\r\n0.9568107\r\n\r\n\r\n4\r\n\r\n\r\n17\r\n\r\n\r\n0.8698369\r\n\r\n\r\n4\r\n\r\n\r\n18\r\n\r\n\r\n0.7343896\r\n\r\n\r\n4\r\n\r\n\r\n19\r\n\r\n\r\n0.5330597\r\n\r\n\r\n4\r\n\r\n\r\n20\r\n\r\n\r\n0.3941038\r\n\r\n\r\n4\r\n\r\n\r\n21\r\n\r\n\r\n0.3186075\r\n\r\n\r\n4\r\n\r\n\r\n22\r\n\r\n\r\n0.2594569\r\n\r\n\r\n4\r\n\r\n\r\n23\r\n\r\n\r\n0.2114486\r\n\r\n\r\n\r\n\r\n\r\nggplot(data = empi_curve[1:96, ], aes(Hour, Prediction_coefficient)) +\r\n  geom_line(lwd = 1.3, \r\n            col = \"red\") + \r\n  facet_grid(rows = vars(Month)) + \r\n  xlab(\"Hour of the day\") +\r\n  ylab(\"Prediction coefficient\") +\r\n  theme_bw(base_size = 15)\r\n\r\n\r\n\r\nThe function Empirical_hourly_temperatures() uses these coefficients to generate hourly temperatures. To fill gaps in daily or hourly temperature records, the make_all_day_table() function is used.\r\n\r\n\r\ncoeffs <- Empirical_daily_temperature_curve(Winters_hours_gaps)\r\nWinters_daily <-\r\n  make_all_day_table(Winters_hours_gaps, input_timestep = \"hour\")\r\nWinters_hours <- Empirical_hourly_temperatures(Winters_daily, coeffs)\r\n\r\n\r\nThe next step is to plot the results to visualize the hourly temperature data. This enables a comparison between the empirical method, the triangular function, and the idealized temperature curve. Furthermore, actual observed temperatures will be used for validation. To streamline this process, the data will first be simplified for easier handling:\r\n\r\n\r\nWinters_hours <- Winters_hours[, c(\"Year\", \"Month\", \"Day\", \"Hour\", \"Temp\")]\r\ncolnames(Winters_hours)[ncol(Winters_hours)] <- \"Temp_empirical\"\r\nWinters_ideal <-\r\n  stack_hourly_temps(Winters_daily, latitude = 38.5)$hourtemps\r\nWinters_ideal <- Winters_ideal[, c(\"Year\", \"Month\", \"Day\", \"Hour\", \"Temp\")]\r\ncolnames(Winters_ideal)[ncol(Winters_ideal)] <- \"Temp_ideal\"\r\n\r\n\r\nThe next step is to generate the triangular dataset, requiring a clear understanding of its construction.\r\n\r\n\r\nWinters_triangle <- Winters_daily\r\nWinters_triangle[, \"Hour\"] <- 0\r\nWinters_triangle$Hour[nrow(Winters_triangle)] <- 23\r\nWinters_triangle[, \"Temp\"] <- 0\r\nWinters_triangle <-\r\n  make_all_day_table(Winters_triangle, timestep = \"hour\")\r\ncolnames(Winters_triangle)[ncol(Winters_triangle)] <-\r\n  \"Temp_triangular\"\r\n\r\n# with the following loop, we fill in the daily Tmin and Tmax values for every\r\n# hour of the dataset\r\n\r\nfor (i in 2:nrow(Winters_triangle))\r\n{\r\n  if (is.na(Winters_triangle$Tmin[i]))\r\n    Winters_triangle$Tmin[i] <- Winters_triangle$Tmin[i - 1]\r\n  if (is.na(Winters_triangle$Tmax[i]))\r\n    Winters_triangle$Tmax[i] <- Winters_triangle$Tmax[i - 1]\r\n}\r\nWinters_triangle$Temp_triangular <- NA\r\n\r\n# now we assign the daily Tmin value to the 6th hour of every day\r\n\r\nWinters_triangle$Temp_triangular[which(Winters_triangle$Hour == 6)] <-\r\n  Winters_triangle$Tmin[which(Winters_triangle$Hour == 6)]\r\n\r\n# we also assign the daily Tmax value to the 18th hour of every day\r\n\r\nWinters_triangle$Temp_triangular[which(Winters_triangle$Hour == 18)] <-\r\n  Winters_triangle$Tmax[which(Winters_triangle$Hour == 18)]\r\n\r\n# in the following step, we use the chillR function \"interpolate_gaps\"\r\n# to fill in all the gaps in the hourly record with straight lines\r\n\r\nWinters_triangle$Temp_triangular <-\r\n  interpolate_gaps(Winters_triangle$Temp_triangular)$interp\r\nWinters_triangle <-\r\n  Winters_triangle[, c(\"Year\", \"Month\", \"Day\", \"Hour\", \"Temp_triangular\")]\r\n\r\n\r\nComparison of Temperature Models\r\nThree methods were compared: the triangular model, the idealized model, and the empirical model. The data were merged and visualized:\r\n\r\n\r\nWinters_temps <-\r\n  merge(Winters_hours_gaps,\r\n        Winters_hours,\r\n        by = c(\"Year\", \"Month\", \"Day\", \"Hour\"))\r\nWinters_temps <-\r\n  merge(Winters_temps,\r\n        Winters_triangle,\r\n        by = c(\"Year\", \"Month\", \"Day\", \"Hour\"))\r\nWinters_temps <-\r\n  merge(Winters_temps,\r\n        Winters_ideal,\r\n        by = c(\"Year\", \"Month\", \"Day\", \"Hour\"))\r\n\r\n\r\nAccuracy of the three models was then compared using the Root Mean Square Error (RMSE) metric:\r\n\r\n\r\nRMSEP(Winters_temps$Temp_triangular, Winters_temps$Temp)\r\n\r\n[1] 4.695289\r\n\r\nRMSEP(Winters_temps$Temp_ideal, Winters_temps$Temp)\r\n\r\n[1] 1.630714\r\n\r\nRMSEP(Winters_temps$Temp_empirical, Winters_temps$Temp)\r\n\r\n[1] 1.410625\r\n\r\nResults:\r\nTriangular method: RMSE = 4.7\r\nIdealized model: RMSE = 1.63\r\nEmpirical model: RMSE = 1.41\r\nThe empirical model achieves the highest accuracy. This approach is especially crucial for calculating the Chilling Hours.\r\nExercises on hourly temperatures\r\nChoose a location of interest, find out its latitude and produce plots of daily sunrise, sunset and daylength.\r\nThe Yakima Valley in Washington State, USA, is located at about 46.6° N latitude. This region has a continental climate with cold winters and hot, dry summers, creating ideal conditions for growing fruit trees. The valley is well known for producing a variety of fruits, including apples, cherries, pears, and grapes, which benefit from its distinct seasonal changes. Using the daylength() function, you could create plots showing daily sunrise, sunset, and day length times.\r\n\r\n\r\nYakima <- daylength(latitude = 46.6, JDay = 1:365)\r\n\r\nYakima_df <-\r\n  data.frame(\r\n    JDay = 1:365,\r\n    Sunrise = Yakima$Sunrise,\r\n    Sunset = Yakima$Sunset,\r\n    Daylength = Yakima$Daylength\r\n  )\r\n\r\nYakima_df_longer <- pivot_longer(Yakima_df, cols = c(Sunrise:Daylength))\r\n\r\nggplot(Yakima_df_longer, aes(JDay, value)) +\r\n  geom_line(lwd = 1.5) +\r\n  facet_grid(cols = vars(name)) +\r\n  ylab(\"Time of Day / Daylength (Hours)\") +\r\n  theme_bw(base_size = 15)\r\n\r\n\r\n\r\nProduce an hourly dataset, based on idealized daily curves, for the KA_weather dataset (included in chillR)\r\n\r\n\r\nKA_hourly <- stack_hourly_temps(KA_weather, latitude = 50.4)\r\n\r\n\r\nBased on idealized daily curves, the hourly dataset for Julian Day 6 (January 6th) is shown below:\r\n\r\n\r\n\r\nYear\r\n\r\n\r\nMonth\r\n\r\n\r\nDay\r\n\r\n\r\nTmax\r\n\r\n\r\nTmin\r\n\r\n\r\nJDay\r\n\r\n\r\nHour\r\n\r\n\r\nTemp\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n0\r\n\r\n\r\n4.990741\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n1\r\n\r\n\r\n4.881232\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n2\r\n\r\n\r\n4.782253\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n3\r\n\r\n\r\n4.691956\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n4\r\n\r\n\r\n4.608939\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n5\r\n\r\n\r\n4.532117\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n6\r\n\r\n\r\n4.460628\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n7\r\n\r\n\r\n4.393780\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n8\r\n\r\n\r\n4.491337\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n9\r\n\r\n\r\n5.430950\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n10\r\n\r\n\r\n6.302486\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n11\r\n\r\n\r\n7.048391\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n12\r\n\r\n\r\n7.619410\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n13\r\n\r\n\r\n7.977836\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n14\r\n\r\n\r\n8.100000\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n15\r\n\r\n\r\n7.977836\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n16\r\n\r\n\r\n7.619410\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n17\r\n\r\n\r\n7.419674\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n18\r\n\r\n\r\n7.318918\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n19\r\n\r\n\r\n7.248287\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n20\r\n\r\n\r\n7.193854\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n21\r\n\r\n\r\n7.149557\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n22\r\n\r\n\r\n7.112208\r\n\r\n\r\n1998\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n8.1\r\n\r\n\r\n4.4\r\n\r\n\r\n6\r\n\r\n\r\n23\r\n\r\n\r\n7.079920\r\n\r\n\r\n\r\nProduce empirical temperature curve parameters for the Winters_hours_gaps dataset, and use them to predict hourly values from daily temperatures (this is very similar to the example above, but please make sure you understand what’s going on).\r\n\r\n\r\n# Generating empirical daily temperature curve from observed hourly data\r\nempi_curve <- Empirical_daily_temperature_curve(Winters_hours_gaps)\r\n\r\n# Filling gaps in daily or hourly temperature data\r\nWinters_daily <- make_all_day_table(Winters_hours_gaps, input_timestep = \"hour\")\r\n\r\n# Using empirical coefficients to predict hourly temperatures based on daily temperatures\r\nWinters_hours <- Empirical_hourly_temperatures(Winters_daily, empi_curve)\r\n\r\n# Make an empirical dataset \r\nWinters_hours <- Winters_hours[, c(\"Year\", \"Month\", \"Day\", \"Hour\", \"Temp\")]\r\ncolnames(Winters_hours)[ncol(Winters_hours)] <- \"Temp_empirical\"\r\n\r\n# Merge data frames\r\nWinters_temps <-\r\n  merge(Winters_hours_gaps,\r\n        Winters_hours,\r\n        by = c(\"Year\", \"Month\", \"Day\", \"Hour\"))\r\n\r\n\r\n\r\n\r\n# Covert Year, Month, Day and Hour columns into R's date formate and reorganizing the data frame\r\nWinters_temps[, \"DATE\"] <-\r\n  ISOdate(Winters_temps$Year,\r\n          Winters_temps$Month,\r\n          Winters_temps$Day,\r\n          Winters_temps$Hour)\r\n\r\nWinters_temps_to_plot <-\r\n  Winters_temps[, c(\"DATE\",\r\n                    \"Temp\",\r\n                    \"Temp_empirical\")]\r\nWinters_temps_to_plot <- Winters_temps_to_plot[100:200, ]\r\nWinters_temps_to_plot <- pivot_longer(Winters_temps_to_plot, cols=Temp:Temp_empirical)\r\ncolnames(Winters_temps_to_plot) <- c(\"DATE\", \"Method\", \"Temperature\")\r\n\r\nggplot(data = Winters_temps_to_plot, aes(DATE, Temperature, colour = Method)) +\r\n  geom_line(lwd = 1.3) + ylab(\"Temperature (°C)\") + xlab(\"Date\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:28:22+01:00"
    },
    {
      "path": "manual_chill.html",
      "title": "Manual chill",
      "author": [],
      "contents": "\r\nThis chapter explains how to calculate Chilling Hours using R and the chillR package. Chilling Hours measure the number of hours where temperatures are between 0°C and 7.2°C, which is important for certain plants to meet their cold requirements during dormancy and grow properly.\r\nData Requirements\r\nThe calculation requires hourly temperature data, which is not always available. The chillR package provides tools to approximate data from daily records. In this example, the dataset Winters_hours_gaps is used, containing hourly temperature data recorded in 2008 from a walnut orchard in Winters, California.\r\nData Preparation\r\nThe chillR package is loaded using library(chillR). The relevant columns (year, month, day, hour, temperature) are extracted and stored in a new dataset named hourtemps, ensuring the correct format for calculating Chilling Hours.\r\n\r\n\r\nhourtemps <- Winters_hours_gaps[,c(\"Year\",\r\n                                   \"Month\",\r\n                                   \"Day\",\r\n                                   \"Hour\",\r\n                                   \"Temp\")]\r\n\r\n\r\nManual Calculation of Chilling Hours\r\nChilling Hours are defined as any hour where the temperature falls between 0°C and 7.2°C. In R, this is implemented using a logical condition:\r\n\r\n\r\nhourtemps[, \"Chilling_Hour\"] <- hourtemps$Temp >= 0 & hourtemps$Temp <= 7.2\r\n\r\n\r\nA new column Chilling_Hour (TRUE/FALSE) is created to indicate whether a given hour qualifies. The total number of Chilling Hours can then be calculated using sum(hourtemps$Chilling_Hour).\r\nAutomation with Functions\r\nTo simplify the process, a function CH() was created to automatically add the Chilling_Hour column:\r\n\r\n\r\nCH <- function(hourtemps) {\r\n  hourtemps[, \"Chilling_Hour\"] <- hourtemps$Temp >= 0 & hourtemps$Temp <= 7.2\r\n  return(hourtemps)\r\n}\r\n\r\n\r\nAdditionally, a function sum_CH() was developed to calculate the total number of Chilling Hours between two specific dates:\r\n\r\n\r\nsum_CH <- function(hourtemps, Start_Year, Start_Month, Start_Day, Start_Hour, \r\n                              End_Year, End_Month, End_Day, End_Hour) {\r\n  hourtemps[,\"Chilling_Hour\"] <- hourtemps$Temp >= 0 & hourtemps$Temp <= 7.2\r\n\r\n  Start_Index <- which(hourtemps$Year == Start_Year & hourtemps$Month == Start_Month &\r\n                       hourtemps$Day == Start_Day & hourtemps$Hour == Start_Hour)\r\n  End_Index <- which(hourtemps$Year == End_Year & hourtemps$Month == End_Month &\r\n                     hourtemps$Day == End_Day & hourtemps$Hour == End_Hour)\r\n\r\n  CHs <- sum(hourtemps$Chilling_Hour[Start_Index:End_Index])\r\n  return(CHs)\r\n}\r\n\r\n\r\nThis function uses the which() function to identify the relevant rows in the dataset based on the selected time range.\r\nOptimization of Function Parameters\r\nInstead of passing year, month, day, and hour separately, compact strings in the format YEARMODAHO (e.g., 2008040100 for April 1, 2008, at 00:00) can be used. The function extracts values using substr() and converts them into numeric values.\r\n\r\n\r\nsum_CH <- function(hourtemps, startYEARMODAHO, endYEARMODAHO) {\r\n  hourtemps[, \"Chilling_Hour\"] <- hourtemps$Temp >= 0 & hourtemps$Temp <= 7.2\r\n\r\n  startYear <- as.numeric(substr(startYEARMODAHO, 1, 4))\r\n  startMonth <- as.numeric(substr(startYEARMODAHO, 5, 6))\r\n  startDay <- as.numeric(substr(startYEARMODAHO, 7, 8))\r\n  startHour <- as.numeric(substr(startYEARMODAHO, 9, 10))\r\n\r\n  endYear <- as.numeric(substr(endYEARMODAHO, 1, 4))\r\n  endMonth <- as.numeric(substr(endYEARMODAHO, 5, 6))\r\n  endDay <- as.numeric(substr(endYEARMODAHO, 7, 8))\r\n  endHour <- as.numeric(substr(endYEARMODAHO, 9, 10))\r\n\r\n  Start_Index <- which(hourtemps$Year == startYear & hourtemps$Month == startMonth &\r\n                       hourtemps$Day == startDay & hourtemps$Hour == startHour)\r\n  End_Index <- which(hourtemps$Year == endYear & hourtemps$Month == endMonth &\r\n                     hourtemps$Day == endDay & hourtemps$Hour == endHour)\r\n\r\n  CHs <- sum(hourtemps$Chilling_Hour[Start_Index:End_Index])\r\n  return(CHs)\r\n}\r\n\r\n\r\nApplication Example\r\nUsing the function sum_CH(), it was calculated that between April 1st and October 11th, 2008, the walnut orchard experienced 77 Chilling Hours:\r\n\r\n\r\nsum_CH(hourtemps, startYEARMODAHO = 2008040100, endYEARMODAHO = 2008101100)\r\n\r\n[1] 77\r\n\r\nExercises on basic chill modeling\r\nWrite a basic function that calculates warm hours (>25°C).\r\n\r\n\r\nWH <- function(data)\r\n  {data[, \"Warm_Hour\"] <- data$Temp > 25\r\n  return(data)\r\n}\r\n\r\n\r\nApply this function to the Winters_hours_gaps dataset.\r\n\r\n\r\nWH(Winters_hours_gaps)\r\n\r\n\r\n\r\n\r\nYear\r\n\r\n\r\nMonth\r\n\r\n\r\nDay\r\n\r\n\r\nHour\r\n\r\n\r\nTemp_gaps\r\n\r\n\r\nTemp\r\n\r\n\r\nWarm_Hour\r\n\r\n\r\n2008\r\n\r\n\r\n3\r\n\r\n\r\n3\r\n\r\n\r\n10\r\n\r\n\r\n15.127\r\n\r\n\r\n15.127\r\n\r\n\r\nFALSE\r\n\r\n\r\n2008\r\n\r\n\r\n3\r\n\r\n\r\n3\r\n\r\n\r\n11\r\n\r\n\r\n17.153\r\n\r\n\r\n17.153\r\n\r\n\r\nFALSE\r\n\r\n\r\n2008\r\n\r\n\r\n3\r\n\r\n\r\n3\r\n\r\n\r\n12\r\n\r\n\r\n18.699\r\n\r\n\r\n18.699\r\n\r\n\r\nFALSE\r\n\r\n\r\n2008\r\n\r\n\r\n3\r\n\r\n\r\n3\r\n\r\n\r\n13\r\n\r\n\r\n18.699\r\n\r\n\r\n18.699\r\n\r\n\r\nFALSE\r\n\r\n\r\n2008\r\n\r\n\r\n3\r\n\r\n\r\n3\r\n\r\n\r\n14\r\n\r\n\r\n18.842\r\n\r\n\r\n18.842\r\n\r\n\r\nFALSE\r\n\r\n\r\n2008\r\n\r\n\r\n3\r\n\r\n\r\n3\r\n\r\n\r\n15\r\n\r\n\r\n19.508\r\n\r\n\r\n19.508\r\n\r\n\r\nFALSE\r\n\r\n\r\n2008\r\n\r\n\r\n3\r\n\r\n\r\n3\r\n\r\n\r\n16\r\n\r\n\r\n19.318\r\n\r\n\r\n19.318\r\n\r\n\r\nFALSE\r\n\r\n\r\n2008\r\n\r\n\r\n3\r\n\r\n\r\n3\r\n\r\n\r\n17\r\n\r\n\r\n17.701\r\n\r\n\r\n17.701\r\n\r\n\r\nFALSE\r\n\r\n\r\n2008\r\n\r\n\r\n3\r\n\r\n\r\n3\r\n\r\n\r\n18\r\n\r\n\r\n15.414\r\n\r\n\r\n15.414\r\n\r\n\r\nFALSE\r\n\r\n\r\n2008\r\n\r\n\r\n3\r\n\r\n\r\n3\r\n\r\n\r\n19\r\n\r\n\r\n12.727\r\n\r\n\r\n12.727\r\n\r\n\r\nFALSE\r\n\r\n\r\nExtend this function, so that it can take start and end dates as inputs and sums up warm hours between these dates.\r\n\r\n\r\nsum_WH <- function(data, \r\n                   startYEARMODAHO,\r\n                   endYEARMODAHO)\r\n  \r\n{data[,\"Warm_Hour\"] <- data$Temp > 25\r\n\r\nstartYear <- as.numeric(substr(startYEARMODAHO, 1, 4))\r\nstartMonth <- as.numeric(substr(startYEARMODAHO, 5, 6))\r\nstartDay <- as.numeric(substr(startYEARMODAHO, 7, 8))\r\nstartHour <- as.numeric(substr(startYEARMODAHO, 9, 10))\r\n\r\nendYear <- as.numeric(substr(endYEARMODAHO, 1, 4))\r\nendMonth <- as.numeric(substr(endYEARMODAHO, 5, 6))\r\nendDay <- as.numeric(substr(endYEARMODAHO, 7, 8))\r\nendHour <- as.numeric(substr(endYEARMODAHO, 9, 10))\r\n\r\n\r\nStart_Date <- which(data$Year == startYear &\r\n                    data$Month == startMonth &\r\n                    data$Day == startDay &\r\n                    data$Hour == startHour)\r\n\r\nEnd_Date <- which(data$Year == endYear &\r\n                  data$Month == endMonth &\r\n                  data$Day == endDay &\r\n                  data$Hour == endHour)\r\n\r\nWHs <- sum(data$Warm_Hour[Start_Date:End_Date])\r\nreturn(WHs)\r\n}\r\n\r\n\r\nApplication Example:\r\n\r\n\r\nsum_WH(Winters_hours_gaps, startYEARMODAHO = 2008080100, \r\n                           endYEARMODAHO = 2008083100)\r\n\r\n[1] 283\r\n\r\nDuring the month of August 2008, from the 1st to the 31st, the walnut orchard experienced a total of 283 warm hours (defined as hours when the temperature exceeded 25°C).\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:28:38+01:00"
    },
    {
      "path": "save.html",
      "title": "Saving and loading data",
      "author": [],
      "contents": "\r\nThe compilation time increases with more data processing, especially with a large dataset (100 years of hourly weather data). Each hourly calculation requires extensive computations, and scenario analysis for climate change will add even more complexity. To handle this, saving results for faster reloading is essential.\r\nSaving and Loading Data R provides the save and load functions, but simpler formats like CSV are preferred for easy inspection. Here’s how to save and load data using CSV:\r\nSaving Data\r\n\r\n\r\n# Save Temperatures dataset as CSV\r\nwrite.csv(Temperatures, file = \"Yakima/Temperatures.csv\", row.names = FALSE)\r\n\r\n\r\nLoading Data\r\n\r\n\r\n# Load data using chillR's read_tab function for compatibility across regions\r\nTemperatures <- read_tab(\"Yakima/Temperatures.csv\")\r\n\r\n\r\nread_tab is preferred over read.csv because it automatically handles regional differences (e.g., commas vs. semicolons as delimiters).\r\nSaving and Loading Complex Data\r\nFor more complex objects (like lists of data frames), use chillR functions:\r\n\r\n\r\n# Save a list with multiple elements\r\ntest_list <- list(Number = 1, \r\n                  String = \"Thanks for using chillR!\", \r\n                  DataFrame = data.frame(a = c(1, 2, 3)))\r\n\r\nsave_temperature_scenarios(test_list, \r\n                           path = \"data\", \r\n                           prefix = \"test_list\")\r\n\r\n\r\nThis creates multiple files for each list element:\r\ntest_list_1_Number.csv\r\ntest_list_2_String.csv\r\ntest_list_3_DataFrame.csv\r\nTo reload the list:\r\n\r\n\r\ntest_list <- load_temperature_scenarios(path = \"data\", prefix = \"test_list\")\r\n\r\n\r\nOptimizing Markdown Document Execution\r\nTo avoid rerunning time-intensive calculations, save results and reload them during document knitting. Control code visibility and execution with these options:\r\necho = FALSE: Hide code but run it.\r\neval = FALSE: Show code but don’t run it.\r\ninclude = FALSE: Hide both code and output but run it.\r\nmessage = FALSE: Hide messages.\r\nwarning = FALSE: Hide warnings.\r\nThese options allow preloading necessary data for later code chunks without re-executing time-consuming tasks.\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:28:51+01:00"
    },
    {
      "path": "simple_phenology.html",
      "title": "Simple phenology analysis",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\nIn this section the focus shifts to a detailed phenology analysis, using the bloom dates of the pear cultivar ‘Alexander Lucas’ as an example. This dataset was previously examined in the frost analysis and includes a time series (1958–2019) of first, full, and last bloom dates recorded at Campus Klein-Altendorf.\r\nFor this analysis, only first bloom dates will be used. If working on a personal computer, the dataset can be downloaded from the provided link.\r\nData Reading and Preparation\r\nThe first step is to load the dataset from a CSV file. The read_tab function is used to handle potential issues with delimiters (such as commas or semicolons).\r\n\r\n\r\nAlex <- read_tab(\"data/Alexander_Lucas_bloom_1958_2019.csv\")\r\n\r\n\r\nOnce the data is loaded, it is prepared for analysis. The pivot_longer function transforms the data from wide to long format so that bloom stages are consolidated into a single column.\r\n\r\n\r\nAlex <- pivot_longer(Alex,\r\n                     cols = c(First_bloom:Last_bloom),\r\n                     names_to = \"Stage\",\r\n                     values_to = \"YEARMODA\")\r\n\r\nAlex_first <- Alex %>%\r\n  mutate(Year = as.numeric(substr(YEARMODA, 1, 4)),\r\n         Month = as.numeric(substr(YEARMODA, 5, 6)),\r\n         Day = as.numeric(substr(YEARMODA, 7, 8))) %>%\r\n  make_JDay() %>%\r\n  filter(Stage == \"First_bloom\")\r\n\r\n\r\nThis process extracts the year, month, and day from the YEARMODA column, converts them into a Julian day (JDay), and filters the data for the first bloom.\r\nTime Series Analysis\r\nThe first step in analyzing the phenology is visualizing the first bloom dates over the years to identify any trends or changes over time.\r\nVisualization of First Bloom Dates\r\nA scatter plot is used to visualize the first bloom dates across years:\r\n\r\n\r\nggplot(Alex_first,\r\n       aes(Pheno_year,\r\n           JDay)) +\r\n  geom_point() +\r\n  ylab(\"First bloom date (day of the year)\") +\r\n  xlab (\"Year\") +\r\n  theme_bw(base_size = 15)\r\n\r\n\r\n\r\nAt first glance, the plot does not reveal a clear pattern or trend. To check for any underlying trend, the Kendall trend test is applied to statistically assess the presence of a trend.\r\nKendall Trend Test\r\nThe Kendall test checks whether there is a statistically significant trend in the bloom dates over the years:\r\n\r\n\r\nlibrary(Kendall)\r\nKendall(x = Alex_first$Pheno_year,\r\n        y = Alex_first$JDay)\r\n\r\ntau = -0.186, 2-sided pvalue =0.03533\r\n\r\nThe p-value of 0.035 and the negative Tau value suggest that there is a significant trend toward earlier blooming. This indicates that the bloom dates have been shifting earlier over time.\r\nLinear Regression for Trend Analysis\r\nTo quantify the trend, a linear regression is fitted, and the trend is visualized with a regression line:\r\n\r\n\r\nx <- Alex_first$Pheno_year\r\ny <- Alex_first$JDay\r\n\r\nsummary(lm(y ~ x))\r\n\r\n\r\nCall:\r\nlm(formula = y ~ x)\r\n\r\nResiduals:\r\n     Min       1Q   Median       3Q      Max \r\n-30.0959  -6.3591  -0.5959   6.6468  20.1238 \r\n\r\nCoefficients:\r\n             Estimate Std. Error t value Pr(>|t|)   \r\n(Intercept) 429.16615  142.06000   3.021   0.0037 **\r\nx            -0.16184    0.07144  -2.266   0.0271 * \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 10.07 on 60 degrees of freedom\r\nMultiple R-squared:  0.0788,    Adjusted R-squared:  0.06345 \r\nF-statistic: 5.133 on 1 and 60 DF,  p-value: 0.0271\r\n\r\n\r\n\r\nggplot(Alex_first,\r\n       aes(Year,\r\n           JDay)) +\r\n  geom_point() +\r\n  geom_smooth(method = 'lm',\r\n              formula = y ~ x) +\r\n  ylab(\"First bloom date (day of the year)\") +\r\n  xlab (\"Year\") +\r\n  theme_bw(base_size = 15)\r\n\r\n\r\n\r\nThe estimated slope of -0.16 indicates that, on average, the bloom dates are occurring 0.16 days earlier each year.\r\nPolynomial Regression for a Complex Model\r\nA linear regression is a simple approach, but in many cases, a more complex model might be necessary. Here, a 25th-degree polynomial is used to improve the model fit.\r\n\r\n\r\nsummary(lm(y ~ poly(x, 25)))\r\n\r\n\r\nCall:\r\nlm(formula = y ~ poly(x, 25))\r\n\r\nResiduals:\r\n     Min       1Q   Median       3Q      Max \r\n-13.7311  -4.5098  -0.1227   2.8640  15.4590 \r\n\r\nCoefficients:\r\n              Estimate Std. Error t value             Pr(>|t|)    \r\n(Intercept)   107.3387     1.0549 101.753 < 0.0000000000000002 ***\r\npoly(x, 25)1  -22.8054     8.3063  -2.746              0.00937 ** \r\npoly(x, 25)2   -5.8672     8.3063  -0.706              0.48451    \r\npoly(x, 25)3   14.7725     8.3063   1.778              0.08377 .  \r\npoly(x, 25)4   -5.3974     8.3063  -0.650              0.51995    \r\npoly(x, 25)5  -11.6801     8.3063  -1.406              0.16825    \r\npoly(x, 25)6    2.1928     8.3063   0.264              0.79329    \r\npoly(x, 25)7   -0.3034     8.3063  -0.037              0.97107    \r\npoly(x, 25)8    6.0115     8.3063   0.724              0.47391    \r\npoly(x, 25)9  -22.2895     8.3063  -2.683              0.01094 *  \r\npoly(x, 25)10   5.9522     8.3063   0.717              0.47825    \r\npoly(x, 25)11  -6.1217     8.3063  -0.737              0.46590    \r\npoly(x, 25)12   3.2676     8.3063   0.393              0.69636    \r\npoly(x, 25)13 -14.8467     8.3063  -1.787              0.08229 .  \r\npoly(x, 25)14  13.5180     8.3063   1.627              0.11237    \r\npoly(x, 25)15  10.1544     8.3063   1.222              0.22946    \r\npoly(x, 25)16 -12.6116     8.3063  -1.518              0.13767    \r\npoly(x, 25)17  -1.3315     8.3063  -0.160              0.87354    \r\npoly(x, 25)18  -6.3438     8.3063  -0.764              0.45000    \r\npoly(x, 25)19  14.9753     8.3063   1.803              0.07978 .  \r\npoly(x, 25)20   3.4573     8.3063   0.416              0.67972    \r\npoly(x, 25)21 -29.1997     8.3063  -3.515              0.00121 ** \r\npoly(x, 25)22  10.4145     8.3063   1.254              0.21799    \r\npoly(x, 25)23   2.9898     8.3063   0.360              0.72100    \r\npoly(x, 25)24 -14.3045     8.3063  -1.722              0.09363 .  \r\npoly(x, 25)25 -20.9324     8.3063  -2.520              0.01631 *  \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 8.306 on 36 degrees of freedom\r\nMultiple R-squared:  0.6237,    Adjusted R-squared:  0.3623 \r\nF-statistic: 2.386 on 25 and 36 DF,  p-value: 0.008421\r\n\r\n\r\n\r\nggplot(Alex_first,\r\n       aes(Year,\r\n           JDay)) +\r\n  geom_point() +\r\n  geom_smooth(method='lm',\r\n              formula = y ~ poly(x, 25)) +\r\n  ylab(\"First bloom date (day of the year)\") +\r\n  xlab (\"Year\") +\r\n  theme_bw(base_size = 15)\r\n\r\n\r\n\r\nThe 25th-degree polynomial fits the data very well, but this is an example of overfitting, where the model becomes too complex and captures random fluctuations in the data instead of real underlying patterns.\r\nOverfitting\r\nAn overly complex model that fits the data too well can be problematic because it may capture random noise instead of genuine relationships. While a good model typically has low error, overfitting makes it difficult to generalize the model to new data.\r\np-Hacking\r\np-hacking refers to the practice of searching through large datasets to find random correlations and then presenting them as statistically significant. This practice leads to false discoveries and is considered poor scientific practice.\r\nEcological Theory\r\nTo understand phenomena like bloom dates better, it is crucial to consider the underlying ecological processes. A basic ecological theory suggests that temperature affects phenology.\r\nCausal Diagram: Time → Temperature → Phenology\r\nThe direct influence of time on phenology might be misleading, as it is not time itself that drives the bloom dates but rather changes in temperature, which are influenced by climate change:\r\nTime → Greenhouse Gas Concentrations → Climate Forcing → Temperature\r\nTemperature Correlations\r\nTo better understand the relationship between temperature and bloom dates, weather data is included. Annual average temperatures are calculated:\r\n\r\n\r\ntemperature <- read_tab(\"data/TMaxTMin1958-2019_patched.csv\")\r\n\r\nTmin <- temperature %>%\r\n  group_by(Year) %>%\r\n  summarise(Tmin = mean(Tmin))\r\n\r\nTmax <- temperature %>%\r\n  group_by(Year) %>% \r\n  summarise(Tmax = mean(Tmax))\r\n\r\nAnnual_means <- Tmin %>%\r\n  cbind(Tmax[,2]) %>%\r\n  mutate(Tmean = (Tmin + Tmax)/2)\r\n\r\nAnnual_means <- merge(Annual_means,\r\n                      Alex_first)\r\n\r\nAnnual_means_longer <- Annual_means[,c(1:4,10)] %>%\r\n  pivot_longer(cols = c(Tmin:Tmean),\r\n               names_to = \"Variable\",\r\n               values_to = \"Temp\")\r\n\r\n\r\nThese temperature data are then combined with bloom data to create a plot showing the relationship between temperature and first bloom dates.\r\nVisualizing Temperature and Bloom Date\r\n\r\n\r\nggplot(Annual_means_longer,\r\n       aes(x=Temp,\r\n           y=JDay)) + \r\n  geom_point() +\r\n  geom_smooth(method=\"lm\",\r\n              formula=y~x) + \r\n  facet_wrap(\"Variable\")\r\n\r\n\r\n\r\nThe linear regression indicates that there is a correlation between temperature and bloom date, though this correlation could be driven by climate change rather than just temperature itself.\r\nRegression Analysis for Temperature\r\nTo analyze the influence of different temperature variables (Tmin, Tmax, Tmean) on the bloom date, a linear regression is performed for each:\r\n\r\n\r\nsummary(lm(Annual_means$JDay ~ Annual_means$Tmin))\r\n\r\n\r\nCall:\r\nlm(formula = Annual_means$JDay ~ Annual_means$Tmin)\r\n\r\nResiduals:\r\n     Min       1Q   Median       3Q      Max \r\n-25.4960  -6.9227  -0.0472   6.9066  18.4940 \r\n\r\nCoefficients:\r\n                  Estimate Std. Error t value             Pr(>|t|)\r\n(Intercept)        140.288      8.610  16.293 < 0.0000000000000002\r\nAnnual_means$Tmin   -6.020      1.558  -3.864             0.000277\r\n                     \r\n(Intercept)       ***\r\nAnnual_means$Tmin ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 9.385 on 60 degrees of freedom\r\nMultiple R-squared:  0.1992,    Adjusted R-squared:  0.1859 \r\nF-statistic: 14.93 on 1 and 60 DF,  p-value: 0.0002765\r\n\r\n\r\n\r\nsummary(lm(Annual_means$JDay ~ Annual_means$Tmax))\r\n\r\n\r\nCall:\r\nlm(formula = Annual_means$JDay ~ Annual_means$Tmax)\r\n\r\nResiduals:\r\n     Min       1Q   Median       3Q      Max \r\n-28.2420  -5.7340   0.3032   5.8515  19.4918 \r\n\r\nCoefficients:\r\n                  Estimate Std. Error t value             Pr(>|t|)\r\n(Intercept)       168.5020    12.9573  13.004 < 0.0000000000000002\r\nAnnual_means$Tmax  -4.3586     0.9198  -4.739            0.0000136\r\n                     \r\n(Intercept)       ***\r\nAnnual_means$Tmax ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 8.947 on 60 degrees of freedom\r\nMultiple R-squared:  0.2723,    Adjusted R-squared:  0.2602 \r\nF-statistic: 22.45 on 1 and 60 DF,  p-value: 0.00001363\r\n\r\n\r\n\r\nsummary(lm(Annual_means$JDay ~ Annual_means$Tmean))\r\n\r\n\r\nCall:\r\nlm(formula = Annual_means$JDay ~ Annual_means$Tmean)\r\n\r\nResiduals:\r\n     Min       1Q   Median       3Q      Max \r\n-25.9808  -5.5032   0.3793   6.1267  18.1822 \r\n\r\nCoefficients:\r\n                   Estimate Std. Error t value             Pr(>|t|)\r\n(Intercept)         173.467     12.379  14.013 < 0.0000000000000002\r\nAnnual_means$Tmean   -6.780      1.264  -5.363           0.00000138\r\n                      \r\n(Intercept)        ***\r\nAnnual_means$Tmean ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 8.623 on 60 degrees of freedom\r\nMultiple R-squared:  0.324, Adjusted R-squared:  0.3128 \r\nF-statistic: 28.76 on 1 and 60 DF,  p-value: 0.000001381\r\n\r\nFunction for Temperature and Bloom Date Correlations\r\nTo better capture the effect of temperature on bloom dates, a function is developed to compute correlations over different periods.\r\n\r\n\r\ntemps_JDays <-\r\n  make_JDay(temperature)\r\n\r\ncorr_temp_pheno <- function(start_JDay, # the start JDay of the period\r\n                            end_JDay, # the start JDay of the period\r\n                            temps_JDay = temps_JDays, # the temperature dataset\r\n                            bloom = Alex_first) # a data.frame with bloom dates\r\n{\r\n  temps_JDay <- temps_JDay %>%\r\n    mutate(Season = Year)\r\n  \r\n  if(start_JDay > end_JDay)\r\n    temps_JDay$Season[temps_JDay$JDay >= start_JDay]<-\r\n      temps_JDay$Year[temps_JDay$JDay >= start_JDay]+1\r\n  \r\n  if(start_JDay > end_JDay)\r\n    sub_temps <- subset(temps_JDay,\r\n                        JDay <= end_JDay | JDay >= start_JDay)\r\n  \r\n  if(start_JDay <= end_JDay) \r\n    sub_temps <- subset(temps_JDay,\r\n                        JDay <= end_JDay & JDay >= start_JDay)\r\n  \r\n  mean_temps <- sub_temps %>%\r\n    group_by(Season) %>%\r\n    summarise(Tmin = mean(Tmin),\r\n              Tmax = mean(Tmax)) %>%\r\n    mutate(Tmean = (Tmin + Tmax)/2)\r\n  \r\n  colnames(mean_temps)[1] <- c(\"Pheno_year\")\r\n  \r\n  temps_bloom <- merge(mean_temps,\r\n                       bloom[c(\"Pheno_year\",\r\n                               \"JDay\")])\r\n  \r\n  # Let's just extract the slopes of the regression model for now\r\n  slope_Tmin <- summary(lm(temps_bloom$JDay~temps_bloom$Tmin))$coefficients[2,1]\r\n  slope_Tmean <- summary(lm(temps_bloom$JDay~temps_bloom$Tmean))$coefficients[2,1]\r\n  slope_Tmax <- summary(lm(temps_bloom$JDay~temps_bloom$Tmax))$coefficients[2,1]\r\n  \r\n  c(start_JDay = start_JDay,\r\n    end_JDay = end_JDay,\r\n    length = length(unique(sub_temps$JDay)),\r\n    slope_Tmin = slope_Tmin,\r\n    slope_Tmean = slope_Tmean,\r\n    slope_Tmax = slope_Tmax)\r\n}\r\n\r\n\r\nCalculating Correlations for Specific Periods\r\nThe function is applied to specific periods:\r\n\r\n\r\ncorr_temp_pheno(start_JDay = 305,\r\n                end_JDay = 45,\r\n                temps_JDay = temps_JDays,\r\n                bloom = Alex_first)\r\n\r\n start_JDay    end_JDay      length  slope_Tmin slope_Tmean \r\n 305.000000   45.000000  107.000000   -2.254426   -2.655599 \r\n slope_Tmax \r\n  -2.799758 \r\n\r\n\r\n\r\ncorr_temp_pheno(start_JDay = 305,\r\n                end_JDay = 29,\r\n                temps_JDay = temps_JDays,\r\n                bloom = Alex_first)\r\n\r\n start_JDay    end_JDay      length  slope_Tmin slope_Tmean \r\n 305.000000   29.000000   91.000000   -1.821312   -2.135616 \r\n slope_Tmax \r\n  -2.237499 \r\n\r\nThe function can now be applied to various reasonable day ranges. Instead of testing all possible combinations, only every 5th start and end date will be used to balance computational efficiency with thorough analysis.\r\n\r\n\r\nlibrary(colorRamps) \r\n\r\nstJDs <- seq(from = 1,\r\n             to = 366,\r\n             by = 10)\r\n\r\neJDs <- seq(from = 1,\r\n            to = 366,\r\n            by = 10)\r\n\r\nfor(stJD in stJDs)\r\n  for(eJD in eJDs)\r\n    {correlations <- corr_temp_pheno(stJD,\r\n                                     eJD)\r\n    \r\n    if(stJD == 1 & eJD == 1)\r\n      corrs <- correlations else\r\n        corrs <- rbind(corrs, correlations)\r\n}\r\n\r\n\r\nslopes <- as.data.frame(corrs) %>%\r\n  rename(Tmin = slope_Tmin,\r\n         Tmax = slope_Tmax,\r\n         Tmean = slope_Tmean) %>%\r\n  pivot_longer(cols = c(Tmin : Tmax),\r\n               values_to = \"Slope\",\r\n               names_to = \"Variable\")\r\n\r\n\r\nPlotting Correlations\r\nThe correlations between temperature and bloom dates for different periods are visualized:\r\n\r\n\r\nggplot(data = slopes,\r\n       aes(x = start_JDay,\r\n           y = length,\r\n           fill = Slope)) +\r\n  geom_tile() +\r\n  facet_wrap(vars(Variable)) +\r\n  scale_fill_gradientn(colours = matlab.like(15)) +\r\n  ylab(\"Interval duration (days)\") + \r\n  xlab(\"Start date of temperature summary interval (Day of year)\") +\r\n  theme_bw(base_size = 15)\r\n\r\n\r\n\r\nExercises on simple phenology analysis\r\nProvide a brief narrative describing what p-hacking is, and why this is a problematic approach to data analysis.\r\nP-hacking is the practice of manipulating data analysis to achieve statistically significant results, often by testing multiple hypotheses or adjusting methods until a low p-value appears. This increases the risk of false positives, leading to misleading conclusions and poor reproducibility. To avoid this, researchers should predefine hypotheses, apply proper statistical corrections, and ensure transparency.\r\nProvide a sketch of your causal understanding of the relationship between temperature and bloom dates.\r\nA simplified causal diagram for the relationship between temperature and bloom dates is:\r\nTemp_chilling → Chill accumulation → Temp_forcing → Heat accumulation → Bloom Date\r\nTemp_chilling: Cold temperatures during winter contribute to chill accumulation.\r\nChill accumulation: Trees require a certain amount of chilling to end dormancy.\r\nTemp_forcing: Warmer temperatures in spring promote heat accumulation.\r\nHeat accumulation: Once enough heat is accumulated, the tree initiates blooming.\r\nBloom Date: The final outcome, determined by the balance of chilling and forcing.\r\nWhat do we need to know to build a process-based model from this?\r\nA process-based model for bloom timing requires:\r\nChilling & Forcing: Defining cold and warm periods, selecting appropriate models, and determining temperature thresholds.\r\nTemperature Response: Understanding how trees react to temperature changes and how chilling and forcing interact.\r\nData for Calibration: Historical bloom records, temperature data, and experimental studies for validation. By parameterizing and testing, the model can be optimized for accurate predictions.\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:31:52+01:00"
    },
    {
      "path": "temp_data.html",
      "title": "Getting temperature data",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\nTemperature data is crucial for phenology and chill models, as it serves as a key input for these calculations. However, accessing weather data is often challenging due to restrictions and high costs, even when the data is publicly funded.\r\nThe chillR package facilitates access to global and California-specific weather databases, helping researchers obtain necessary temperature records.\r\nGlobal Summary of the Day (GSOD)\r\nThe National Centers for Environmental Information (NCEI) provides temperature data through the GSOD database. While retrieving data manually can be cumbersome, chillR offers a streamlined solution with the function handle_gsod().\r\nListing Weather Stations\r\nTo retrieve a list of weather stations near a specific location, sorted by proximity, use:\r\n\r\n\r\nstation_list <- handle_gsod(action = \"list_stations\", \r\n                            location = c(7.10, 50.73), \r\n                            time_interval = c(1990, 2020))\r\n\r\n\r\nThis function returns a table containing station codes, available data years, and the percentage of the selected time period covered.\r\nDownloading Weather Data\r\nOnce a suitable station is identified, its chillR_code can be used to download temperature records:\r\n\r\n\r\nweather <- handle_gsod(action = \"download_weather\", \r\n                       location = station_list$chillR_code[4], \r\n                       time_interval = c(1990,2020))\r\n\r\n\r\nThis returns a list where weather[[1]] contains metadata, and weather[[2]] holds the actual temperature dataset.\r\nCleaning Weather Data\r\nRaw GSOD data contains unnecessary variables and is recorded in Fahrenheit. chillR provides a function to clean and convert these records:\r\n\r\n\r\ncleaned_weather <- handle_gsod(weather)\r\n\r\n\r\nTemperature values are converted using the formula:\r\n\\(Temperature[°C]=(Temperature[°F]-32)\\cdot\\frac{5}{9}\\)\r\nThis results in a more usable dataset suitable for further analysis.\r\nSaving Data for Future Use\r\n\r\n\r\nwrite.csv(station_list, \"data/station_list.csv\", row.names=FALSE)\r\nwrite.csv(weather[[1]], \"data/Bonn_raw_weather.csv\", row.names=FALSE)\r\nwrite.csv(cleaned_weather[[1]], \"data/Bonn_chillR_weather.csv\", row.names=FALSE)\r\n\r\n\r\nExercises on getting temperature data\r\n\r\n\r\n\r\nChoose a location of interest and find the 25 closest weather stations using the handle_gsod function\r\n\r\n\r\nstation_list_Yakima <- handle_gsod(action = \"list_stations\",\r\n                                   location = c(long = -120.50, lat = 46.60), \r\n                                   time_interval = c(1990, 2020))\r\n\r\n\r\n\r\n\r\n\r\nchillR_code\r\n\r\n\r\nSTATION.NAME\r\n\r\n\r\nCTRY\r\n\r\n\r\nLat\r\n\r\n\r\nLong\r\n\r\n\r\nBEGIN\r\n\r\n\r\nEND\r\n\r\n\r\nDistance\r\n\r\n\r\nOverlap_years\r\n\r\n\r\nPerc_interval_covered\r\n\r\n\r\n72781024243\r\n\r\n\r\nYAKIMA AIR TERMINAL/MCALSR FIELD AP\r\n\r\n\r\nUS\r\n\r\n\r\n46.564\r\n\r\n\r\n-120.535\r\n\r\n\r\n19730101\r\n\r\n\r\n20250304\r\n\r\n\r\n4.82\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n99999924243\r\n\r\n\r\nYAKIMA AIR TERMINAL\r\n\r\n\r\nUS\r\n\r\n\r\n46.568\r\n\r\n\r\n-120.543\r\n\r\n\r\n19480101\r\n\r\n\r\n19721231\r\n\r\n\r\n4.85\r\n\r\n\r\n0.00\r\n\r\n\r\n0\r\n\r\n\r\n72781399999\r\n\r\n\r\nVAGABOND AAF / YAKIMA TRAINING CENTER WASHINGTON USA\r\n\r\n\r\nUS\r\n\r\n\r\n46.667\r\n\r\n\r\n-120.454\r\n\r\n\r\n20030617\r\n\r\n\r\n20081110\r\n\r\n\r\n8.25\r\n\r\n\r\n5.40\r\n\r\n\r\n17\r\n\r\n\r\n72056299999\r\n\r\n\r\nRANGE OP 13 / YAKIMA TRAINING CENTER\r\n\r\n\r\nUS\r\n\r\n\r\n46.800\r\n\r\n\r\n-120.167\r\n\r\n\r\n20080530\r\n\r\n\r\n20170920\r\n\r\n\r\n33.79\r\n\r\n\r\n9.31\r\n\r\n\r\n30\r\n\r\n\r\n72788399999\r\n\r\n\r\nBOWERS FLD\r\n\r\n\r\nUS\r\n\r\n\r\n47.033\r\n\r\n\r\n-120.531\r\n\r\n\r\n20000101\r\n\r\n\r\n20031231\r\n\r\n\r\n48.26\r\n\r\n\r\n4.00\r\n\r\n\r\n13\r\n\r\n\r\n72788324220\r\n\r\n\r\nBOWERS FIELD AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n47.034\r\n\r\n\r\n-120.531\r\n\r\n\r\n19880106\r\n\r\n\r\n20250304\r\n\r\n\r\n48.37\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n99999924220\r\n\r\n\r\nELLENSBURG BOWERS FI\r\n\r\n\r\nUS\r\n\r\n\r\n47.034\r\n\r\n\r\n-120.530\r\n\r\n\r\n19480601\r\n\r\n\r\n19550101\r\n\r\n\r\n48.37\r\n\r\n\r\n0.00\r\n\r\n\r\n0\r\n\r\n\r\n72784094187\r\n\r\n\r\nHANFORD AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n46.567\r\n\r\n\r\n-119.600\r\n\r\n\r\n20060101\r\n\r\n\r\n20130326\r\n\r\n\r\n68.96\r\n\r\n\r\n7.23\r\n\r\n\r\n23\r\n\r\n\r\n72784099999\r\n\r\n\r\nHANFORD\r\n\r\n\r\nUS\r\n\r\n\r\n46.567\r\n\r\n\r\n-119.600\r\n\r\n\r\n19730101\r\n\r\n\r\n19971231\r\n\r\n\r\n68.96\r\n\r\n\r\n8.00\r\n\r\n\r\n26\r\n\r\n\r\n72782594239\r\n\r\n\r\nPANGBORN MEMORIAL AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n47.397\r\n\r\n\r\n-120.201\r\n\r\n\r\n20000101\r\n\r\n\r\n20250304\r\n\r\n\r\n91.58\r\n\r\n\r\n21.00\r\n\r\n\r\n68\r\n\r\n\r\n72782599999\r\n\r\n\r\nPANGBORN MEM\r\n\r\n\r\nUS\r\n\r\n\r\n47.399\r\n\r\n\r\n-120.207\r\n\r\n\r\n19730101\r\n\r\n\r\n19971231\r\n\r\n\r\n91.69\r\n\r\n\r\n8.00\r\n\r\n\r\n26\r\n\r\n\r\n72788499999\r\n\r\n\r\nRICHLAND AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n46.306\r\n\r\n\r\n-119.304\r\n\r\n\r\n19810203\r\n\r\n\r\n20250303\r\n\r\n\r\n97.39\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n72781524237\r\n\r\n\r\nSTAMPASS PASS FLTWO\r\n\r\n\r\nUS\r\n\r\n\r\n47.277\r\n\r\n\r\n-121.337\r\n\r\n\r\n19730101\r\n\r\n\r\n20250304\r\n\r\n\r\n98.63\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n99999924237\r\n\r\n\r\nSTAMPEDE PASS\r\n\r\n\r\nUS\r\n\r\n\r\n47.277\r\n\r\n\r\n-121.337\r\n\r\n\r\n19480101\r\n\r\n\r\n19721231\r\n\r\n\r\n98.63\r\n\r\n\r\n0.00\r\n\r\n\r\n0\r\n\r\n\r\n72790024141\r\n\r\n\r\nEPHRATA MUNICIPAL AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n47.308\r\n\r\n\r\n-119.516\r\n\r\n\r\n20050101\r\n\r\n\r\n20250304\r\n\r\n\r\n108.64\r\n\r\n\r\n16.00\r\n\r\n\r\n52\r\n\r\n\r\n72782624141\r\n\r\n\r\nEPHRATA MUNICIPAL\r\n\r\n\r\nUS\r\n\r\n\r\n47.308\r\n\r\n\r\n-119.515\r\n\r\n\r\n19420101\r\n\r\n\r\n19971231\r\n\r\n\r\n108.69\r\n\r\n\r\n8.00\r\n\r\n\r\n26\r\n\r\n\r\n99999924141\r\n\r\n\r\nEPHRATA AP FCWOS\r\n\r\n\r\nUS\r\n\r\n\r\n47.308\r\n\r\n\r\n-119.515\r\n\r\n\r\n19480101\r\n\r\n\r\n19550101\r\n\r\n\r\n108.69\r\n\r\n\r\n0.00\r\n\r\n\r\n0\r\n\r\n\r\n72782724110\r\n\r\n\r\nGRANT COUNTY INTL AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n47.193\r\n\r\n\r\n-119.315\r\n\r\n\r\n19430610\r\n\r\n\r\n20250304\r\n\r\n\r\n111.73\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n72782799999\r\n\r\n\r\nMOSES LAKE/GRANT CO\r\n\r\n\r\nUS\r\n\r\n\r\n47.200\r\n\r\n\r\n-119.317\r\n\r\n\r\n20000101\r\n\r\n\r\n20031231\r\n\r\n\r\n112.06\r\n\r\n\r\n4.00\r\n\r\n\r\n13\r\n\r\n\r\n72784524163\r\n\r\n\r\nTRI-CITIES AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n46.270\r\n\r\n\r\n-119.118\r\n\r\n\r\n19730101\r\n\r\n\r\n20250304\r\n\r\n\r\n112.21\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n72784599999\r\n\r\n\r\nTRI CITIES\r\n\r\n\r\nUS\r\n\r\n\r\n46.267\r\n\r\n\r\n-119.117\r\n\r\n\r\n20000101\r\n\r\n\r\n20031231\r\n\r\n\r\n112.40\r\n\r\n\r\n4.00\r\n\r\n\r\n13\r\n\r\n\r\n99999924163\r\n\r\n\r\nPASCO NAS\r\n\r\n\r\nUS\r\n\r\n\r\n46.267\r\n\r\n\r\n-119.117\r\n\r\n\r\n19450401\r\n\r\n\r\n19460601\r\n\r\n\r\n112.40\r\n\r\n\r\n0.00\r\n\r\n\r\n0\r\n\r\n\r\n72698824219\r\n\r\n\r\nMUNICIPAL AIRPORT\r\n\r\n\r\nUS\r\n\r\n\r\n45.619\r\n\r\n\r\n-121.166\r\n\r\n\r\n19730101\r\n\r\n\r\n20250304\r\n\r\n\r\n120.70\r\n\r\n\r\n31.00\r\n\r\n\r\n100\r\n\r\n\r\n99999924219\r\n\r\n\r\nTHE DALLES MUNICIPAL ARPT\r\n\r\n\r\nUS\r\n\r\n\r\n45.619\r\n\r\n\r\n-121.166\r\n\r\n\r\n19480101\r\n\r\n\r\n19650101\r\n\r\n\r\n120.70\r\n\r\n\r\n0.00\r\n\r\n\r\n0\r\n\r\n\r\n72688399999\r\n\r\n\r\nHERMISTON MUNI\r\n\r\n\r\nUS\r\n\r\n\r\n45.828\r\n\r\n\r\n-119.259\r\n\r\n\r\n19980514\r\n\r\n\r\n20051231\r\n\r\n\r\n128.55\r\n\r\n\r\n7.64\r\n\r\n\r\n25\r\n\r\n\r\n\r\nDownload weather data for the most promising station on the list\r\n\r\n\r\nweather_Yakima <- handle_gsod(action = \"download_weather\",\r\n                              location = station_list_Yakima$chillR_code[1],\r\n                              time_interval = c(1990, 2020))\r\n\r\n\r\n\r\n\r\nweather_Yakima[[1]][1:20,]\r\n\r\n\r\n\r\n\r\n\r\nDATE\r\n\r\n\r\nDate\r\n\r\n\r\nYear\r\n\r\n\r\nMonth\r\n\r\n\r\nDay\r\n\r\n\r\nTmin\r\n\r\n\r\nTmax\r\n\r\n\r\nTmean\r\n\r\n\r\nPrec\r\n\r\n\r\nYEARMODA\r\n\r\n\r\n1990-01-01 12:00:00\r\n\r\n\r\n1990-01-01\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n1\r\n\r\n\r\n-1.722\r\n\r\n\r\n1.722\r\n\r\n\r\n-0.500\r\n\r\n\r\n0.000\r\n\r\n\r\n19900101\r\n\r\n\r\n1990-01-02 12:00:00\r\n\r\n\r\n1990-01-02\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n-5.611\r\n\r\n\r\n6.111\r\n\r\n\r\n0.056\r\n\r\n\r\n0.000\r\n\r\n\r\n19900102\r\n\r\n\r\n1990-01-03 12:00:00\r\n\r\n\r\n1990-01-03\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n3\r\n\r\n\r\n-5.611\r\n\r\n\r\n7.778\r\n\r\n\r\n0.056\r\n\r\n\r\n0.000\r\n\r\n\r\n19900103\r\n\r\n\r\n1990-01-04 12:00:00\r\n\r\n\r\n1990-01-04\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n4\r\n\r\n\r\n-3.278\r\n\r\n\r\n13.889\r\n\r\n\r\n2.444\r\n\r\n\r\n0.000\r\n\r\n\r\n19900104\r\n\r\n\r\n1990-01-05 12:00:00\r\n\r\n\r\n1990-01-05\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n-3.278\r\n\r\n\r\n13.889\r\n\r\n\r\n2.556\r\n\r\n\r\n0.000\r\n\r\n\r\n19900105\r\n\r\n\r\n1990-01-06 12:00:00\r\n\r\n\r\n1990-01-06\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n-3.278\r\n\r\n\r\n11.722\r\n\r\n\r\n6.222\r\n\r\n\r\n0.000\r\n\r\n\r\n19900106\r\n\r\n\r\n1990-01-07 12:00:00\r\n\r\n\r\n1990-01-07\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n7\r\n\r\n\r\n-2.222\r\n\r\n\r\n11.722\r\n\r\n\r\n9.000\r\n\r\n\r\n3.048\r\n\r\n\r\n19900107\r\n\r\n\r\n1990-01-08 12:00:00\r\n\r\n\r\n1990-01-08\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n8\r\n\r\n\r\n2.778\r\n\r\n\r\n12.222\r\n\r\n\r\n6.722\r\n\r\n\r\n9.652\r\n\r\n\r\n19900108\r\n\r\n\r\n1990-01-09 12:00:00\r\n\r\n\r\n1990-01-09\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n9\r\n\r\n\r\n1.111\r\n\r\n\r\n11.111\r\n\r\n\r\n4.111\r\n\r\n\r\n15.748\r\n\r\n\r\n19900109\r\n\r\n\r\n1990-01-10 12:00:00\r\n\r\n\r\n1990-01-10\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n10\r\n\r\n\r\n1.111\r\n\r\n\r\n12.222\r\n\r\n\r\n7.167\r\n\r\n\r\n2.794\r\n\r\n\r\n19900110\r\n\r\n\r\n1990-01-11 12:00:00\r\n\r\n\r\n1990-01-11\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n11\r\n\r\n\r\n0.000\r\n\r\n\r\n8.278\r\n\r\n\r\n2.778\r\n\r\n\r\n0.000\r\n\r\n\r\n19900111\r\n\r\n\r\n1990-01-12 12:00:00\r\n\r\n\r\n1990-01-12\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n12\r\n\r\n\r\n0.000\r\n\r\n\r\n6.111\r\n\r\n\r\n2.833\r\n\r\n\r\n0.254\r\n\r\n\r\n19900112\r\n\r\n\r\n1990-01-13 12:00:00\r\n\r\n\r\n1990-01-13\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n13\r\n\r\n\r\n-2.778\r\n\r\n\r\n6.111\r\n\r\n\r\n0.944\r\n\r\n\r\n0.254\r\n\r\n\r\n19900113\r\n\r\n\r\n1990-01-14 12:00:00\r\n\r\n\r\n1990-01-14\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n14\r\n\r\n\r\n-3.889\r\n\r\n\r\n5.000\r\n\r\n\r\n-0.111\r\n\r\n\r\n0.000\r\n\r\n\r\n19900114\r\n\r\n\r\n1990-01-15 12:00:00\r\n\r\n\r\n1990-01-15\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n15\r\n\r\n\r\n-3.889\r\n\r\n\r\n4.389\r\n\r\n\r\n0.889\r\n\r\n\r\n0.000\r\n\r\n\r\n19900115\r\n\r\n\r\n1990-01-16 12:00:00\r\n\r\n\r\n1990-01-16\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n16\r\n\r\n\r\n-0.611\r\n\r\n\r\n7.222\r\n\r\n\r\n3.556\r\n\r\n\r\n0.000\r\n\r\n\r\n19900116\r\n\r\n\r\n1990-01-17 12:00:00\r\n\r\n\r\n1990-01-17\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n17\r\n\r\n\r\n-4.389\r\n\r\n\r\n7.778\r\n\r\n\r\n1.111\r\n\r\n\r\n0.000\r\n\r\n\r\n19900117\r\n\r\n\r\n1990-01-18 12:00:00\r\n\r\n\r\n1990-01-18\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n18\r\n\r\n\r\n-7.778\r\n\r\n\r\n8.278\r\n\r\n\r\n-2.667\r\n\r\n\r\n0.000\r\n\r\n\r\n19900118\r\n\r\n\r\n1990-01-19 12:00:00\r\n\r\n\r\n1990-01-19\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n19\r\n\r\n\r\n-7.778\r\n\r\n\r\n3.278\r\n\r\n\r\n0.389\r\n\r\n\r\n0.000\r\n\r\n\r\n19900119\r\n\r\n\r\n1990-01-20 12:00:00\r\n\r\n\r\n1990-01-20\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n20\r\n\r\n\r\n-2.222\r\n\r\n\r\n2.222\r\n\r\n\r\n0.778\r\n\r\n\r\n0.000\r\n\r\n\r\n19900120\r\n\r\n\r\n\r\nConvert the weather data into chillR format\r\n\r\n\r\ncleaned_weather_Yakima <- handle_gsod(weather_Yakima) \r\n\r\n\r\n\r\n\r\ncleaned_weather_Yakima[[1]][1:20,]\r\n\r\n\r\n\r\n\r\n\r\nDate\r\n\r\n\r\nYear\r\n\r\n\r\nMonth\r\n\r\n\r\nDay\r\n\r\n\r\nTmin\r\n\r\n\r\nTmax\r\n\r\n\r\nTmean\r\n\r\n\r\nPrec\r\n\r\n\r\n1990-01-01\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n1\r\n\r\n\r\n-1.722\r\n\r\n\r\n1.722\r\n\r\n\r\n-0.500\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-02\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n-5.611\r\n\r\n\r\n6.111\r\n\r\n\r\n0.056\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-03\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n3\r\n\r\n\r\n-5.611\r\n\r\n\r\n7.778\r\n\r\n\r\n0.056\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-04\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n4\r\n\r\n\r\n-3.278\r\n\r\n\r\n13.889\r\n\r\n\r\n2.444\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-05\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n5\r\n\r\n\r\n-3.278\r\n\r\n\r\n13.889\r\n\r\n\r\n2.556\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-06\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\n-3.278\r\n\r\n\r\n11.722\r\n\r\n\r\n6.222\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-07\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n7\r\n\r\n\r\n-2.222\r\n\r\n\r\n11.722\r\n\r\n\r\n9.000\r\n\r\n\r\n3.048\r\n\r\n\r\n1990-01-08\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n8\r\n\r\n\r\n2.778\r\n\r\n\r\n12.222\r\n\r\n\r\n6.722\r\n\r\n\r\n9.652\r\n\r\n\r\n1990-01-09\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n9\r\n\r\n\r\n1.111\r\n\r\n\r\n11.111\r\n\r\n\r\n4.111\r\n\r\n\r\n15.748\r\n\r\n\r\n1990-01-10\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n10\r\n\r\n\r\n1.111\r\n\r\n\r\n12.222\r\n\r\n\r\n7.167\r\n\r\n\r\n2.794\r\n\r\n\r\n1990-01-11\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n11\r\n\r\n\r\n0.000\r\n\r\n\r\n8.278\r\n\r\n\r\n2.778\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-12\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n12\r\n\r\n\r\n0.000\r\n\r\n\r\n6.111\r\n\r\n\r\n2.833\r\n\r\n\r\n0.254\r\n\r\n\r\n1990-01-13\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n13\r\n\r\n\r\n-2.778\r\n\r\n\r\n6.111\r\n\r\n\r\n0.944\r\n\r\n\r\n0.254\r\n\r\n\r\n1990-01-14\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n14\r\n\r\n\r\n-3.889\r\n\r\n\r\n5.000\r\n\r\n\r\n-0.111\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-15\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n15\r\n\r\n\r\n-3.889\r\n\r\n\r\n4.389\r\n\r\n\r\n0.889\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-16\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n16\r\n\r\n\r\n-0.611\r\n\r\n\r\n7.222\r\n\r\n\r\n3.556\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-17\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n17\r\n\r\n\r\n-4.389\r\n\r\n\r\n7.778\r\n\r\n\r\n1.111\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-18\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n18\r\n\r\n\r\n-7.778\r\n\r\n\r\n8.278\r\n\r\n\r\n-2.667\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-19\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n19\r\n\r\n\r\n-7.778\r\n\r\n\r\n3.278\r\n\r\n\r\n0.389\r\n\r\n\r\n0.000\r\n\r\n\r\n1990-01-20\r\n\r\n\r\n1990\r\n\r\n\r\n1\r\n\r\n\r\n20\r\n\r\n\r\n-2.222\r\n\r\n\r\n2.222\r\n\r\n\r\n0.778\r\n\r\n\r\n0.000\r\n\r\n\r\n\r\n\r\n\r\ndir.create(\"Yakima\")\r\nwrite.csv(station_list_Yakima,\"Yakima/station_list.csv\", row.names = FALSE)\r\nwrite.csv(weather_Yakima[[1]],\"Yakima/raw_weather.csv\", row.names = FALSE)\r\nwrite.csv(cleaned_weather_Yakima[[1]],\"Yakima/chillR_weather.csv\", row.names = FALSE)\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:32:14+01:00"
    },
    {
      "path": "tools.html",
      "title": "Some useful tools in R",
      "author": [],
      "contents": "\r\nAn evolving language - and a lifelong learning process\r\nThe R universe is continuously evolving, offering more than just its original base functions. Over time, modern tools and more elegant programming styles have become integral. In the upcoming chapters, we will introduce some of these new tools, along with the basics required to use them effectively.\r\nThe tidyverse\r\nMany of the tools introduced here come from the tidyverse – a collection of packages developed by Hadley Wickham and his team. This collection offers numerous ways to improve programming skills. In this book, only the functions that are directly used will be covered. A major advantage of the tidyverse is that with a single command – library(tidyverse) – all functions in the package collection become available.\r\nThe ggplot2 package\r\nThe ggplot2 package, first released by Hadley Wickham in 2007, has become one of the most popular R packages because it significantly simplifies the creation of attractive graphics. The package history can be found here, and an introduction with links to various tutorials is available here.\r\nThe tibble package\r\nA tibble is an enhanced version of a data.frame offering several improvements. The most notable improvement is that tibbles avoid the common data.frame behavior of unexpectedly converting strings into factors. Although tibbles are relatively new here, they will be used throughout the rest of the book.\r\nTo create a tibble from a regular data.frame (or a similar structure), the as_tibble command can be used:\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\n\r\n\r\ndat <- data.frame(a = c(1, 2, 3), b = c(4, 5, 6))\r\nd <- as_tibble(dat)\r\nd\r\n\r\n# A tibble: 3 × 2\r\n      a     b\r\n  <dbl> <dbl>\r\n1     1     4\r\n2     2     5\r\n3     3     6\r\n\r\nThe magrittr package - pipes\r\nMagrittr helps organize steps applied to the same dataset by using the pipe operator %>%. This operator links multiple operations on a data structure, such as a tibble, making it easier to perform tasks like calculating the sum of all numbers in the dataset:\r\n\r\n\r\nd %>% sum()\r\n\r\n[1] 21\r\n\r\nAfter the pipe operator %>%, the next function automatically takes the piped-in data as its first input, so it’s unnecessary to specify it explicitly. Additional commands can be chained by adding more pipes, allowing for building more complex workflows, as shown in examples later.\r\nThe tidyr package\r\nThe tidyr package offers helpful functions for organizing data. The KA_weather dataset from chillR will be used here to illustrate some of these functions:\r\n\r\n\r\nlibrary(chillR)\r\n\r\n\r\n\r\n\r\nKAw <- as_tibble(KA_weather[1:10,])\r\nKAw\r\n\r\n# A tibble: 10 × 5\r\n    Year Month   Day  Tmax  Tmin\r\n   <int> <int> <int> <dbl> <dbl>\r\n 1  1998     1     1   8.2   5.1\r\n 2  1998     1     2   9.1   5  \r\n 3  1998     1     3  10.4   3.3\r\n 4  1998     1     4   8.4   4.5\r\n 5  1998     1     5   7.7   4.5\r\n 6  1998     1     6   8.1   4.4\r\n 7  1998     1     7  12     6.9\r\n 8  1998     1     8  11.2   8.6\r\n 9  1998     1     9  13.9   8.5\r\n10  1998     1    10  14.5   3.6\r\n\r\npivot_longer\r\nThe pivot_longer function reshapes data from separate columns (like Tmin and Tmax) into individual rows. This transformation is often necessary for tasks like plotting data with the ggplot2 package. The function can be combined with a pipe for a streamlined workflow:\r\n\r\n\r\nKAwlong <- KAw %>% pivot_longer(cols = Tmax:Tmin)\r\nKAwlong\r\n\r\n# A tibble: 20 × 5\r\n    Year Month   Day name  value\r\n   <int> <int> <int> <chr> <dbl>\r\n 1  1998     1     1 Tmax    8.2\r\n 2  1998     1     1 Tmin    5.1\r\n 3  1998     1     2 Tmax    9.1\r\n 4  1998     1     2 Tmin    5  \r\n 5  1998     1     3 Tmax   10.4\r\n 6  1998     1     3 Tmin    3.3\r\n 7  1998     1     4 Tmax    8.4\r\n 8  1998     1     4 Tmin    4.5\r\n 9  1998     1     5 Tmax    7.7\r\n10  1998     1     5 Tmin    4.5\r\n11  1998     1     6 Tmax    8.1\r\n12  1998     1     6 Tmin    4.4\r\n13  1998     1     7 Tmax   12  \r\n14  1998     1     7 Tmin    6.9\r\n15  1998     1     8 Tmax   11.2\r\n16  1998     1     8 Tmin    8.6\r\n17  1998     1     9 Tmax   13.9\r\n18  1998     1     9 Tmin    8.5\r\n19  1998     1    10 Tmax   14.5\r\n20  1998     1    10 Tmin    3.6\r\n\r\npivot_wider\r\nThe pivot_wider function allows for the opposite transformation of pivot_longer, converting rows back into separate columns:\r\n\r\n\r\nKAwwide <- KAwlong %>% pivot_wider(names_from = name) \r\nKAwwide\r\n\r\n# A tibble: 10 × 5\r\n    Year Month   Day  Tmax  Tmin\r\n   <int> <int> <int> <dbl> <dbl>\r\n 1  1998     1     1   8.2   5.1\r\n 2  1998     1     2   9.1   5  \r\n 3  1998     1     3  10.4   3.3\r\n 4  1998     1     4   8.4   4.5\r\n 5  1998     1     5   7.7   4.5\r\n 6  1998     1     6   8.1   4.4\r\n 7  1998     1     7  12     6.9\r\n 8  1998     1     8  11.2   8.6\r\n 9  1998     1     9  13.9   8.5\r\n10  1998     1    10  14.5   3.6\r\n\r\nselect\r\nThe select function allows users to choose a subset of columns from a data.frame or tibble:\r\n\r\n\r\nKAw %>% select(c(Month, Day, Tmax))\r\n\r\n# A tibble: 10 × 3\r\n   Month   Day  Tmax\r\n   <int> <int> <dbl>\r\n 1     1     1   8.2\r\n 2     1     2   9.1\r\n 3     1     3  10.4\r\n 4     1     4   8.4\r\n 5     1     5   7.7\r\n 6     1     6   8.1\r\n 7     1     7  12  \r\n 8     1     8  11.2\r\n 9     1     9  13.9\r\n10     1    10  14.5\r\n\r\nfilter\r\nThe filter function reduces a data.frame or tibble to just the rows that fulfill certain conditions:\r\n\r\n\r\nKAw %>% filter(Tmax > 10)\r\n\r\n# A tibble: 5 × 5\r\n   Year Month   Day  Tmax  Tmin\r\n  <int> <int> <int> <dbl> <dbl>\r\n1  1998     1     3  10.4   3.3\r\n2  1998     1     7  12     6.9\r\n3  1998     1     8  11.2   8.6\r\n4  1998     1     9  13.9   8.5\r\n5  1998     1    10  14.5   3.6\r\n\r\nmutate\r\nThe mutate function is essential for creating, modifying, and deleting columns in a data.frame or tibble. For example, it can be used to add new columns, such as converting Tmin and Tmax to Kelvin:\r\n\r\n\r\nKAw_K <- KAw %>% mutate(Tmax_K = Tmax + 273.15, Tmin_K = Tmin + 273.15)\r\nKAw_K\r\n\r\n# A tibble: 10 × 7\r\n    Year Month   Day  Tmax  Tmin Tmax_K Tmin_K\r\n   <int> <int> <int> <dbl> <dbl>  <dbl>  <dbl>\r\n 1  1998     1     1   8.2   5.1   281.   278.\r\n 2  1998     1     2   9.1   5     282.   278.\r\n 3  1998     1     3  10.4   3.3   284.   276.\r\n 4  1998     1     4   8.4   4.5   282.   278.\r\n 5  1998     1     5   7.7   4.5   281.   278.\r\n 6  1998     1     6   8.1   4.4   281.   278.\r\n 7  1998     1     7  12     6.9   285.   280.\r\n 8  1998     1     8  11.2   8.6   284.   282.\r\n 9  1998     1     9  13.9   8.5   287.   282.\r\n10  1998     1    10  14.5   3.6   288.   277.\r\n\r\nTo delete the columns created with mutate, you can set them to NULL:\r\n\r\n\r\nKAw_K %>% mutate(Tmin_K = NULL, Tmax_K = NULL)\r\n\r\n# A tibble: 10 × 5\r\n    Year Month   Day  Tmax  Tmin\r\n   <int> <int> <int> <dbl> <dbl>\r\n 1  1998     1     1   8.2   5.1\r\n 2  1998     1     2   9.1   5  \r\n 3  1998     1     3  10.4   3.3\r\n 4  1998     1     4   8.4   4.5\r\n 5  1998     1     5   7.7   4.5\r\n 6  1998     1     6   8.1   4.4\r\n 7  1998     1     7  12     6.9\r\n 8  1998     1     8  11.2   8.6\r\n 9  1998     1     9  13.9   8.5\r\n10  1998     1    10  14.5   3.6\r\n\r\nNext, the original temperature values will be replaced directly with their corresponding Kelvin values:\r\n\r\n\r\nKAw %>% mutate(Tmin = Tmin + 273.15, Tmax = Tmax + 273.15)\r\n\r\n# A tibble: 10 × 5\r\n    Year Month   Day  Tmax  Tmin\r\n   <int> <int> <int> <dbl> <dbl>\r\n 1  1998     1     1  281.  278.\r\n 2  1998     1     2  282.  278.\r\n 3  1998     1     3  284.  276.\r\n 4  1998     1     4  282.  278.\r\n 5  1998     1     5  281.  278.\r\n 6  1998     1     6  281.  278.\r\n 7  1998     1     7  285.  280.\r\n 8  1998     1     8  284.  282.\r\n 9  1998     1     9  287.  282.\r\n10  1998     1    10  288.  277.\r\n\r\narrange\r\nThe arrange function sorts data in data.frames or tibbles:\r\n\r\n\r\nKAw %>% arrange(Tmax, Tmin)\r\n\r\n# A tibble: 10 × 5\r\n    Year Month   Day  Tmax  Tmin\r\n   <int> <int> <int> <dbl> <dbl>\r\n 1  1998     1     5   7.7   4.5\r\n 2  1998     1     6   8.1   4.4\r\n 3  1998     1     1   8.2   5.1\r\n 4  1998     1     4   8.4   4.5\r\n 5  1998     1     2   9.1   5  \r\n 6  1998     1     3  10.4   3.3\r\n 7  1998     1     8  11.2   8.6\r\n 8  1998     1     7  12     6.9\r\n 9  1998     1     9  13.9   8.5\r\n10  1998     1    10  14.5   3.6\r\n\r\nIt can also sort in descending order:\r\n\r\n\r\nKAw %>% arrange(desc(Tmax), Tmin)\r\n\r\n# A tibble: 10 × 5\r\n    Year Month   Day  Tmax  Tmin\r\n   <int> <int> <int> <dbl> <dbl>\r\n 1  1998     1    10  14.5   3.6\r\n 2  1998     1     9  13.9   8.5\r\n 3  1998     1     7  12     6.9\r\n 4  1998     1     8  11.2   8.6\r\n 5  1998     1     3  10.4   3.3\r\n 6  1998     1     2   9.1   5  \r\n 7  1998     1     4   8.4   4.5\r\n 8  1998     1     1   8.2   5.1\r\n 9  1998     1     6   8.1   4.4\r\n10  1998     1     5   7.7   4.5\r\n\r\nLoops\r\nUnderstanding loops is essential for efficient coding. Loops enable the repetition of operations multiple times without needing to retype or copy-paste code. There are two primary types of loops: for loops and while loops.\r\nFor loops\r\nIn a for loop, explicit instructions dictate how many times the code inside the loop should be executed, based on a vector or list of elements:\r\n\r\n\r\nfor (i in 1:3) print(\"Hello\")\r\n\r\n[1] \"Hello\"\r\n[1] \"Hello\"\r\n[1] \"Hello\"\r\n\r\nThis code executes the loop three times, printing “Hello” each time. A more complex example uses multiple lines inside curly brackets:\r\n\r\n\r\naddition <- 1\r\n\r\nfor (i in 1:3)\r\n{\r\n  addition <- addition + 1\r\n  print(addition)\r\n}\r\n\r\n[1] 2\r\n[1] 3\r\n[1] 4\r\n\r\nYou can also use a variable such as i in more creative ways within the loop:\r\n\r\n\r\nnames <- c(\"Paul\", \"Mary\", \"John\")\r\n\r\nfor (i in 1:3)\r\n{\r\n  print(paste(\"Hello\", names[i]))\r\n}\r\n\r\n[1] \"Hello Paul\"\r\n[1] \"Hello Mary\"\r\n[1] \"Hello John\"\r\n\r\nWhile loops\r\nA while loop continues until a condition is no longer met:\r\n\r\n\r\ncond <- 5\r\n\r\nwhile (cond > 0)\r\n{\r\n  print(cond)\r\n  cond <- cond - 1\r\n}\r\n\r\n[1] 5\r\n[1] 4\r\n[1] 3\r\n[1] 2\r\n[1] 1\r\n\r\napply functions\r\nR offers a more efficient way to perform operations on multiple elements simultaneously using functions from the apply family: apply, lapply, and sapply. These functions require two key arguments: the list of items to apply the operation to and the operation itself.\r\nsapply\r\nThe sapply function is used to apply an operation to a vector:\r\n\r\n\r\nfunc <- function(x) x + 1\r\nsapply(1:5, func)\r\n\r\n[1] 2 3 4 5 6\r\n\r\nlapply\r\nThe lapply function returns a list as the output, even if the input is a vector:\r\n\r\n\r\nlapply(1:5, func)\r\n\r\n[[1]]\r\n[1] 2\r\n\r\n[[2]]\r\n[1] 3\r\n\r\n[[3]]\r\n[1] 4\r\n\r\n[[4]]\r\n[1] 5\r\n\r\n[[5]]\r\n[1] 6\r\n\r\napply\r\nThe apply function is designed for arrays, allowing operations to be performed either on rows (MARGIN = 1) or columns (MARGIN = 2):\r\n\r\n\r\nmat <- matrix(c(1, 1, 1, 2, 2, 2, 3, 3, 3), c(3, 3))\r\napply(mat, MARGIN = 1, sum) # sum of rows\r\n\r\n[1] 6 6 6\r\n\r\napply(mat, MARGIN = 2, sum) # sum of columns\r\n\r\n[1] 3 6 9\r\n\r\nExercises on useful R tools\r\nBased on the Winters_hours_gaps dataset, use magrittr pipes and functions of the tidyverse to accomplish the following:\r\nConvert the dataset into a tibble\r\n\r\nSelect only the top 10 rows of the dataset\r\n\r\n\r\n\r\nWHG <- as_tibble(Winters_hours_gaps[1:10, ])\r\nWHG\r\n\r\n# A tibble: 10 × 6\r\n    Year Month   Day  Hour Temp_gaps  Temp\r\n   <int> <int> <int> <int>     <dbl> <dbl>\r\n 1  2008     3     3    10      15.1  15.1\r\n 2  2008     3     3    11      17.2  17.2\r\n 3  2008     3     3    12      18.7  18.7\r\n 4  2008     3     3    13      18.7  18.7\r\n 5  2008     3     3    14      18.8  18.8\r\n 6  2008     3     3    15      19.5  19.5\r\n 7  2008     3     3    16      19.3  19.3\r\n 8  2008     3     3    17      17.7  17.7\r\n 9  2008     3     3    18      15.4  15.4\r\n10  2008     3     3    19      12.7  12.7\r\n\r\nConvert the tibble to a long format, with separate rows for Temp_gaps and Temp\r\n\r\nTo see the difference between the columns Temp_gaps and Temp, rows 279 to 302 (Julian Day 15) are used below:\r\n\r\n\r\nWHG <- as_tibble(Winters_hours_gaps[279:302, ])\r\nWHGlong <- WHG %>% pivot_longer(cols = Temp_gaps:Temp)\r\nWHGlong\r\n\r\n# A tibble: 48 × 6\r\n    Year Month   Day  Hour name      value\r\n   <int> <int> <int> <int> <chr>     <dbl>\r\n 1  2008     3    15     0 Temp_gaps  6.76\r\n 2  2008     3    15     0 Temp       6.76\r\n 3  2008     3    15     1 Temp_gaps  6.48\r\n 4  2008     3    15     1 Temp       6.48\r\n 5  2008     3    15     2 Temp_gaps  5.51\r\n 6  2008     3    15     2 Temp       5.51\r\n 7  2008     3    15     3 Temp_gaps  6.89\r\n 8  2008     3    15     3 Temp       6.89\r\n 9  2008     3    15     4 Temp_gaps  6.10\r\n10  2008     3    15     4 Temp       6.10\r\n# ℹ 38 more rows\r\n\r\nUse ggplot2 to plot Temp_gaps and Temp as facets (point or line plot)\r\n\r\n\r\n\r\nggplot(WHGlong, aes(Hour, value)) +\r\n  geom_line(lwd = 1.5) +\r\n  facet_grid(cols = vars(name)) +\r\n  ylab(\"Temperature (°C)\") +\r\n  theme_bw(base_size = 15)\r\n\r\n\r\n\r\nConvert the dataset back to the wide format\r\n\r\n\r\n\r\nWHGwide <- WHGlong %>% pivot_wider(names_from = name)\r\nWHGwide\r\n\r\n# A tibble: 24 × 6\r\n    Year Month   Day  Hour Temp_gaps  Temp\r\n   <int> <int> <int> <int>     <dbl> <dbl>\r\n 1  2008     3    15     0      6.76  6.76\r\n 2  2008     3    15     1      6.48  6.48\r\n 3  2008     3    15     2      5.51  5.51\r\n 4  2008     3    15     3      6.89  6.89\r\n 5  2008     3    15     4      6.10  6.10\r\n 6  2008     3    15     5     NA     6.91\r\n 7  2008     3    15     6     NA     6.10\r\n 8  2008     3    15     7     NA     5.98\r\n 9  2008     3    15     8     NA     8.99\r\n10  2008     3    15     9     10.8  10.8 \r\n# ℹ 14 more rows\r\n\r\nSelect only the following columns: Year, Month, Day and Temp\r\n\r\n\r\n\r\nWHG %>% select(c(Year, Month, Day, Temp))\r\n\r\n# A tibble: 24 × 4\r\n    Year Month   Day  Temp\r\n   <int> <int> <int> <dbl>\r\n 1  2008     3    15  6.76\r\n 2  2008     3    15  6.48\r\n 3  2008     3    15  5.51\r\n 4  2008     3    15  6.89\r\n 5  2008     3    15  6.10\r\n 6  2008     3    15  6.91\r\n 7  2008     3    15  6.10\r\n 8  2008     3    15  5.98\r\n 9  2008     3    15  8.99\r\n10  2008     3    15 10.8 \r\n# ℹ 14 more rows\r\n\r\nSort the dataset by the Temp column, in descending order\r\n\r\n\r\n\r\nWHG %>% arrange(desc(Temp))\r\n\r\n# A tibble: 24 × 6\r\n    Year Month   Day  Hour Temp_gaps  Temp\r\n   <int> <int> <int> <int>     <dbl> <dbl>\r\n 1  2008     3    15    13      NA    15.2\r\n 2  2008     3    15    16      14.5  14.5\r\n 3  2008     3    15    14      NA    14.2\r\n 4  2008     3    15    12      NA    14.2\r\n 5  2008     3    15    15      14.1  14.1\r\n 6  2008     3    15    11      NA    13.6\r\n 7  2008     3    15    17      13.3  13.3\r\n 8  2008     3    15    18      12.1  12.1\r\n 9  2008     3    15    10      12.0  12.0\r\n10  2008     3    15     9      10.8  10.8\r\n# ℹ 14 more rows\r\n\r\nFor the Winter_hours_gaps dataset, write a for loop to convert all temperatures (Temp column) to degrees Fahrenheit\r\nSo that the execution of the following code does not take too long, only Julian Day 15 (rows 279 to 302) is used here. To convert the entire Temp column to Fahrenheit, just omit [279:302]\r\n\r\n\r\nTemp <- Winters_hours_gaps$Temp[279:302]\r\n\r\nfor (i in Temp)\r\n{\r\n  Fahrenheit <- i * 1.8 + 32 \r\n  print(Fahrenheit)\r\n}\r\n\r\n[1] 44.1734\r\n[1] 43.6712\r\n[1] 41.9252\r\n[1] 44.4002\r\n[1] 42.9836\r\n[1] 44.4452\r\n[1] 42.9836\r\n[1] 42.755\r\n[1] 48.182\r\n[1] 51.3698\r\n[1] 53.69\r\n[1] 56.4692\r\n[1] 57.506\r\n[1] 59.4446\r\n[1] 57.5492\r\n[1] 57.3332\r\n[1] 58.1522\r\n[1] 55.9058\r\n[1] 53.8196\r\n[1] 49.4708\r\n[1] 47.6474\r\n[1] 47.3342\r\n[1] 48.182\r\n[1] 47.7806\r\n\r\nExecute the same operation with a function from the apply family\r\nHere it is the same as in 2, just omit [279:302] to convert the entire Temp column\r\n\r\n\r\nx <- Winters_hours_gaps$Temp\r\n\r\nfahrenheit <- function(x)\r\n  x * 1.8 + 32\r\n\r\nsapply(x[279:302], fahrenheit)\r\n\r\n [1] 44.1734 43.6712 41.9252 44.4002 42.9836 44.4452 42.9836 42.7550\r\n [9] 48.1820 51.3698 53.6900 56.4692 57.5060 59.4446 57.5492 57.3332\r\n[17] 58.1522 55.9058 53.8196 49.4708 47.6474 47.3342 48.1820 47.7806\r\n\r\nNow use the tidyverse function mutate to achieve the same outcome\r\n\r\n\r\nWHG_F <- WHG %>% mutate(Temp_F = Temp * 1.8 + 32)\r\nWHG_F\r\n\r\n# A tibble: 24 × 7\r\n    Year Month   Day  Hour Temp_gaps  Temp Temp_F\r\n   <int> <int> <int> <int>     <dbl> <dbl>  <dbl>\r\n 1  2008     3    15     0      6.76  6.76   44.2\r\n 2  2008     3    15     1      6.48  6.48   43.7\r\n 3  2008     3    15     2      5.51  5.51   41.9\r\n 4  2008     3    15     3      6.89  6.89   44.4\r\n 5  2008     3    15     4      6.10  6.10   43.0\r\n 6  2008     3    15     5     NA     6.91   44.4\r\n 7  2008     3    15     6     NA     6.10   43.0\r\n 8  2008     3    15     7     NA     5.98   42.8\r\n 9  2008     3    15     8     NA     8.99   48.2\r\n10  2008     3    15     9     10.8  10.8    51.4\r\n# ℹ 14 more rows\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:32:46+01:00"
    },
    {
      "path": "tree_dormancy.html",
      "title": "Tree dormancy in temperate fruit trees",
      "author": [],
      "contents": "\r\nThis chapter explores dormancy in temperate fruit trees. This topic remains complex and has many unanswered questions. A central question for researchers is, “How do trees know when to flower?” Although it seems clear that trees bloom in spring, the reality is more complicated. This chapter provides a better understanding of dormancy and demonstrates how to use the chillR tool to predict flowering times, even in the face of challenges posed by global warming.\r\nDormancy definition\r\nTree dormancy is a state of reduced activity that occurs when environmental conditions are unfavorable, especially during winter. This state acts as a survival strategy, helping trees withstand extreme temperatures, water shortages, and other stress factors. During dormancy, trees slow down or stop their growth to conserve energy and avoid damage. Dormancy is a continuous process divided into three phases:\r\nDormancy Establishment\r\nDormancy establishment is the process where temperate trees transition from active growth in summer to a dormant state in autumn. This shift is mainly triggered by shorter daylight hours and decreasing temperatures, causing buds to form, growth to stop, and leaves to fall. The importance of these factors varies by species, with some trees responding more to day length and others to temperature.\r\nEndo-dormancy\r\nEndo-dormancy is a phase of dormancy controlled by the plant’s internal factors, where growth is suppressed even under favorable conditions. It requires a period of cold exposure (chilling) to release the buds from this state, preventing premature growth during temporary warm spells in winter. Low temperatures are the main trigger for breaking endo-dormancy, while the role of light (photoperiod) is still uncertain.\r\nEco-dormancy\r\nEco-dormancy is the phase after endo-dormancy, where buds have regained their ability to grow but remain inactive due to unfavorable environmental conditions, mainly low temperatures. During this phase, growth is on hold until warmer temperatures trigger it. Heat accumulation is needed to resume growth. Eco-dormancy ends when enough heat has been accumulated, leading to visible growth changes, typically in late winter or early spring.\r\nThe below video Introduction to dormancy by Dr. Erica Fadón gives the basic knowledge of this dormancy phases and processes that regulate dormancy.\r\n\r\n\r\n\r\n\r\nDormancy physiology\r\nDormancy as a whole is the result of complex interactions between numerous physiological processes that occur in different parts of the tree, such as buds, twigs, meristems, and vascular tissues. We divide these processes into four main themes:\r\nTransport: occurs at both the whole-plant and cellular levels\r\nPhytohormone Dynamics: behavior and levels of plant hormones during dormancy\r\nGenetic and Epigenetic Regulation: how genetic factors and their modifications influence dormancy\r\nDynamics of Nonstructural Carbohydrates: changes in carbohydrate levels that affect dormancy\r\nThe following figure from the study “A conceptual framework for Winter Dormancy in Deciduous Trees” by Fadón et al. (2015) presents a conceptual framework of winter dormancy in deciduous trees and summarizes the three dormancy phases along with their respective physiological processes.\r\nConceptual framework of winter dormancy in deciduous trees. The dormancy framework (gray background) indicates three main phases: (a) dormancy establishment (light gray), (b) endo-dormancy (dark gray), and (c) eco-dormancy (medium gray). For each phase (a–c), the dormancy-related physiological processes are represented by colored shapes and numbers (0 to 4).All the processes depicted are explained in detail in the video below, Dormancy Physiology by Dr. Erica Fadón.\r\n\r\n\r\n\r\n\r\nExperimental and statistical determination of chilling and forcing periods\r\nDormancy consists of two phases where temperatures have opposite effects on flowering. During endodormancy, higher chill accumulation leads to earlier flowering, whereas similar cool temperatures during ecodormancy can delay flowering. The challenge lies in differentiating between these two phases, as the tree buds appear to be in the same developmental stage throughout. To address this, there are two methods available:\r\nExperimental method: collecting buds periodically during winter, exposing them to favorable growth conditions, and evaluating bud break to determine when dormancy is overcome\r\nStatistical method: uses long-term phenological data and temperature records to estimate the dates of chilling fulfillment and heat accumulation through partial least squares (PLS) regression analysis\r\nThe video Dormancy determination covers the experimental and statistical methods to determine the chilling and forcing periods for temperate fruit trees to overcome dormancy and initiate growth. It explains the concept of dormancy, its phases (endodormancy and ecodormancy), and the temperature requirements for breaking dormancy.\r\n\r\n\r\n\r\n\r\nPhenology record and BBCH scale\r\nPhenology is the study of periodic events in biological life cycles and how these are influenced by seasonal and interannual variations in climate. This module will involve working with phenology data sets, primarily focusing on a specific stage, usually budbreak, even though trees pass through various developmental stages during the year. These stages are typically identified by numerical codes.\r\nTo describe these growth stages systematically, the BBCH scale is employed. This internationally standardized system outlines the growth and developmental phases of plants. The BBCH scale consists of ten main stages, known as principal growth stages, which are numbered from 0 to 9. Each of these main stages is further divided into substages, enabling a more detailed description of a plant’s development.\r\nPrincipal growth stages:\r\nStage\r\nDescription\r\n0\r\nGermination / sprouting / bud development\r\n1\r\nLeaf development (main shoot)\r\n2\r\nFormation of side shoots / tillering\r\n3\r\nStem elongation or rosette growth / shoot development (main shoot)\r\n4\r\nDevelopment of harvestable vegetative plant parts or vegetatively propagated organs / booting (main shoot)\r\n5\r\nInflorescence emergence\r\n6\r\nFlowering (main shoot)\r\n7\r\nDevelopment of fruit\r\n8\r\nRipening or maturity of fruit and seed\r\n9\r\nSenescence, beginning of dormancy\r\nFor a comprehensive overview of phenology and the BBCH scale, the video Phenology by Dr. Erica Fadón is recommended. In this video, Dr. Fadón explains the concept of phenology and how the BBCH scale uses numerical codes to represent the different developmental stages of trees, from budding and flowering to fruit ripening and leaf fall.\r\n\r\n\r\n\r\n\r\nExcercises on tree dormancy\r\nPut yourself in the place of a breeder who wants to calculate the temperature requirements of a newly released cultivar. Which method will you use to calculate the chilling and forcing periods? Please justify your answer.\r\nAs a breeder aiming to calculate the temperature requirements for the chilling and forcing periods of a newly released cultivar, I would use the experimental method to determine the chilling and forcing periods. Here’s my justification:\r\nDirect measurement of bud response: The experimental method allows me to directly observe when buds break under controlled temperature conditions. By regularly collecting buds during winter and placing them in ideal growth conditions, I can determine exactly when dormancy ends. This practical approach gives me quick and useful information about the specific cultivar\r\nSpecific to the cultivar: Each cultivar has its own unique chilling and forcing needs. The experimental method looks at the specific traits of the new cultivar, making sure the results are relevant and applicable to that variety\r\nImmediate results for breeding decisions: The experimental method provides quick evaluations of bud break, allowing me to make faster decisions about breeding and managing the new cultivar\r\nWhich are the advantages (2) of the BBCH scale compared with earlier scales?\r\nStandardization: The BBCH scale provides a standardized framework for describing plant growth stages, enabling consistent communication and comparisons across studies\r\nDetailed Staging: It offers a more granular categorization of developmental stages using a two-digit system, allowing for a better understanding of plant development and environmental impacts.\r\nClassify the following phenological stages of sweet cherry according to the BBCH scale:\r\n\r\nleft image: BBCH stage 55 (single flower buds visible (still closed), green scales slightly open)\r\nmiddle image: BBCH stage 65 (full flowering: at least 50% of flowers open, first petals falling)\r\nright image: BBCH stage 89 (fruit ripe for harvesting)\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:32:53+01:00"
    },
    {
      "path": "winter_chill.html",
      "title": "Winter chill projections",
      "author": [],
      "contents": "\r\nThis section provides an overview of how winter chill can be modeled. It summarizes past studies on this topic, aiming to clarify the methodological aspects that lead to the analyses conducted. By the end of this lesson, most of the analyses presented in the discussed papers should be understandable.\r\nWinter chill in Oman\r\nDuring his doctoral studies at the University of Kassel, Prof. Dr. Eike Lüdeling became interested in winter chill while participating in research on mountain oases in Oman. Initially focused on calculating nutrient budgets for the oases, particularly in the “Hanging Gardens” of Ash Sharayjah, the study shifted when many fruit trees failed to bear fruit. This led to the hypothesis that insufficient winter chill might be the issue, especially since the oases hosted temperate species such as pomegranates (Punica granatum), walnuts (Juglans regia), and apricots (Prunus armeniaca).\r\nTo investigate this, temperature loggers were placed in three oases at different levels of elevation, allowing for the study of chill accumulation along an elevation gradient. A map of the study area illustrates the locations of the oases:\r\nMap of oasis systems in Al Jabal Al Akhdar, OmanA nearby long-term weather station provided valuable data, although its location - 1000 meters above the lowest oasis - limited its representativeness. Since records were available from the oases, transfer functions were defined to derive oasis temperatures from the long-term data. These transfer functions were set up using PLS regression, which, in hindsight, wasn’t a very good idea, to directly calculate hourly temperatures in the oases from the daily records of the official station at Saiq.\r\nRegression between temperature at Saiq and temperature in three oases, Al Jabal Al Akhdar, OmanThis approach facilitated the calculation of hourly temperatures, which were essential for assessing winter chill dynamics over several years.\r\nChill dynamics between 1983 and 2007, Al Jabal Al Akhdar, OmanThe findings were submitted to the journal Climatic Change (Luedeling et al., 2009b), where reviewers suggested incorporating future climate scenarios. To address this, the LARS-WG weather generator was employed to simulate plausible weather conditions for the oases under scenarios of 1°C and 2°C warming.\r\nChill prospects for 1°C and 2°C warming scenarios in Al Jabal Al Akhdar, OmanThe results illustrated the potential impacts of climate change on winter chill, marking the beginning of a career focused on chill modeling.\r\nChill model sensitivity\r\nAfter completing a PhD at the University of Kassel, Prof. Dr. Eike Lüdeling became a Postdoctoral Scholar at the University of California at Davis, where his research focused on climate change impacts on winter chill in California’s Central Valley, a key region for temperate fruit tree production.\r\nUpon arriving in California, it became evident that the choice of chill model significantly impacts winter chill quantification. Initially, the simplest model was chosen due to a lack of programming skills, but further investigation highlighted the importance of model selection. Extensive library research revealed the need for a thorough examination of various chill models. Knowledge gained in Oman was utilized to create temperature scenarios for multiple locations, allowing for the analysis of how chill accumulation would likely change in the future.\r\nThe analysis focused on changes predicted by various models for the same locations and future scenarios. Here are the locations examined:\r\nWeather station locations in CaliforniaThe results revealed considerable variation in chill projections for these locations. The analysis illustrated significant differences in estimates of chill losses by 2050, indicating that not all models could accurately represent winter chill dynamics. Ultimately, the Dynamic Model emerged as the most reliable option, prompting its primary use in subsequent research.\r\nSensitivity of chill projections to model choice (CH - Chilling Hours; Utah - Utah Model; Utah+ - Positive Utah Model; Port. - Dynamic Model)However, challenges arose with the complexity of the Dynamic Model, which required outdated Excel software for calculations. Additionally, the data processing steps necessary to generate credible temperature scenarios proved cumbersome and error-prone, highlighting the need to develop programming skills for more efficient analysis.\r\nWinter chill in California\r\nThe primary goal during the time in California was to create a winter chill projection for the Central Valley, an important region for fruit and nut production. Utilizing California’s extensive network of weather stations, the plan involved using data from over 100 stations and generating multiple climate scenarios. To manage this complex task efficiently, a decision was made to automate most processes, leading to an exploration of programming.\r\nThe automation was implemented using JSL, a programming language associated with the statistics software JMP, which facilitated the handling of the data. Despite some challenges, the automation was largely successful, though running the weather generator manually for each station remained tedious. Ultimately, projections were generated for all stations, illustrating chill accumulation over 100 plausible winter seasons for each climate scenario.\r\nTo present the results effectively, a metric called ‘Safe Winter Chill’ was developed, defined as the 10th percentile of the chill distribution, indicating the minimum chill amount that would be exceeded in 90% of the years. Here’s an illustration of the Safe Winter Chill metric:\r\nIllustration of the Safe Winter Chill conceptA method for spatially interpolating the station results was also established, leading to the creation of maps that depicted winter chill prospects for the Central Valley. Here’s one of the maps that resulted from this:\r\nWinter chill prospects for California’s Central ValleyThis analysis was published in the journal PLOS ONE (Luedeling et al., 2009d).\r\nWinter chill ratios\r\nFollowing the automation of processing steps in JSL, attention turned to creating a global winter chill projection. The Global Summary of the Day database was identified as a valuable data source, featuring records from thousands of weather stations. The project proved challenging due to limited programming skills. Data processing was carried out on six computers operating around the clock for several weeks, likely a result of initial setup difficulties rather than the complexity of the analyses. In the end, data for about 5,000 weather stations were processed, generating multiple chill metrics.\r\nThis extensive dataset allowed for a comparison of chill models by calculating the ratios between various chill metrics at each station. If these ratios had been consistent worldwide (e.g., one Chill Portion always equating to ten Chilling Hours), any chill model could have been reliably used. However, significant variations in chill metric ratios were observed globally.\r\nChill metric ratios around the worldThis study was published in the International Journal of Biometeorology (Luedeling & Brown, 2011a).\r\nA global projection of future winter chill\r\nUsing the same analytical methods, a global projection of the potential impacts of climate change on winter chill was also generated:\r\nProjected decline in available winter chill around the worldThe regions marked in red and orange on the lower two maps may experience significant impacts on fruit and nut production due to decreasing winter chill. With substantial chill losses, it is unlikely that growers will be able to sustain their current tree cultivars. Notably, the Mediterranean region is expected to be particularly affected.\r\nWinter chill projection for the Mediterranean regionThis prompted collaboration with partners in the Mediterranean region and other countries with similar climates, such as South Africa and Chile.\r\nWinter chill in Germany\r\nGermany is not highlighted as particularly vulnerable to chill losses, and an analysis of historical chilling trends from 1950 supports this observation:\r\nWinter chill in Germany in 2010, and changes between 1950 and 2010Winter chill in Tunisia\r\nProspects for orchards in Tunisia are particularly challenging due to the region being close to the warmest limits for many fruit and nut tree species. An assessment published in 2018 examined past and future trends in winter chill for an orchard in Central Tunisia, following a seven-year gap from earlier studies. This delay stemmed from other professional commitments and the difficulty of obtaining suitable future climate data for chill modeling.\r\nWhile climate change data is widely available, much of it is presented as spatial grids, making it cumbersome to work with. Each climate scenario requires numerous grids for temperature and rainfall, leading to substantial data storage needs, sometimes exceeding 700 GB. Soon after establishing a processing structure for these datasets, the IPCC introduced the Representative Concentration Pathways (RCPs), rendering earlier scenarios outdated and complicating the analysis further, especially given the limited data transfer capabilities while based in Kenya.\r\nCollaboration with colleagues in Tunisia, particularly Haifa Benmoussa, revealed that tree crops like almonds and pistachios are highly vulnerable to climate change impacts. Fortunately, a new climate database specifically for Africa, called AFRICLIM, was developed, facilitating the acquisition and processing of relevant climate scenarios. This allowed for the incorporation of new functions in chillR to sample from AFRICLIM grids and produce the necessary climate projections.\r\nWinter chill analysis for an orchard near Sfax in Central Tunisia (blue bars indicate approximate chilling requirements of pistachios and two types of almonds)The figure, which is to be created by the end of the semester, illustrates the historical development of chill accumulation at a specific location, with observed values represented by red dots and typical chill distributions shown as boxplots. These data were generated using a weather generator that is calibrated with historical weather data and produces artificial annual weather records. The generator was also used to create future scenarios based on the AFRICLIM database.\r\nThe analysis indicates that in none of the future scenarios does the cultivation of pistachios or high-chill almonds remain viable. This conclusion is supported by observations in Tunisia, where, after the warm winter of 2015/16, many pistachio trees barely developed any flowers, leading to crop failures.\r\nPistachio tree near Sfax, Central Tunisia, in April of 2016Winter chill in Chile\r\nAFRICLIM addressed the challenge of obtaining future climate data for Africa but did not fully meet the needs for integrating climate change projections into chillR. It was limited to African data, and users seeking information for single locations had to download large datasets, which was inefficient. A more effective solution was needed to access data quickly for individual weather stations globally.\r\nAn early resource was ClimateWizard, developed by Evan Girvetz, which initially provided gridded data but later included a script for extracting information for specific locations. This functionality was eventually made available through an API at CIAT, allowing access to outputs from 15 climate models for the latest RCP scenarios. This advancement enabled Eduardo Fernández to analyze past and future chill development across nine locations in Chile, expanding the geographic scope of the research.\r\nMap of fruit growing locations in ChileThe following diagram illustrates the assessment of past and future winter chill across nine locations in Chile:\r\nAssessment of past and future winter chill for 9 locations across ChileEduardo preferred a different plot design and utilized the ggplot2 package, a robust plotting tool for R, to redesign it. The complexity of having data from multiple sites made interpretation challenging, prompting Eduardo to creatively summarize key information for each scenario. He presented this information as a heat map, simplifying the visualization.\r\nHeatmap showing Safe Winter Chill (10% quantile of chill distribution) for nine locations in ChileChill projection for Patagonia\r\nCertain regions may become more suitable for agriculture as the climate changes. An analysis was conducted to assess the climatic suitability for fruit and nut trees in Patagonia, southern Argentina, which is located at the southern frontier of agriculture:\r\nMap of parts of Patagonia in Argentina, showing locations that were analyzed in this studyWeather station records for all locations on the map were obtained, enabling the calibration of a weather generator and the download of climate projections from the ClimateWizard database. This facilitated the creation of past and future temperature scenarios for all stations, as well as the computation of winter chill and other agroclimatic metrics. However, the results of the winter chill calculations were not particularly noteworthy, as minimal changes were projected.\r\nHeatmap showing Safe Winter Chill (10% quantile of chill distribution) for eleven locations in PatagoniaClimate change could potentially enhance land suitability for fruit trees by providing increased summer heat:\r\nPast and projected future heat availability for four exemplary locations in PatagoniaA further beneficial development is a likely reduction in the number of frost hours:\r\nPast and projected frost risk for four exemplary locations in PatagoniaWhile the changes observed may appear minor, they are likely to shift many locations from a climate that is too cool for agriculture, particularly for fruit trees, to a more optimal situation. This presents a rare instance of potentially positive news related to climate change, though it is important to acknowledge that these changes could have negative consequences for natural ecosystems and other agricultural systems.\r\nChill model comparison\r\nEduardo Fernandez recently utilized the climate change analysis framework to enhance previous chill model comparisons, significantly building on earlier work. He compiled a collection of 13 methods for quantifying chill accumulation from existing literature and applied these models to datasets from several locations in Germany, Tunisia, and Chile, which are part of the PASIT project. A map illustrates the locations included in this analysis.\r\nLocations used for comparing predictions by a total of 13 chill models across different climatesThe expectation was that the models would show significant differences in the extent of changes they predicted, and this anticipation was indeed fulfilled:\r\nChill change projections by a total of 13 chill models across different climate scenariosThe figure illustrates the changes predicted by 13 different models across various sites and climate scenarios, categorized into three groups: warm, moderate, and cool. Eduardo’s analysis reveals significant discrepancies among the models, highlighting the risks of selecting the most convenient model for predictions. The variation in predictions is evident in the color distribution across the rows of the panels, with a uniform color indicating consistency among models—something that is not observed here.\r\nFor locations in Tunisia and Chile, the predictions mainly concern the extent of chill losses, ranging from mild to alarming. In Germany, the situation is even less clear, with some models predicting increases in chill and others predicting decreases.\r\nThese findings underscore the importance of model choice, as many models may be arbitrary and can be disregarded, yet uncertainties remain regarding which models accurately represent future conditions. This area of research offers opportunities for further exploration and innovation.\r\nChill projection for all of Tunisia\r\nThe study projected climate change impacts on winter chill for an orchard near Sfax in Central Tunisia, but the region is not the most favorable for temperate fruit and nut tree cultivation. Tunisia is climatically diverse, featuring mountains, plains, coastal areas, and interior deserts, leading to significant variation in historical and future chill availability across the country.\r\nUnder the leadership of Haifa Benmoussa, the team mapped chill accumulation throughout Tunisia using a framework previously developed. This analysis utilized data from 20 weather stations in Tunisia and neighboring countries. By applying the established analytical framework to each location, they were able to interpolate results and create chill maps that illustrate the trends in chill availability in Tunisia over the past few decades:\r\nChill availability maps for Tunisia for several past scenariosThe process of interpolating site-specific results into a comprehensive map for Tunisia involves some areas for improvement. Currently, the methodology uses site-specific predictions of Safe Winter Chill, defined as the 10th percentile of the chill distribution derived from annual temperature dynamics generated by the weather model. This information is then interpolated using the Kriging technique.\r\nIn addition, the elevations of the locations where chill was modeled are also considered. A linear model is fitted to establish a relationship between chill accumulation and elevation. Using a Digital Elevation Model (DEM), the differences between the model-derived elevations from weather stations and the actual elevations of each location are calculated. This difference, not accounted for in the initial chill surface derived from weather station data, is corrected using the established elevation-chill relationship.\r\nWhile this method seems reasonable for Tunisia, it may not be suitable for cooler regions like Germany, where the relationship between elevation and chill availability may not be linear. The resulting projection of future chill for Tunisia is displayed in the following map:\r\nChill availability for Tunisia for various plausible scenarios of future climateThe projections reveal significant concern regarding winter chill in Tunisia. The Dynamic Model, which is regarded as a reliable predictor, indicates substantial decreases in Chill Portions, the units used by the model. This trend poses serious challenges for much of the country. Even in areas where some winter chill is expected to persist, farmers will need to adapt their practices, as the tree species currently cultivated are suited to past climate conditions. Adaptation strategies may include shifting to tree cultivars with lower chilling requirements, provided such options are available.\r\nRevisiting chill accumulation in Oman\r\nAfter a decade of exploration in other regions, the analysis turned back to Oman, where there was a desire to enhance the initial study of chill accumulation. The first assessment had limitations, particularly concerning model selection and a lack of adequate future climate data. With encouragement from Prof. Dr. Andreas Bürkert, a more robust evaluation became possible using the climate change analysis framework. This involved incorporating new methods to convert daily temperatures into hourly data. Updated assessments of past winter chill and future forecasts for the oases of Al Jabal Al Akhdar were produced, with the findings published in Climatic Change (Buerkert et al., 2020).\r\nExercises on past chill projections\r\nSketch out three data access and processing challenges that had to be overcome in order to produce chill projections with state-of-the-art methodology.\r\nAccessing Climate Data for Specific Locations:\r\nPrevious climate datasets like AFRICLIM and ClimateWizard only provided large-scale data. To get weather data for specific locations without downloading too much extra information, an API was created to quickly access data for single sites\r\nConverting Daily to Hourly Temperature Data:\r\nChill models need hourly temperature data, but many databases only give daily averages. Early methods for converting daily to hourly data weren’t very good, especially in areas with unique temperatures. Improved algorithms were developed to estimate hourly temperatures more accurately from daily data\r\nHandling Large Volumes of Climate Model Outputs:\r\nStudying different climate futures involves dealing with a lot of data from many climate models, which can be hard to manage. To handle this large amount of data effectively, workflows were streamlined and selective processing techniques were used\r\nOutline, in your understanding, the basic steps that are necessary to make such projections.\r\nTo make climate-based chill projections for specific regions, here are the essential steps typically involved:\r\nData Collection and Calibration: collect historical weather data and use it to calibrate a weather generator for realistic temperature simulations\r\nModel Selection and Scenario Setup: choose relevant climate models and emission scenarios to explore various future climates\r\nGenerate Temperature Projections: downscale climate data, converting it to daily or hourly temperatures as needed for chill calculations\r\nChill Calculation: apply chill models to estimate chill accumulation across different climate scenarios\r\nAnalysis and Visualization: compare chill projections across models and scenarios and visualize the findings\r\nInterpretation: validate projections with observed data where possible and assess agricultural impacts and adaptation needs\r\n\r\n\r\n\r\n",
      "last_modified": "2025-03-11T17:33:05+01:00"
    }
  ],
  "collections": []
}
